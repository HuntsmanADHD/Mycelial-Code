# Mycelial Native Compiler - Main Orchestration File
# Wires together all 5 compiler agents into a complete compilation pipeline
#
# Pipeline: Source Code -> Lexer -> Parser -> IR Generator -> Code Generator -> Assembler -> Linker -> ELF Binary
#
# Author: Opus (Claude Opus 4.5)
# Date: 2026-01-01
# Status: M1 Complete Pipeline Orchestration

network mycelial_compiler {

  # ============================================================================
  # SECTION 1: FREQUENCY DEFINITIONS (All Signal Types)
  # ============================================================================

  frequencies {

    # --------------------------------------------------------------------------
    # 1.1 Compilation Control Signals
    # --------------------------------------------------------------------------

    # Initial startup signal (from fruiting body)
    startup {
      source_file: string       # Path to .mycelial source file
      output_file: string       # Path for output ELF binary
    }

    # Request to compile a source file
    compile_request {
      source_file: string       # Path to .mycelial source file
      output_file: string       # Path for output ELF binary
    }

    # Final compilation complete signal
    compilation_complete {
      output_file: string       # Path to generated binary
      file_size: u64            # Size in bytes
      success: boolean          # Overall success status
    }

    # Compilation error signal
    compilation_error {
      stage: string             # "lexer", "parser", "ir", "codegen", "assembler", "linker"
      message: string           # Error description
      line: u32                 # Source line (if applicable)
      column: u32               # Source column (if applicable)
    }

    # --------------------------------------------------------------------------
    # 1.2 Lexer -> Parser Signals
    # --------------------------------------------------------------------------

    # Request to lex source code
    lex_request {
      source: string            # Source code to lex
      filename: string          # Source filename
    }

    # Individual token from lexer
    token {
      type: string              # Token type (NETWORK, IDENTIFIER, NUMBER, etc.)
      value: string             # Token value as string
      line: u32                 # Source line number
      column: u32               # Source column number
    }

    # Lexer completion signal
    lex_complete {
      token_count: u32          # Total tokens emitted
      error_count: u32          # Number of lexer errors
    }

    # --------------------------------------------------------------------------
    # 1.3 Parser -> IR Generator Signals
    # --------------------------------------------------------------------------

    # Individual AST node (for streaming if needed)
    ast_node {
      node_type: string         # AST node type
      node_id: u32              # Unique node identifier
      parent_id: u32            # Parent node ID (0 for root)
      data: string              # JSON-encoded node data
    }

    # Complete AST (primary handoff to IR generator)
    ast_complete {
      program: Program          # Full Program AST
    }

    # Parser error signal
    parse_error {
      message: string           # Error message
      line: u32                 # Source line
      column: u32               # Source column
      expected: string          # Expected token/construct
      found: string             # Actual token/construct
    }

    # Parser completion signal
    parse_complete {
      program_id: u32           # Program identifier
      node_count: u32           # Total AST nodes
      error_count: u32          # Number of parse errors
    }

    # --------------------------------------------------------------------------
    # 1.4 IR Generator -> Code Generator Signals
    # --------------------------------------------------------------------------

    # Individual IR instruction
    ir_node {
      instruction: IRInstruction  # The IR instruction to process
    }

    # Function boundary signals
    ir_function_start {
      name: string              # Function name
      params: string            # JSON-encoded parameter list
      return_type: string       # Return type (I8, I16, I32, I64, PTR, VOID)
    }

    ir_function_end {
      name: string              # Function name
    }

    # LIR function (alternative batch format)
    lir_function {
      name: string              # Function name
      params: string            # JSON-encoded parameters
      return_type: string       # Return type
      basic_blocks: string      # JSON-encoded basic blocks
    }

    # LIR struct definition
    lir_struct {
      name: string              # Struct name
      fields: string            # JSON-encoded field list
      total_size: u32           # Total struct size in bytes
      alignment: u32            # Struct alignment
    }

    # IR generation complete
    ir_complete {
      instruction_count: u32    # Total IR instructions
      function_count: u32       # Number of functions
      struct_count: u32         # Number of structs
    }

    # IR generation error
    ir_error {
      message: string           # Error message
      location: string          # Source location info
    }

    # --------------------------------------------------------------------------
    # 1.5 Code Generator -> Assembler Signals
    # --------------------------------------------------------------------------

    # x86-64 assembly instruction
    asm_instruction {
      label: string             # Label for this instruction (optional)
      mnemonic: string          # Instruction mnemonic (mov, add, etc.)
      operands: string          # JSON-encoded operand list
    }

    # Data directive
    asm_data {
      label: string             # Data label
      data_type: string         # "asciz", "quad", "byte", "align"
      value: string             # Data value
    }

    # Section directive
    asm_section {
      name: string              # Section name (.text, .rodata, .data, .bss)
    }

    # Code generation complete
    codegen_complete {
      instruction_count: u32    # Total assembly instructions
      function_count: u32       # Number of functions generated
    }

    # Register allocation complete (internal)
    allocation_complete {
      function_name: string     # Function name
      vreg_count: u32           # Number of virtual registers
      spill_count: u32          # Number of spilled registers
    }

    # --------------------------------------------------------------------------
    # 1.6 Assembler -> Linker Signals
    # --------------------------------------------------------------------------

    # Encoded machine code bytes
    machine_code {
      section: string           # Section name (.text, .rodata, etc.)
      offset: u32               # Offset within section
      bytes: string             # Hex-encoded byte string
    }

    # Relocation entry
    relocation {
      section: string           # Section containing relocation
      offset: u32               # Offset within section
      symbol: string            # Symbol name
      reloc_type: string        # R_X86_64_PC32, R_X86_64_64, etc.
      addend: i64               # Addend value
    }

    # Symbol definition
    symbol_def {
      name: string              # Symbol name
      section: string           # Section containing symbol
      offset: u32               # Offset within section
      is_global: boolean        # Global visibility
    }

    # Section metadata
    section_info {
      name: string              # Section name
      size: u32                 # Section size in bytes
      flags: u32                # Section flags (0x2, 0x4, etc.)
    }

    # Assembly complete
    asm_complete {
      total_bytes: u32          # Total machine code bytes
      symbol_count: u32         # Number of symbols
      relocation_count: u32     # Number of relocations
    }

    # Assembly error
    asm_error {
      message: string           # Error message
      line: u32                 # Line number in assembly
      instruction: string       # Problematic instruction
    }

    # --------------------------------------------------------------------------
    # 1.7 Linker Output Signals
    # --------------------------------------------------------------------------

    # Linking complete
    link_complete {
      output_file: string       # Path to output binary
      file_size: u64            # Binary size in bytes
      entry_point: u64          # Entry point virtual address
    }

    # Linking error
    link_error {
      message: string           # Error message
      symbol: string            # Problematic symbol (if applicable)
    }

    # ELF binary data (internal)
    elf_binary {
      bytes: string             # Hex-encoded ELF binary
    }
  }

  # ============================================================================
  # SECTION 2: TYPE DEFINITIONS
  # ============================================================================

  types {

    # Token type enumeration
    enum TokenType {
      # Keywords
      NETWORK, FREQUENCIES, FREQUENCY, HYPHAE, HYPHAL,
      STATE, ON, SIGNAL, EMIT, REPORT, SPAWN, DIE,
      SOCKET, FRUITING_BODY, TOPOLOGY, CONFIG,
      IF, ELSE, WHERE, REST, CYCLE, LET, FOR, IN, WHILE,
      IMPORT, TYPES, STRUCT, ENUM, CONSTANTS,
      TRUE, FALSE,
      # Type keywords
      U8, U16, U32, U64, I8, I16, I32, I64, F32, F64,
      STRING_TYPE, BINARY_TYPE, BOOLEAN_TYPE,
      VEC, QUEUE, MAP,
      # Literals
      NUMBER, STRING_LIT, IDENTIFIER,
      # Operators
      PLUS, MINUS, STAR, SLASH, PERCENT,
      EQ, NE, LT, GT, LE, GE,
      AND, OR, NOT,
      ASSIGN, ARROW, COLON, DOT, COMMA,
      # Delimiters
      LPAREN, RPAREN, LBRACE, RBRACE, LBRACKET, RBRACKET,
      # Special
      EOF, ERROR
    }

    # Token structure
    struct Token {
      type: TokenType
      value: string
      line: u32
      column: u32
    }

    # Compilation stage enumeration
    enum CompileStage {
      IDLE,
      LEXING,
      PARSING,
      IR_GENERATION,
      CODE_GENERATION,
      ASSEMBLING,
      LINKING,
      COMPLETE,
      ERROR
    }

    # -------------------------------------------------------------------------
    # Parser AST Types
    # -------------------------------------------------------------------------

    struct SourceLocation {
      line: u32
      column: u32
    }

    struct ParseError {
      message: string
      location: SourceLocation
      expected: string
      found: string
    }

    # ─────────────────────────────────────────────────────────────────────────
    # AST Node Types
    # ─────────────────────────────────────────────────────────────────────────

    enum ASTNodeType {
      PROGRAM, NETWORK_DEF, FREQUENCY_DEF, HYPHAL_DEF, STATE_BLOCK,
      STATE_FIELD, RULE, TOPOLOGY_RULE, SOCKET_DEF, FRUITING_BODY_DEF,
      STATEMENT, EXPRESSION, TYPE_REF, LITERAL
    }

    # ─────────────────────────────────────────────────────────────────────────
    # Program (Top Level)
    # ─────────────────────────────────────────────────────────────────────────

    struct Program {
      items: vec<ProgramItem>
      location: SourceLocation
    }

    enum ProgramItem {
      Frequency(FrequencyDef),
      Network(NetworkDef),
      Import(ImportDef)
    }

    # ─────────────────────────────────────────────────────────────────────────
    # Definitions
    # ─────────────────────────────────────────────────────────────────────────

    struct ImportDef {
      path: string
      location: SourceLocation
    }

    struct FrequencyDef {
      name: string
      fields: vec<FieldDef>
      location: SourceLocation
    }

    struct FieldDef {
      name: string
      field_type: TypeRef
      location: SourceLocation
    }

    struct NetworkDef {
      name: string
      frequencies: vec<FrequencyDef>
      types: vec<TypeDef>
      constants: vec<ConstantDef>
      hyphae: vec<HyphalDef>
      topology: vec<TopologyItem>
      config: vec<ConfigItem>
      location: SourceLocation
    }

    struct TypeDef {
      name: string
      type_kind: TypeDefKind
      location: SourceLocation
    }

    enum TypeDefKind {
      Struct(vec<FieldDef>),
      Enum(vec<EnumVariant>)
    }

    struct EnumVariant {
      name: string
      fields: vec<FieldDef>
      location: SourceLocation
    }

    struct ConstantDef {
      name: string
      value: Expression
      location: SourceLocation
    }

    struct ConfigItem {
      key: string
      value: Expression
      location: SourceLocation
    }

    # ─────────────────────────────────────────────────────────────────────────
    # Hyphal (Agent) Definitions
    # ─────────────────────────────────────────────────────────────────────────

    struct HyphalDef {
      name: string
      frequency_ref: string       # Optional: "frequency X"
      state: StateBlock
      rules: vec<Rule>
      location: SourceLocation
    }

    struct StateBlock {
      fields: vec<StateField>
      location: SourceLocation
    }

    struct StateField {
      name: string
      field_type: TypeRef
      init_value: Expression      # Optional initial value
      location: SourceLocation
    }

    struct Rule {
      trigger: RuleTrigger
      guard: Expression           # Optional "where" predicate
      body: vec<Statement>
      location: SourceLocation
    }

    enum RuleTrigger {
      Signal(SignalMatch),
      Rest,
      Cycle(u32)
    }

    struct SignalMatch {
      frequency: string
      binding: string             # Variable binding name
      location: SourceLocation
    }

    # ─────────────────────────────────────────────────────────────────────────
    # Topology
    # ─────────────────────────────────────────────────────────────────────────

    enum TopologyItem {
      Spawn(SpawnDef),
      Socket(SocketDef),
      FruitingBody(FruitingBodyDef)
    }

    struct SpawnDef {
      hyphal: string
      instance: string
      location: SourceLocation
    }

    struct SocketDef {
      from: string
      to: string
      frequency: string
      location: SourceLocation
    }

    struct FruitingBodyDef {
      name: string
      location: SourceLocation
    }

    # ─────────────────────────────────────────────────────────────────────────
    # Statements
    # ─────────────────────────────────────────────────────────────────────────

    enum Statement {
      Let(LetStatement),
      Assignment(AssignmentStatement),
      Conditional(ConditionalStatement),
      Emit(EmitStatement),
      Report(ReportStatement),
      Spawn(SpawnStatement),
      Die(DieStatement),
      ForLoop(ForLoopStatement),
      WhileLoop(WhileLoopStatement),
      Return(ReturnStatement),
      Break(BreakStatement),
      Continue(ContinueStatement),
      Expression(ExpressionStatement),
      None
    }

    struct LetStatement {
      name: string
      type_annotation: TypeRef    # Optional
      value: Expression
      location: SourceLocation
    }

    struct AssignmentStatement {
      target: AssignmentTarget
      value: Expression
      location: SourceLocation
    }

    enum AssignmentTarget {
      Variable(string),
      StateField(string),
      FieldAccess(Expression, string),
      IndexAccess(Expression, Expression)
    }

    struct ConditionalStatement {
      condition: Expression
      then_body: vec<Statement>
      else_body: vec<Statement>   # Empty if no else
      location: SourceLocation
    }

    struct EmitStatement {
      frequency: string
      fields: vec<FieldInit>
      location: SourceLocation
    }

    struct FieldInit {
      name: string
      value: Expression
      location: SourceLocation
    }

    struct ReportStatement {
      metric: string
      value: Expression
      location: SourceLocation
    }

    struct SpawnStatement {
      hyphal: string
      instance: string
      location: SourceLocation
    }

    struct DieStatement {
      location: SourceLocation
    }

    struct ForLoopStatement {
      variable: string
      iterable: Expression
      body: vec<Statement>
      location: SourceLocation
    }

    struct WhileLoopStatement {
      condition: Expression
      body: vec<Statement>
      location: SourceLocation
    }

    struct ReturnStatement {
      value: Expression           # Optional
      location: SourceLocation
    }

    struct BreakStatement {
      location: SourceLocation
    }

    struct ContinueStatement {
      location: SourceLocation
    }

    struct ExpressionStatement {
      expression: Expression
      location: SourceLocation
    }

    # ─────────────────────────────────────────────────────────────────────────
    # Expressions
    # ─────────────────────────────────────────────────────────────────────────

    enum Expression {
      Literal(LiteralExpr),
      Identifier(IdentifierExpr),
      BinaryOp(BinaryOpExpr),
      UnaryOp(UnaryOpExpr),
      FieldAccess(FieldAccessExpr),
      IndexAccess(IndexAccessExpr),
      Call(CallExpr),
      MethodCall(MethodCallExpr),
      StateAccess(StateAccessExpr),
      SignalAccess(SignalAccessExpr),
      ListLiteral(ListLiteralExpr),
      MapLiteral(MapLiteralExpr),
      StructLiteral(StructLiteralExpr),
      Grouped(GroupedExpr),
      None
    }

    struct LiteralExpr {
      value: Literal
      location: SourceLocation
    }

    struct IdentifierExpr {
      name: string
      location: SourceLocation
    }

    struct BinaryOpExpr {
      op: BinaryOperator
      left: Expression
      right: Expression
      location: SourceLocation
    }

    enum BinaryOperator {
      # Arithmetic
      Add, Sub, Mul, Div, Mod,
      # Comparison
      Eq, Ne, Lt, Gt, Le, Ge,
      # Logical
      And, Or
    }

    struct UnaryOpExpr {
      op: UnaryOperator
      operand: Expression
      location: SourceLocation
    }

    enum UnaryOperator {
      Not, Neg, Pos
    }

    struct FieldAccessExpr {
      object: Expression
      field: string
      location: SourceLocation
    }

    struct IndexAccessExpr {
      object: Expression
      index: Expression
      location: SourceLocation
    }

    struct CallExpr {
      name: string
      args: vec<Expression>
      location: SourceLocation
    }

    struct MethodCallExpr {
      object: Expression
      method: string
      args: vec<Expression>
      location: SourceLocation
    }

    struct StateAccessExpr {
      field: string
      location: SourceLocation
    }

    struct SignalAccessExpr {
      binding: string
      field: string
      location: SourceLocation
    }

    struct ListLiteralExpr {
      elements: vec<Expression>
      location: SourceLocation
    }

    struct MapLiteralExpr {
      entries: vec<MapEntry>
      location: SourceLocation
    }

    struct MapEntry {
      key: Expression
      value: Expression
      location: SourceLocation
    }

    struct StructLiteralExpr {
      type_name: string
      fields: vec<FieldInit>
      location: SourceLocation
    }

    struct GroupedExpr {
      inner: Expression
      location: SourceLocation
    }

    # ─────────────────────────────────────────────────────────────────────────
    # Literals
    # ─────────────────────────────────────────────────────────────────────────

    enum Literal {
      Number(i64),
      Float(f64),
      String(string),
      Bool(boolean),
      Null
    }

    # ─────────────────────────────────────────────────────────────────────────
    # Type References
    # ─────────────────────────────────────────────────────────────────────────

    enum TypeRef {
      Primitive(PrimitiveType),
      Vec(TypeRef),
      Queue(TypeRef),
      Map(TypeRef, TypeRef),
      Custom(string),
      None
    }

    enum PrimitiveType {
      U8, U16, U32, U64,
      I8, I16, I32, I64,
      F32, F64,
      Boolean, String, Binary
    }

    # -------------------------------------------------------------------------
    # IR Generator Types
    # -------------------------------------------------------------------------

    # Low-level IR types
    enum LIRType {
      I8, I16, I32, I64,
      F32, F64,
      Ptr,
      Void
    }

    # Field layout information for struct types
    struct FieldLayout {
      name: string
      offset: u32
      size: u32
      field_type: LIRType
    }

    # Struct field information (for IR emission)
    struct StructField {
      name: string
      offset: u32
      size: u32
      field_type: LIRType
    }

    # Struct layout information
    struct StructLayout {
      fields: vec<FieldLayout>
      total_size: u32
      alignment: u32
    }

    # IR generation context
    struct IRGenContext {
      current_function: string
      current_hyphal: string
      current_trigger_frequency: string
      temp_counter: u32
      label_counter: u32
      signal_counter: u32
      payload_counter: u32
      current_agent_id: u32
      frequency_map: map<string, u32>
      struct_layouts: map<string, StructLayout>
      local_vars: map<string, string>
    }

    # -------------------------------------------------------------------------
    # Low-Level IR (LIR) Types
    # -------------------------------------------------------------------------

    # LIR function parameter
    struct Parameter {
      name: string
      param_type: LIRType
    }

    # LIR basic block
    struct BasicBlock {
      label: string
      instructions: vec<Instruction>
      terminator: Terminator
    }

    # IR operation codes (opcodes)
    enum IROpcode {
      LABEL,
      MOVE,
      CONST,
      LOAD,
      STORE,
      LOAD_FIELD,
      STORE_FIELD,
      ADD,
      SUB,
      MUL,
      DIV,
      MOD,
      AND,
      OR,
      XOR,
      SHL,
      SHR,
      NOT,
      NEG,
      CMP_EQ,
      CMP_NE,
      CMP_LT,
      CMP_LE,
      CMP_GT,
      CMP_GE,
      CALL,
      GET_FIELD_ADDR,
      ALLOC,
      FREE,
      BITCAST,
      PHI,
      JUMP,
      BRANCH,
      RET,
      SIGNAL_ALLOC,
      SIGNAL_SET_PAYLOAD,
      SIGNAL_SET_FIELD,
      SIGNAL_EMIT
    }

    # Flattened IR instruction representation (used by register allocator)
    # This is a simplified struct with common fields across all instruction types
    struct IRInstruction {
      op: IROpcode             # Operation code
      dst: string              # Destination register/variable (empty if none)
      src1: string             # First source operand (empty if none)
      src2: string             # Second source operand (empty if none)
      imm: i64                 # Immediate value (for constants)
      label: string            # Label (for jumps/branches)
      type_size: u32           # Size/offset for memory operations
    }

    # Live interval for register allocation
    struct LiveInterval {
      vreg: string             # Virtual register name
      start: u32               # Start position
      end: u32                 # End position
      assigned: string         # Assigned physical register (empty if not assigned)
      spill_slot: i32          # Spill slot index (-1 if not spilled)
    }

    # x86-64 relocation types (forward declaration for Section)
    enum RelocationType {
      R_X86_64_32,             # Direct 32-bit zero extended
      R_X86_64_32S,            # Direct 32-bit sign extended
      R_X86_64_64,             # Direct 64-bit
      R_X86_64_PC32            # PC-relative 32-bit signed
    }

    # Section relocation entry (forward declaration for Section)
    struct SectionRelocation {
      offset: u32              # Offset within section
      symbol: string           # Symbol name to relocate against
      reloc_type: RelocationType # Relocation type
      addend: i64              # Addend value
    }

    # ELF section for linker
    struct Section {
      name: string             # Section name (e.g., ".text", ".data")
      data: vec<u8>            # Section data bytes
      relocations: vec<SectionRelocation> # Relocation entries
    }

    # Assembly instruction line
    struct AsmLine {
      label: string            # Label (empty if none)
      mnemonic: string         # Instruction mnemonic (e.g., "mov", "add")
      operands: vec<string>    # Operands list
      line_num: u32            # Source line number
    }

    # Symbol table entry
    struct Symbol {
      name: string             # Symbol name
      section: string          # Section name (e.g., ".text")
      offset: u32              # Offset within section
      is_global: boolean       # Is globally visible
      is_defined: boolean      # Is defined (vs. external reference)
    }

    # Symbol entry for linker (includes resolved virtual address)
    struct SymbolEntry {
      name: string             # Symbol name
      section: string          # Section name (e.g., ".text")
      offset: u32              # Offset within section
      is_global: boolean       # Is globally visible
      vaddr: u64               # Virtual address (after layout)
    }

    # Relocation entry for linker
    struct RelocationEntry {
      section: string          # Section containing relocation
      offset: u32              # Offset within section
      symbol: string           # Symbol name to relocate against
      reloc_type: RelocationType # Relocation type
      addend: i64              # Addend value
    }

    # Data directive line
    struct DataLine {
      label: string            # Label (empty if none)
      data_type: string        # Data type (e.g., ".byte", ".word", ".quad")
      value: string            # Data value
      line_num: u32            # Source line number
    }

    # Instruction relocation entry
    struct InstrRelocation {
      offset: u8               # Offset within instruction
      symbol: string           # Symbol name to relocate against
      reloc_type: RelocationType # Relocation type
      addend: i64              # Addend value
    }

    # Encoded machine code instruction
    struct EncodedInstruction {
      bytes: vec<u8>           # Machine code bytes
      relocations: vec<InstrRelocation> # Relocation entries
    }

    # Register information
    struct RegisterInfo {
      name: string             # Register name (e.g., "rax", "rbx")
      code: u8                 # Register code (0-15)
      is_extended: boolean     # Whether this is an extended register (r8-r15)
      size: u8                 # Register size in bytes (1, 2, 4, 8)
    }

    # Memory operand
    struct MemoryOperand {
      base: string             # Base register name
      index: string            # Index register name (empty if none)
      scale: u8                # Scale factor (1, 2, 4, 8)
      displacement: i32        # Displacement value
      is_rip_relative: boolean # Whether this is RIP-relative addressing
    }

    # Assembly operand types
    enum Operand {
      Reg(RegisterInfo),       # Register operand
      Imm(i64),                # Immediate value
      Mem(MemoryOperand),      # Memory operand
      Label(string)            # Label reference
    }

    # LIR instruction enum
    enum Instruction {
      Move(MoveInst),
      Load(LoadInst),
      Store(StoreInst),
      LoadField(LoadFieldInst),
      StoreField(StoreFieldInst),
      Add(BinaryInst),
      Sub(BinaryInst),
      Mul(BinaryInst),
      Div(BinaryInst),
      Mod(BinaryInst),
      And(BinaryInst),
      Or(BinaryInst),
      Xor(BinaryInst),
      Not(UnaryInst),
      Neg(UnaryInst),
      CmpEq(CompareInst),
      CmpNe(CompareInst),
      CmpLt(CompareInst),
      CmpLe(CompareInst),
      CmpGt(CompareInst),
      CmpGe(CompareInst),
      Call(CallInst),
      Const(ConstInst),
      GetFieldAddr(GetFieldAddrInst),
      Alloc(AllocInst),
      SignalAlloc(SignalAllocInst),
      SignalSetPayload(SignalSetPayloadInst),
      SignalSetField(SignalSetFieldInst),
      SignalEmit(SignalEmitInst)
    }

    struct MoveInst {
      dst: string
      src: string
    }

    struct LoadInst {
      dst: string
      addr: string
    }

    struct StoreInst {
      addr: string
      src: string
    }

    struct LoadFieldInst {
      dst: string
      object: string
      offset: u32
    }

    struct StoreFieldInst {
      object: string
      offset: u32
      src: string
    }

    struct BinaryInst {
      dst: string
      lhs: string
      rhs: string
    }

    struct UnaryInst {
      dst: string
      operand: string
    }

    struct CompareInst {
      dst: string
      lhs: string
      rhs: string
    }

    struct CallInst {
      dst: string
      func: string
      args: vec<string>
    }

    struct ConstInst {
      dst: string
      value: ConstValue
      const_type: LIRType
    }

    enum ConstValue {
      Int(i64),
      Float(f64),
      String(string),
      Bool(boolean)
    }

    struct GetFieldAddrInst {
      dst: string
      object: string
      offset: u32
    }

    struct AllocInst {
      dst: string
      size: u32
    }

    struct SignalAllocInst {
      dst: string
      frequency_id: u32
      source_agent_id: u32
    }

    struct SignalSetPayloadInst {
      signal: string
      payload: string
      payload_size: u32
    }

    struct SignalSetFieldInst {
      payload: string
      field_offset: u32
      value: string
    }

    struct SignalEmitInst {
      signal: string
      frequency_id: u32
    }

    # Terminator enum
    enum Terminator {
      Jump(JumpTerm),
      Branch(BranchTerm),
      Return(ReturnTerm)
    }

    struct JumpTerm {
      target: string
    }

    struct BranchTerm {
      condition: string
      true_label: string
      false_label: string
    }

    struct ReturnTerm {
      value: string
    }
  }

  # ============================================================================
  # SECTION 3: LEXER HYPHAL
  # ============================================================================

  hyphae {

    hyphal lexer {
      state {
        source: string                    # Source code to tokenize
        filename: string                  # Source filename
        position: u32                     # Current position in source
        line: u32                         # Current line number
        column: u32                       # Current column number
        tokens_emitted: u32               # Count of tokens emitted
        error_count: u32                  # Lexer error count

        # Keyword lookup table
        keywords: map<string, string>     # Word -> Token type mapping
      }

      # Initialize lexer state
      on rest {
        state.position = 0
        state.line = 1
        state.column = 1
        state.tokens_emitted = 0
        state.error_count = 0

        # Initialize keywords map
        state.keywords = map_new()
        map_insert(state.keywords, "network", "NETWORK")
        map_insert(state.keywords, "frequencies", "FREQUENCIES")
        map_insert(state.keywords, "frequency", "FREQUENCY")
        map_insert(state.keywords, "hyphae", "HYPHAE")
        map_insert(state.keywords, "hyphal", "HYPHAL")
        map_insert(state.keywords, "state", "STATE")
        map_insert(state.keywords, "on", "ON")
        map_insert(state.keywords, "signal", "SIGNAL")
        map_insert(state.keywords, "emit", "EMIT")
        map_insert(state.keywords, "report", "REPORT")
        map_insert(state.keywords, "spawn", "SPAWN")
        map_insert(state.keywords, "die", "DIE")
        map_insert(state.keywords, "socket", "SOCKET")
        map_insert(state.keywords, "fruiting_body", "FRUITING_BODY")
        map_insert(state.keywords, "topology", "TOPOLOGY")
        map_insert(state.keywords, "config", "CONFIG")
        map_insert(state.keywords, "if", "IF")
        map_insert(state.keywords, "else", "ELSE")
        map_insert(state.keywords, "where", "WHERE")
        map_insert(state.keywords, "rest", "REST")
        map_insert(state.keywords, "cycle", "CYCLE")
        map_insert(state.keywords, "let", "LET")
        map_insert(state.keywords, "for", "FOR")
        map_insert(state.keywords, "in", "IN")
        map_insert(state.keywords, "while", "WHILE")
        map_insert(state.keywords, "true", "TRUE")
        map_insert(state.keywords, "false", "FALSE")
        map_insert(state.keywords, "u8", "U8")
        map_insert(state.keywords, "u16", "U16")
        map_insert(state.keywords, "u32", "U32")
        map_insert(state.keywords, "u64", "U64")
        map_insert(state.keywords, "i8", "I8")
        map_insert(state.keywords, "i16", "I16")
        map_insert(state.keywords, "i32", "I32")
        map_insert(state.keywords, "i64", "I64")
        map_insert(state.keywords, "f32", "F32")
        map_insert(state.keywords, "f64", "F64")
        map_insert(state.keywords, "string", "STRING_TYPE")
        map_insert(state.keywords, "binary", "BINARY_TYPE")
        map_insert(state.keywords, "boolean", "BOOLEAN_TYPE")
        map_insert(state.keywords, "vec", "VEC")
        map_insert(state.keywords, "queue", "QUEUE")
        map_insert(state.keywords, "map", "MAP")
      }

      # Receive tokenization request
      on signal(lex_request, req) {
        state.source = req.source
        state.filename = req.filename
        state.position = 0
        state.line = 1
        state.column = 1
        state.tokens_emitted = 0
        state.error_count = 0

        # Start tokenization
        tokenize_all()
      }

      # Main tokenization loop
      rule tokenize_all() {
        while state.position < string_len(state.source) {
          skip_whitespace_and_comments()

          if state.position >= string_len(state.source) {
            break
          }

          let tok = next_token()
          emit token {
            type: tok.type,
            value: tok.value,
            line: tok.line,
            column: tok.column
          }
          state.tokens_emitted = state.tokens_emitted + 1
        }

        # Emit EOF token
        emit token {
          type: "EOF",
          value: "",
          line: state.line,
          column: state.column
        }
        state.tokens_emitted = state.tokens_emitted + 1

        # Signal completion
        emit lex_complete {
          token_count: state.tokens_emitted,
          error_count: state.error_count
        }
      }

      # Peek at current character
      rule peek(offset: u32) -> string {
        let pos = state.position + offset
        if pos >= string_len(state.source) {
          return ""
        }
        return string_char_at(state.source, pos)
      }

      # Advance position and return current character
      rule advance() -> string {
        if state.position >= string_len(state.source) {
          return ""
        }

        let ch = string_char_at(state.source, state.position)
        state.position = state.position + 1

        if ch == "\n" {
          state.line = state.line + 1
          state.column = 1
        } else {
          state.column = state.column + 1
        }

        return ch
      }

      # Skip whitespace
      rule skip_whitespace() {
        while state.position < string_len(state.source) {
          let ch = peek(0)
          if ch == " " || ch == "\t" || ch == "\n" || ch == "\r" {
            advance()
          } else {
            break
          }
        }
      }

      # Skip comment (# to end of line)
      rule skip_comment() -> boolean {
        if peek(0) == "#" {
          while state.position < string_len(state.source) && peek(0) != "\n" {
            advance()
          }
          if peek(0) == "\n" {
            advance()
          }
          return true
        }
        return false
      }

      # Skip whitespace and comments
      rule skip_whitespace_and_comments() {
        while true {
          skip_whitespace()
          if !skip_comment() {
            break
          }
        }
      }

      # Read a number (integer or float)
      rule read_number() -> Token {
        let start_line = state.line
        let start_col = state.column
        let num_str = ""

        # Read integer part
        while state.position < string_len(state.source) && is_digit(peek(0)) {
          num_str = string_concat(num_str, advance())
        }

        # Read decimal part if present
        if peek(0) == "." && is_digit(peek(1)) {
          num_str = string_concat(num_str, advance())  # consume '.'
          while state.position < string_len(state.source) && is_digit(peek(0)) {
            num_str = string_concat(num_str, advance())
          }
        }

        return Token {
          type: "NUMBER",
          value: num_str,
          line: start_line,
          column: start_col
        }
      }

      # Read a string literal
      rule read_string(quote: string) -> Token {
        let start_line = state.line
        let start_col = state.column
        let str_val = ""

        advance()  # consume opening quote

        while state.position < string_len(state.source) && peek(0) != quote {
          if peek(0) == "\\" {
            advance()  # consume backslash
            let next_ch = advance()
            if next_ch == "n" {
              str_val = string_concat(str_val, "\n")
            } else if next_ch == "t" {
              str_val = string_concat(str_val, "\t")
            } else if next_ch == "r" {
              str_val = string_concat(str_val, "\r")
            } else if next_ch == "\\" {
              str_val = string_concat(str_val, "\\")
            } else if next_ch == "\"" {
              str_val = string_concat(str_val, "\"")
            } else if next_ch == "'" {
              str_val = string_concat(str_val, "'")
            } else {
              str_val = string_concat(str_val, next_ch)
            }
          } else {
            str_val = string_concat(str_val, advance())
          }
        }

        if state.position >= string_len(state.source) {
          state.error_count = state.error_count + 1
          emit compilation_error {
            stage: "lexer",
            message: "Unterminated string literal",
            line: start_line,
            column: start_col
          }
        } else {
          advance()  # consume closing quote
        }

        return Token {
          type: "STRING_LIT",
          value: str_val,
          line: start_line,
          column: start_col
        }
      }

      # Read an identifier or keyword
      rule read_identifier() -> Token {
        let start_line = state.line
        let start_col = state.column
        let ident = ""

        while state.position < string_len(state.source) && is_alnum_or_underscore(peek(0)) {
          ident = string_concat(ident, advance())
        }

        # Check if it's a keyword
        if map_contains(state.keywords, ident) {
          return Token {
            type: map_get(state.keywords, ident),
            value: ident,
            line: start_line,
            column: start_col
          }
        }

        return Token {
          type: "IDENTIFIER",
          value: ident,
          line: start_line,
          column: start_col
        }
      }

      # Get next token
      rule next_token() -> Token {
        let start_line = state.line
        let start_col = state.column
        let ch = peek(0)

        # Numbers
        if is_digit(ch) {
          return read_number()
        }

        # Strings
        if ch == "\"" || ch == "'" {
          return read_string(ch)
        }

        # Identifiers and keywords
        if is_alpha_or_underscore(ch) {
          return read_identifier()
        }

        # Two-character operators
        let two_char = string_concat(ch, peek(1))

        if two_char == "->" {
          advance()
          advance()
          return Token { type: "ARROW", value: "->", line: start_line, column: start_col }
        }

        if two_char == "==" {
          advance()
          advance()
          return Token { type: "EQ", value: "==", line: start_line, column: start_col }
        }

        if two_char == "!=" {
          advance()
          advance()
          return Token { type: "NE", value: "!=", line: start_line, column: start_col }
        }

        if two_char == "<=" {
          advance()
          advance()
          return Token { type: "LE", value: "<=", line: start_line, column: start_col }
        }

        if two_char == ">=" {
          advance()
          advance()
          return Token { type: "GE", value: ">=", line: start_line, column: start_col }
        }

        if two_char == "&&" {
          advance()
          advance()
          return Token { type: "AND", value: "&&", line: start_line, column: start_col }
        }

        if two_char == "||" {
          advance()
          advance()
          return Token { type: "OR", value: "||", line: start_line, column: start_col }
        }

        # Single-character tokens
        advance()

        if ch == "{" {
          return Token { type: "LBRACE", value: "{", line: start_line, column: start_col }
        }
        if ch == "}" {
          return Token { type: "RBRACE", value: "}", line: start_line, column: start_col }
        }
        if ch == "(" {
          return Token { type: "LPAREN", value: "(", line: start_line, column: start_col }
        }
        if ch == ")" {
          return Token { type: "RPAREN", value: ")", line: start_line, column: start_col }
        }
        if ch == "[" {
          return Token { type: "LBRACKET", value: "[", line: start_line, column: start_col }
        }
        if ch == "]" {
          return Token { type: "RBRACKET", value: "]", line: start_line, column: start_col }
        }
        if ch == "," {
          return Token { type: "COMMA", value: ",", line: start_line, column: start_col }
        }
        if ch == ":" {
          return Token { type: "COLON", value: ":", line: start_line, column: start_col }
        }
        if ch == "." {
          return Token { type: "DOT", value: ".", line: start_line, column: start_col }
        }
        if ch == "=" {
          return Token { type: "ASSIGN", value: "=", line: start_line, column: start_col }
        }
        if ch == "+" {
          return Token { type: "PLUS", value: "+", line: start_line, column: start_col }
        }
        if ch == "-" {
          return Token { type: "MINUS", value: "-", line: start_line, column: start_col }
        }
        if ch == "*" {
          return Token { type: "STAR", value: "*", line: start_line, column: start_col }
        }
        if ch == "/" {
          return Token { type: "SLASH", value: "/", line: start_line, column: start_col }
        }
        if ch == "%" {
          return Token { type: "PERCENT", value: "%", line: start_line, column: start_col }
        }
        if ch == "<" {
          return Token { type: "LT", value: "<", line: start_line, column: start_col }
        }
        if ch == ">" {
          return Token { type: "GT", value: ">", line: start_line, column: start_col }
        }
        if ch == "!" {
          return Token { type: "NOT", value: "!", line: start_line, column: start_col }
        }
        if ch == "@" {
          return Token { type: "AT", value: "@", line: start_line, column: start_col }
        }

        # Unknown character - emit error
        state.error_count = state.error_count + 1
        emit compilation_error {
          stage: "lexer",
          message: format("Unexpected character: '{}'", ch),
          line: start_line,
          column: start_col
        }

        return Token { type: "ERROR", value: ch, line: start_line, column: start_col }
      }

      # Helper: check if character is a digit
      rule is_digit(ch: string) -> boolean {
        return ch == "0" || ch == "1" || ch == "2" || ch == "3" || ch == "4" ||
               ch == "5" || ch == "6" || ch == "7" || ch == "8" || ch == "9"
      }

      # Helper: check if character is alphabetic or underscore
      rule is_alpha_or_underscore(ch: string) -> boolean {
        return ch == "_" ||
               (ch >= "a" && ch <= "z") ||
               (ch >= "A" && ch <= "Z")
      }

      # Helper: check if character is alphanumeric or underscore
      rule is_alnum_or_underscore(ch: string) -> boolean {
        return is_alpha_or_underscore(ch) || is_digit(ch)
      }
    }
  }

  # ============================================================================
  # SECTION 4: AGENT IMPORTS
  # ============================================================================
  #
  # The following agents are imported from their respective source files.
  # Each agent is a self-contained hyphal definition that processes signals.
  #
  # Import paths:
  #   - /compiler/parser.mycelial       (1,972 lines)
  #   - /compiler/ir_generator.mycelial (1,651 lines)
  #   - /compiler/x86_codegen.mycelial  (1,230 lines)
  #   - /compiler/assembler.mycelial    (1,815 lines)
  #   - /compiler/linker.mycelial       (1,050 lines)
  #
  # Total agent code: 7,718 lines
  #
  # Note: In the Mycelial runtime, these would be imported with:
  #   import "/compiler/parser.mycelial" as parser
  #   import "/compiler/ir_generator.mycelial" as ir_generator
  #   import "/compiler/x86_codegen.mycelial" as codegen
  #   import "/compiler/assembler.mycelial" as assembler
  #   import "/compiler/linker.mycelial" as linker
  #
  # For this orchestration file, the agents are referenced by their
  # hyphal names and will be loaded by the runtime.

  # ============================================================================
  # SECTION 5: ORCHESTRATOR HYPHAL
  # ============================================================================

  hyphae {

    hyphal orchestrator {
      state {
        # Current compilation stage
        stage: string                     # Current pipeline stage

        # Input/output files
        source_file: string               # Path to source .mycelial file
        output_file: string               # Path to output binary
        source_code: string               # Loaded source code

        # Inter-agent buffers
        tokens: vec<Token>                # Buffered tokens from lexer
        token_count: u32                  # Token count

        ast_data: string                  # Serialized AST from parser
        ast_node_count: u32               # AST node count

        ir_instructions: vec<string>      # Buffered IR instructions (JSON)
        ir_function_count: u32            # Function count
        ir_struct_count: u32              # Struct count

        asm_instructions: vec<string>     # Buffered assembly instructions
        asm_instruction_count: u32        # Instruction count

        machine_code_sections: map<string, vec<u8>>  # Section -> bytes
        relocations: vec<string>          # Buffered relocations (JSON)
        symbols: map<string, u64>         # Symbol table

        elf_binary: vec<u8>               # Final ELF binary bytes

        # Progress tracking
        error_count: u32                  # Total errors
        errors: vec<string>               # Error messages

        # Timing
        start_time: u64                   # Compilation start time
        stage_times: map<string, u64>     # Per-stage timing
      }

      # Initialize orchestrator
      on rest {
        state.stage = "IDLE"
        state.error_count = 0
        state.token_count = 0
        state.ast_node_count = 0
        state.ir_function_count = 0
        state.ir_struct_count = 0
        state.asm_instruction_count = 0
        state.tokens = vec_new()
        state.ir_instructions = vec_new()
        state.asm_instructions = vec_new()
        state.machine_code_sections = map_new()
        state.relocations = vec_new()
        state.symbols = map_new()
        state.errors = vec_new()
        state.stage_times = map_new()
      }

      # --------------------------------------------------------------------------
      # Main Compilation Entry Point
      # --------------------------------------------------------------------------

      on signal(compile_request, req) {
        state.source_file = req.source_file
        state.output_file = req.output_file
        state.stage = "LEXING"
        state.start_time = time_now()
        state.error_count = 0

        report status { message: format("Compiling: {}", req.source_file) }

        # Read source file
        state.source_code = read_file(req.source_file)

        if string_len(state.source_code) == 0 {
          emit compilation_error {
            stage: "orchestrator",
            message: format("Failed to read source file: {}", req.source_file),
            line: 0,
            column: 0
          }
          state.stage = "ERROR"
          return
        }

        report status { message: "  -> Lexing..." }

        # Start lexer
        emit lex_request {
          source: state.source_code,
          filename: req.source_file
        }
      }

      # --------------------------------------------------------------------------
      # Lexer -> Parser Transition
      # --------------------------------------------------------------------------

      # Buffer tokens from lexer
      on signal(token, t) {
        vec_push(state.tokens, t)
        state.token_count = state.token_count + 1
      }

      # Lexer complete - trigger parser
      on signal(lex_complete, lc) {
        map_insert(state.stage_times, "lexing", time_now() - state.start_time)

        if lc.error_count > 0 {
          state.error_count = state.error_count + lc.error_count
          report status { message: format("  -> Lexer errors: {}", lc.error_count) }
        }

        report status { message: format("  -> Lexed {} tokens", lc.token_count) }
        report status { message: "  -> Parsing..." }

        state.stage = "PARSING"

        # Forward tokens to parser
        for tok in state.tokens {
          emit token {
            type: tok.type,
            value: tok.value,
            line: tok.line,
            column: tok.column
          }
        }

        # Signal lexer complete to parser
        emit lex_complete {
          token_count: lc.token_count,
          error_count: lc.error_count
        }
      }

      # --------------------------------------------------------------------------
      # Parser -> IR Generator Transition
      # --------------------------------------------------------------------------

      # Buffer AST nodes
      on signal(ast_node, node) {
        state.ast_node_count = state.ast_node_count + 1
      }

      # Receive complete AST
      on signal(ast_complete, ast) {
        # Store the Program object (will be serialized when needed)
        state.ast_data = format("{}", ast.program)  # Convert to string for now
        state.ast_node_count = 1  # Placeholder
      }

      # Handle parse errors
      on signal(parse_error, err) {
        state.error_count = state.error_count + 1
        vec_push(state.errors, format("Parse error at {}:{}: {} (expected {}, found {})",
          err.line, err.column, err.message, err.expected, err.found))
      }

      # Parser complete - trigger IR generator
      on signal(parse_complete, pc) {
        map_insert(state.stage_times, "parsing", time_now() - state.start_time)

        report status { message: format("  -> Parsed program") }

        if pc.error_count > 0 {
          state.error_count = state.error_count + pc.error_count
          report status { message: format("  -> Parse errors: {}", pc.error_count) }

          # Abort if too many errors
          if state.error_count > 10 {
            state.stage = "ERROR"
            emit compilation_error {
              stage: "parser",
              message: "Too many errors, aborting compilation",
              line: 0,
              column: 0
            }
            return
          }
        }

        report status { message: "  -> Generating IR..." }

        state.stage = "IR_GENERATION"

        # Forward AST to IR generator
        emit ast_complete {
          program: state.ast_data
        }
      }

      # --------------------------------------------------------------------------
      # IR Generator -> Code Generator Transition
      # --------------------------------------------------------------------------

      # Buffer IR nodes
      on signal(ir_node, node) {
        vec_push(state.ir_instructions, json_encode(node))
      }

      # Track function boundaries
      on signal(ir_function_start, fstart) {
        state.ir_function_count = state.ir_function_count + 1
        # Forward to code generator
        emit ir_function_start {
          name: fstart.name,
          params: fstart.params,
          return_type: fstart.return_type
        }
      }

      on signal(ir_function_end, fend) {
        emit ir_function_end { name: fend.name }
      }

      # Receive LIR functions (alternative format)
      on signal(lir_function, func) {
        state.ir_function_count = state.ir_function_count + 1
      }

      # Receive LIR structs
      on signal(lir_struct, st) {
        state.ir_struct_count = state.ir_struct_count + 1
      }

      # Handle IR errors
      on signal(ir_error, err) {
        state.error_count = state.error_count + 1
        vec_push(state.errors, format("IR error: {} at {}", err.message, err.location))
      }

      # IR generation complete - trigger code generator
      on signal(ir_complete, ic) {
        map_insert(state.stage_times, "ir_generation", time_now() - state.start_time)

        report status { message: format("  -> Generated {} IR instructions, {} functions, {} structs",
          ic.instruction_count, ic.function_count, ic.struct_count) }

        report status { message: "  -> Generating x86-64 code..." }

        state.stage = "CODE_GENERATION"

        # Signal IR complete to code generator
        emit ir_complete {
          instruction_count: ic.instruction_count,
          function_count: ic.function_count,
          struct_count: ic.struct_count
        }
      }

      # --------------------------------------------------------------------------
      # Code Generator -> Assembler Transition
      # --------------------------------------------------------------------------

      # Buffer assembly instructions
      on signal(asm_instruction, instr) {
        vec_push(state.asm_instructions, json_encode(instr))
        state.asm_instruction_count = state.asm_instruction_count + 1

        # Forward to assembler
        emit asm_instruction {
          label: instr.label,
          mnemonic: instr.mnemonic,
          operands: instr.operands
        }
      }

      # Buffer data directives
      on signal(asm_data, data) {
        emit asm_data {
          label: data.label,
          data_type: data.data_type,
          value: data.value
        }
      }

      # Buffer section directives
      on signal(asm_section, sect) {
        emit asm_section { name: sect.name }
      }

      # Code generation complete - trigger assembler
      on signal(codegen_complete, cc) {
        map_insert(state.stage_times, "code_generation", time_now() - state.start_time)

        report status { message: format("  -> Generated {} assembly instructions, {} functions",
          cc.instruction_count, cc.function_count) }

        report status { message: "  -> Assembling..." }

        state.stage = "ASSEMBLING"

        # Signal codegen complete to assembler
        emit codegen_complete {
          instruction_count: cc.instruction_count,
          function_count: cc.function_count
        }
      }

      # --------------------------------------------------------------------------
      # Assembler -> Linker Transition
      # --------------------------------------------------------------------------

      # Receive machine code
      on signal(machine_code, mc) {
        let section_bytes = map_get_or_default(state.machine_code_sections, mc.section, vec_new())
        let decoded_bytes = hex_decode(mc.bytes)
        for b in decoded_bytes {
          vec_push(section_bytes, b)
        }
        map_insert(state.machine_code_sections, mc.section, section_bytes)

        # Forward to linker
        emit machine_code {
          section: mc.section,
          offset: mc.offset,
          bytes: mc.bytes
        }
      }

      # Receive relocations
      on signal(relocation, rel) {
        vec_push(state.relocations, json_encode(rel))

        # Forward to linker
        emit relocation {
          section: rel.section,
          offset: rel.offset,
          symbol: rel.symbol,
          reloc_type: rel.reloc_type,
          addend: rel.addend
        }
      }

      # Receive symbol definitions
      on signal(symbol_def, sym) {
        map_insert(state.symbols, sym.name, sym.offset)

        # Forward to linker
        emit symbol_def {
          name: sym.name,
          section: sym.section,
          offset: sym.offset,
          is_global: sym.is_global
        }
      }

      # Receive section info
      on signal(section_info, info) {
        emit section_info {
          name: info.name,
          size: info.size,
          flags: info.flags
        }
      }

      # Handle assembly errors
      on signal(asm_error, err) {
        state.error_count = state.error_count + 1
        vec_push(state.errors, format("Assembly error at line {}: {} (instruction: {})",
          err.line, err.message, err.instruction))
      }

      # Assembly complete - trigger linker
      on signal(asm_complete, ac) {
        map_insert(state.stage_times, "assembling", time_now() - state.start_time)

        report status { message: format("  -> Assembled {} bytes, {} symbols, {} relocations",
          ac.total_bytes, ac.symbol_count, ac.relocation_count) }

        report status { message: "  -> Linking..." }

        state.stage = "LINKING"

        # Signal assembly complete to linker
        emit asm_complete {
          total_bytes: ac.total_bytes,
          symbol_count: ac.symbol_count,
          relocation_count: ac.relocation_count
        }
      }

      # --------------------------------------------------------------------------
      # Linker Output Handling
      # --------------------------------------------------------------------------

      # Handle link errors
      on signal(link_error, err) {
        state.error_count = state.error_count + 1
        vec_push(state.errors, format("Link error: {} (symbol: {})", err.message, err.symbol))

        state.stage = "ERROR"

        emit compilation_error {
          stage: "linker",
          message: err.message,
          line: 0,
          column: 0
        }
      }

      # Linking complete - finalize
      on signal(link_complete, lc) {
        map_insert(state.stage_times, "linking", time_now() - state.start_time)

        let total_time = time_now() - state.start_time

        state.stage = "COMPLETE"

        report status { message: format("  -> Linked: {} ({} bytes)", lc.output_file, lc.file_size) }
        report status { message: format("  -> Entry point: 0x{:X}", lc.entry_point) }
        report status { message: "" }
        report status { message: format("Compilation complete in {} ms", total_time) }

        if state.error_count == 0 {
          report status { message: format("SUCCESS: {} -> {}", state.source_file, state.output_file) }
        } else {
          report status { message: format("WARNINGS: {} errors encountered", state.error_count) }
        }

        # Emit final completion signal
        emit compilation_complete {
          output_file: lc.output_file,
          file_size: lc.file_size,
          success: state.error_count == 0
        }
      }

      # --------------------------------------------------------------------------
      # Error Handling
      # --------------------------------------------------------------------------

      on signal(compilation_error, err) {
        state.error_count = state.error_count + 1
        vec_push(state.errors, format("[{}] {}:{}: {}",
          err.stage, err.line, err.column, err.message))

        report status { message: format("ERROR [{}]: {}", err.stage, err.message) }
      }
    }
  }

  # ============================================================================
  # SECTION 6: MAIN ENTRY POINT
  # ============================================================================

  hyphae {

    hyphal main {
      state {
        default_source: string
        default_output: string
      }

      on rest {
        state.default_source = "tests/hello_world.mycelial"
        state.default_output = "hello"
      }

      # Startup signal - begin compilation
      on signal(startup, s) {
        report status { message: "" }
        report status { message: "========================================" }
        report status { message: "     MYCELIAL NATIVE COMPILER" }
        report status { message: "========================================" }
        report status { message: "" }

        # Use provided files or defaults
        let source = if s.source_file != "" { s.source_file } else { state.default_source }
        let output = if s.output_file != "" { s.output_file } else { state.default_output }

        emit compile_request {
          source_file: source,
          output_file: output
        }
      }

      # Handle compilation complete
      on signal(compilation_complete, cc) {
        report status { message: "" }

        if cc.success {
          report status { message: "========================================" }
          report status { message: "     COMPILATION SUCCESSFUL" }
          report status { message: "========================================" }
          report status { message: "" }
          report status { message: format("Output: {} ({} bytes)", cc.output_file, cc.file_size) }
          report status { message: "" }
          report status { message: "To run:" }
          report status { message: format("  chmod +x {}", cc.output_file) }
          report status { message: format("  ./{}", cc.output_file) }
        } else {
          report status { message: "========================================" }
          report status { message: "     COMPILATION FAILED" }
          report status { message: "========================================" }
        }

        report status { message: "" }
      }

      # Handle compilation errors
      on signal(compilation_error, err) {
        report status { message: format("ERROR [{}] at {}:{}: {}", err.stage, err.line, err.column, err.message) }
      }
    }
  }
  # ============================================================================
  # SECTION 6.5: COMPILER PIPELINE AGENTS
  # ============================================================================

  hyphae {
    hyphal parser {
      frequency tidal_cycle

      state {
        # Token buffer
        tokens: vec<Token>
        current: u32

        # Error tracking
        errors: vec<ParseError>
        panic_mode: boolean

        # Output
        program: Program

        # Parsing state
        in_rule_body: boolean
        current_binding: string    # Signal binding in scope
      }

      # ─────────────────────────────────────────────────────────────────────────
      # TOKEN BUFFER MANAGEMENT
      # ─────────────────────────────────────────────────────────────────────────

      on signal(token, t) {
        # Buffer tokens as they arrive
        vec_push(state.tokens, Token {
          type: t.type,
          value: t.value,
          line: t.line,
          column: t.column
        })
      }

      on signal(lex_complete, lc) {
        # All tokens received - start parsing
        state.current = 0
        state.panic_mode = false
        vec_clear(state.errors)

        # Parse the program
        let program = parse_program()

        # Emit result
        if vec_len(state.errors) == 0 {
          emit ast_complete {
            program: program
          }
        }

        emit parse_complete {
          program_id: 1,
          error_count: vec_len(state.errors)
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # TOKEN HELPERS
      # ─────────────────────────────────────────────────────────────────────────

      rule peek() -> Token {
        if state.current >= vec_len(state.tokens) {
          return Token { type: TokenType::EOF, value: "", line: 0, column: 0 }
        }
        return state.tokens[state.current]
      }

      rule peek_ahead(n: u32) -> Token {
        let idx = state.current + n
        if idx >= vec_len(state.tokens) {
          return Token { type: TokenType::EOF, value: "", line: 0, column: 0 }
        }
        return state.tokens[idx]
      }

      rule advance() -> Token {
        let tok = peek()
        if tok.type != TokenType::EOF {
          state.current = state.current + 1
        }
        return tok
      }

      rule check(expected: TokenType) -> boolean {
        return peek().type == expected
      }

      rule match_token(expected: TokenType) -> boolean {
        if check(expected) {
          advance()
          return true
        }
        return false
      }

      rule expect(expected: TokenType, message: string) -> Token {
        if check(expected) {
          return advance()
        }
        error(message, expected)
        return Token { type: TokenType::ERROR, value: "", line: peek().line, column: peek().column }
      }

      rule current_location() -> SourceLocation {
        let tok = peek()
        return SourceLocation { line: tok.line, column: tok.column }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # ERROR HANDLING
      # ─────────────────────────────────────────────────────────────────────────

      rule error(message: string, expected: TokenType) {
        let tok = peek()
        let err = ParseError {
          message: message,
          location: SourceLocation { line: tok.line, column: tok.column },
          expected: token_type_to_string(expected),
          found: tok.value
        }
        vec_push(state.errors, err)

        emit parse_error {
          message: message,
          line: tok.line,
          column: tok.column,
          expected: token_type_to_string(expected),
          found: tok.value
        }

        state.panic_mode = true
      }

      rule synchronize() {
        state.panic_mode = false
        advance()

        while !check(TokenType::EOF) {
          # Synchronize at statement boundaries
          match peek().type {
            TokenType::NETWORK | TokenType::FREQUENCY | TokenType::HYPHAL | TokenType::ON | TokenType::EMIT | TokenType::IF | TokenType::LET => {
              return
            }
            _ => {
              advance()
            }
          }
        }
      }

      rule token_type_to_string(tt: TokenType) -> string {
        match tt {
          TokenType::NETWORK => "network"
          TokenType::FREQUENCY => "frequency"
          TokenType::FREQUENCIES => "frequencies"
          TokenType::HYPHAL => "hyphal"
          TokenType::HYPHAE => "hyphae"
          TokenType::STATE => "state"
          TokenType::ON => "on"
          TokenType::SIGNAL => "signal"
          TokenType::REST => "rest"
          TokenType::CYCLE => "cycle"
          TokenType::EMIT => "emit"
          TokenType::REPORT => "report"
          TokenType::SPAWN => "spawn"
          TokenType::DIE => "die"
          TokenType::IF => "if"
          TokenType::ELSE => "else"
          TokenType::LET => "let"
          TokenType::WHERE => "where"
          TokenType::TOPOLOGY => "topology"
          TokenType::SOCKET => "socket"
          TokenType::FRUITING_BODY => "fruiting_body"
          TokenType::LBRACE => "{"
          TokenType::RBRACE => "}"
          TokenType::LPAREN => "("
          TokenType::RPAREN => ")"
          TokenType::COMMA => ","
          TokenType::COLON => ":"
          TokenType::IDENTIFIER => "identifier"
          TokenType::NUMBER => "number"
          TokenType::STRING_LIT => "string"
          TokenType::EOF => "end of file"
          _ => "token"
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # PROGRAM PARSING
      # ─────────────────────────────────────────────────────────────────────────

      rule parse_program() -> Program {
        let items: vec<ProgramItem> = vec_new()
        let loc = current_location()

        while !check(TokenType::EOF) {
          let item = parse_program_item()
          if item != Expression::None {
            vec_push(items, item)
          }

          if state.panic_mode {
            synchronize()
          }
        }

        return Program { items: items, location: loc }
      }

      rule parse_program_item() -> ProgramItem {
        match peek().type {
          TokenType::NETWORK => {
            return ProgramItem::Network(parse_network_def())
          }
          TokenType::FREQUENCY => {
            return ProgramItem::Frequency(parse_frequency_def())
          }
          TokenType::IMPORT => {
            return ProgramItem::Import(parse_import_def())
          }
          _ => {
            error("Expected 'network', 'frequency', or 'import'", TokenType::NETWORK)
            return Expression::None
          }
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # NETWORK PARSING
      # ─────────────────────────────────────────────────────────────────────────

      rule parse_network_def() -> NetworkDef {
        let loc = current_location()
        expect(TokenType::NETWORK, "Expected 'network'")

        let name_tok = expect(TokenType::IDENTIFIER, "Expected network name")
        let name = name_tok.value

        expect(TokenType::LBRACE, "Expected '{' after network name")

        let frequencies: vec<FrequencyDef> = vec_new()
        let types: vec<TypeDef> = vec_new()
        let constants: vec<ConstantDef> = vec_new()
        let hyphae: vec<HyphalDef> = vec_new()
        let topology: vec<TopologyItem> = vec_new()
        let config: vec<ConfigItem> = vec_new()

        while !check(TokenType::RBRACE) && !check(TokenType::EOF) {
          match peek().type {
            TokenType::FREQUENCIES => {
              advance()
              expect(TokenType::LBRACE, "Expected '{' after 'frequencies'")
              while !check(TokenType::RBRACE) && !check(TokenType::EOF) {
                vec_push(frequencies, parse_inline_frequency_def())
              }
              expect(TokenType::RBRACE, "Expected '}' to close frequencies block")
            }
            TokenType::TYPES => {
              advance()
              expect(TokenType::LBRACE, "Expected '{' after 'types'")
              while !check(TokenType::RBRACE) && !check(TokenType::EOF) {
                vec_push(types, parse_type_def())
              }
              expect(TokenType::RBRACE, "Expected '}' to close types block")
            }
            TokenType::CONSTANTS => {
              advance()
              expect(TokenType::LBRACE, "Expected '{' after 'constants'")
              while !check(TokenType::RBRACE) && !check(TokenType::EOF) {
                vec_push(constants, parse_constant_def())
              }
              expect(TokenType::RBRACE, "Expected '}' to close constants block")
            }
            TokenType::HYPHAE => {
              advance()
              expect(TokenType::LBRACE, "Expected '{' after 'hyphae'")
              while !check(TokenType::RBRACE) && !check(TokenType::EOF) {
                vec_push(hyphae, parse_hyphal_def())
              }
              expect(TokenType::RBRACE, "Expected '}' to close hyphae block")
            }
            TokenType::TOPOLOGY => {
              advance()
              expect(TokenType::LBRACE, "Expected '{' after 'topology'")
              while !check(TokenType::RBRACE) && !check(TokenType::EOF) {
                vec_push(topology, parse_topology_item())
              }
              expect(TokenType::RBRACE, "Expected '}' to close topology block")
            }
            TokenType::CONFIG => {
              advance()
              expect(TokenType::LBRACE, "Expected '{' after 'config'")
              while !check(TokenType::RBRACE) && !check(TokenType::EOF) {
                vec_push(config, parse_config_item())
              }
              expect(TokenType::RBRACE, "Expected '}' to close config block")
            }
            _ => {
              error("Unexpected token in network definition", TokenType::RBRACE)
              advance()
            }
          }
        }

        expect(TokenType::RBRACE, "Expected '}' to close network")

        return NetworkDef {
          name: name,
          frequencies: frequencies,
          types: types,
          constants: constants,
          hyphae: hyphae,
          topology: topology,
          config: config,
          location: loc
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # FREQUENCY PARSING
      # ─────────────────────────────────────────────────────────────────────────

      rule parse_frequency_def() -> FrequencyDef {
        let loc = current_location()
        expect(TokenType::FREQUENCY, "Expected 'frequency'")

        let name_tok = expect(TokenType::IDENTIFIER, "Expected frequency name")
        let name = name_tok.value

        expect(TokenType::LBRACE, "Expected '{' after frequency name")

        let fields: vec<FieldDef> = vec_new()
        while !check(TokenType::RBRACE) && !check(TokenType::EOF) {
          vec_push(fields, parse_field_def())
        }

        expect(TokenType::RBRACE, "Expected '}' to close frequency")

        return FrequencyDef {
          name: name,
          fields: fields,
          location: loc
        }
      }

      rule parse_inline_frequency_def() -> FrequencyDef {
        let loc = current_location()

        let name_tok = expect(TokenType::IDENTIFIER, "Expected frequency name")
        let name = name_tok.value

        expect(TokenType::LBRACE, "Expected '{' after frequency name")

        let fields: vec<FieldDef> = vec_new()
        while !check(TokenType::RBRACE) && !check(TokenType::EOF) {
          vec_push(fields, parse_field_def())
        }

        expect(TokenType::RBRACE, "Expected '}' to close frequency")

        return FrequencyDef {
          name: name,
          fields: fields,
          location: loc
        }
      }

      rule parse_field_def() -> FieldDef {
        let loc = current_location()

        let name_tok = expect(TokenType::IDENTIFIER, "Expected field name")
        let name = name_tok.value

        expect(TokenType::COLON, "Expected ':' after field name")

        let field_type = parse_type_ref()

        return FieldDef {
          name: name,
          field_type: field_type,
          location: loc
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # TYPE PARSING
      # ─────────────────────────────────────────────────────────────────────────

      rule parse_type_ref() -> TypeRef {
        let tok = peek()

        match tok.value {
          "u8" => { advance(); return TypeRef::Primitive(PrimitiveType::U8) }
          "u16" => { advance(); return TypeRef::Primitive(PrimitiveType::U16) }
          "u32" => { advance(); return TypeRef::Primitive(PrimitiveType::U32) }
          "u64" => { advance(); return TypeRef::Primitive(PrimitiveType::U64) }
          "i8" => { advance(); return TypeRef::Primitive(PrimitiveType::I8) }
          "i16" => { advance(); return TypeRef::Primitive(PrimitiveType::I16) }
          "i32" => { advance(); return TypeRef::Primitive(PrimitiveType::I32) }
          "i64" => { advance(); return TypeRef::Primitive(PrimitiveType::I64) }
          "f32" => { advance(); return TypeRef::Primitive(PrimitiveType::F32) }
          "f64" => { advance(); return TypeRef::Primitive(PrimitiveType::F64) }
          "boolean" | "bool" => { advance(); return TypeRef::Primitive(PrimitiveType::Boolean) }
          "string" => { advance(); return TypeRef::Primitive(PrimitiveType::String) }
          "binary" => { advance(); return TypeRef::Primitive(PrimitiveType::Binary) }
          "vec" => {
            advance()
            expect(TokenType::LT, "Expected '<' after 'vec'")
            let inner = parse_type_ref()
            expect(TokenType::GT, "Expected '>' to close vec type")
            return TypeRef::Vec(inner)
          }
          "queue" => {
            advance()
            expect(TokenType::LT, "Expected '<' after 'queue'")
            let inner = parse_type_ref()
            expect(TokenType::GT, "Expected '>' to close queue type")
            return TypeRef::Queue(inner)
          }
          "map" => {
            advance()
            expect(TokenType::LT, "Expected '<' after 'map'")
            let key = parse_type_ref()
            expect(TokenType::COMMA, "Expected ',' between map key and value types")
            let val = parse_type_ref()
            expect(TokenType::GT, "Expected '>' to close map type")
            return TypeRef::Map(key, val)
          }
          _ => {
            if tok.type == TokenType::IDENTIFIER {
              advance()
              return TypeRef::Custom(tok.value)
            }
            error("Expected type", TokenType::IDENTIFIER)
            return TypeRef::None
          }
        }
      }

      rule parse_type_def() -> TypeDef {
        let loc = current_location()

        if check(TokenType::STRUCT) {
          advance()
          let name_tok = expect(TokenType::IDENTIFIER, "Expected struct name")
          expect(TokenType::LBRACE, "Expected '{' after struct name")

          let fields: vec<FieldDef> = vec_new()
          while !check(TokenType::RBRACE) && !check(TokenType::EOF) {
            vec_push(fields, parse_field_def())
          }
          expect(TokenType::RBRACE, "Expected '}' to close struct")

          return TypeDef {
            name: name_tok.value,
            type_kind: TypeDefKind::Struct(fields),
            location: loc
          }
        } else if check(TokenType::ENUM) {
          advance()
          let name_tok = expect(TokenType::IDENTIFIER, "Expected enum name")
          expect(TokenType::LBRACE, "Expected '{' after enum name")

          let variants: vec<EnumVariant> = vec_new()
          while !check(TokenType::RBRACE) && !check(TokenType::EOF) {
            vec_push(variants, parse_enum_variant())
            match_token(TokenType::COMMA)  # Optional comma
          }
          expect(TokenType::RBRACE, "Expected '}' to close enum")

          return TypeDef {
            name: name_tok.value,
            type_kind: TypeDefKind::Enum(variants),
            location: loc
          }
        } else {
          error("Expected 'struct' or 'enum'", TokenType::STRUCT)
          return TypeDef { name: "", type_kind: TypeDefKind::Struct(vec_new()), location: loc }
        }
      }

      rule parse_enum_variant() -> EnumVariant {
        let loc = current_location()
        let name_tok = expect(TokenType::IDENTIFIER, "Expected variant name")

        let fields: vec<FieldDef> = vec_new()
        if match_token(TokenType::LPAREN) {
          while !check(TokenType::RPAREN) && !check(TokenType::EOF) {
            vec_push(fields, parse_field_def())
            if !check(TokenType::RPAREN) {
              expect(TokenType::COMMA, "Expected ',' between variant fields")
            }
          }
          expect(TokenType::RPAREN, "Expected ')' to close variant fields")
        }

        return EnumVariant {
          name: name_tok.value,
          fields: fields,
          location: loc
        }
      }

      rule parse_constant_def() -> ConstantDef {
        let loc = current_location()
        let name_tok = expect(TokenType::IDENTIFIER, "Expected constant name")
        expect(TokenType::ASSIGN, "Expected '=' after constant name")
        let value = parse_expression()

        return ConstantDef {
          name: name_tok.value,
          value: value,
          location: loc
        }
      }

      rule parse_config_item() -> ConfigItem {
        let loc = current_location()
        let key_tok = expect(TokenType::IDENTIFIER, "Expected config key")
        expect(TokenType::COLON, "Expected ':' after config key")
        let value = parse_expression()

        return ConfigItem {
          key: key_tok.value,
          value: value,
          location: loc
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # HYPHAL PARSING
      # ─────────────────────────────────────────────────────────────────────────

      rule parse_hyphal_def() -> HyphalDef {
        let loc = current_location()
        expect(TokenType::HYPHAL, "Expected 'hyphal'")

        let name_tok = expect(TokenType::IDENTIFIER, "Expected hyphal name")
        let name = name_tok.value

        # Optional frequency reference
        let freq_ref = ""
        if match_token(TokenType::FREQUENCY) {
          let freq_tok = expect(TokenType::IDENTIFIER, "Expected frequency name")
          freq_ref = freq_tok.value
        }

        expect(TokenType::LBRACE, "Expected '{' after hyphal name")

        let state_block = StateBlock { fields: vec_new(), location: loc }
        let rules: vec<Rule> = vec_new()

        while !check(TokenType::RBRACE) && !check(TokenType::EOF) {
          match peek().type {
            TokenType::STATE => {
              state_block = parse_state_block()
            }
            TokenType::ON => {
              vec_push(rules, parse_rule())
            }
            _ => {
              error("Expected 'state' or 'on' in hyphal definition", TokenType::ON)
              advance()
            }
          }
        }

        expect(TokenType::RBRACE, "Expected '}' to close hyphal")

        return HyphalDef {
          name: name,
          frequency_ref: freq_ref,
          state: state_block,
          rules: rules,
          location: loc
        }
      }

      rule parse_state_block() -> StateBlock {
        let loc = current_location()
        expect(TokenType::STATE, "Expected 'state'")
        expect(TokenType::LBRACE, "Expected '{' after 'state'")

        let fields: vec<StateField> = vec_new()
        while !check(TokenType::RBRACE) && !check(TokenType::EOF) {
          vec_push(fields, parse_state_field())
        }

        expect(TokenType::RBRACE, "Expected '}' to close state block")

        return StateBlock { fields: fields, location: loc }
      }

      rule parse_state_field() -> StateField {
        let loc = current_location()
        let name_tok = expect(TokenType::IDENTIFIER, "Expected field name")
        expect(TokenType::COLON, "Expected ':' after field name")
        let field_type = parse_type_ref()

        let init_value = Expression::None
        if match_token(TokenType::ASSIGN) {
          init_value = parse_expression()
        }

        return StateField {
          name: name_tok.value,
          field_type: field_type,
          init_value: init_value,
          location: loc
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # RULE PARSING
      # ─────────────────────────────────────────────────────────────────────────

      rule parse_rule() -> Rule {
        let loc = current_location()
        expect(TokenType::ON, "Expected 'on'")

        let trigger = parse_rule_trigger()

        # Optional guard
        let guard = Expression::None
        if match_token(TokenType::WHERE) {
          guard = parse_expression()
        }

        expect(TokenType::LBRACE, "Expected '{' after rule trigger")

        state.in_rule_body = true
        let body = parse_statement_list()
        state.in_rule_body = false

        expect(TokenType::RBRACE, "Expected '}' to close rule")

        return Rule {
          trigger: trigger,
          guard: guard,
          body: body,
          location: loc
        }
      }

      rule parse_rule_trigger() -> RuleTrigger {
        match peek().type {
          TokenType::SIGNAL => {
            advance()
            expect(TokenType::LPAREN, "Expected '(' after 'signal'")

            let freq_tok = expect(TokenType::IDENTIFIER, "Expected frequency name")
            let frequency = freq_tok.value

            let binding = ""
            if match_token(TokenType::COMMA) {
              let binding_tok = expect(TokenType::IDENTIFIER, "Expected binding name")
              binding = binding_tok.value
              state.current_binding = binding
            }

            expect(TokenType::RPAREN, "Expected ')' to close signal pattern")

            return RuleTrigger::Signal(SignalMatch {
              frequency: frequency,
              binding: binding,
              location: current_location()
            })
          }
          TokenType::REST => {
            advance()
            return RuleTrigger::Rest
          }
          TokenType::CYCLE => {
            advance()
            let num_tok = expect(TokenType::NUMBER, "Expected cycle number")
            let num = parse_i64(num_tok.value)
            return RuleTrigger::Cycle(num as u32)
          }
          _ => {
            error("Expected 'signal', 'rest', or 'cycle'", TokenType::SIGNAL)
            return RuleTrigger::Rest
          }
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # TOPOLOGY PARSING
      # ─────────────────────────────────────────────────────────────────────────

      rule parse_topology_item() -> TopologyItem {
        match peek().type {
          TokenType::SPAWN => {
            return TopologyItem::Spawn(parse_spawn_def())
          }
          TokenType::SOCKET => {
            return TopologyItem::Socket(parse_socket_def())
          }
          TokenType::FRUITING_BODY => {
            return TopologyItem::FruitingBody(parse_fruiting_body_def())
          }
          _ => {
            error("Expected 'spawn', 'socket', or 'fruiting_body'", TokenType::SPAWN)
            advance()
            return TopologyItem::FruitingBody(FruitingBodyDef { name: "", location: current_location() })
          }
        }
      }

      rule parse_spawn_def() -> SpawnDef {
        let loc = current_location()
        expect(TokenType::SPAWN, "Expected 'spawn'")

        let hyphal_tok = expect(TokenType::IDENTIFIER, "Expected hyphal name")
        expect(TokenType::IDENTIFIER, "Expected 'as'")  # "as" keyword
        let instance_tok = expect(TokenType::IDENTIFIER, "Expected instance name")

        return SpawnDef {
          hyphal: hyphal_tok.value,
          instance: instance_tok.value,
          location: loc
        }
      }

      rule parse_socket_def() -> SocketDef {
        let loc = current_location()
        expect(TokenType::SOCKET, "Expected 'socket'")

        let from_tok = expect(TokenType::IDENTIFIER, "Expected source name")
        expect(TokenType::ARROW, "Expected '->' in socket definition")
        let to_tok = expect(TokenType::IDENTIFIER, "Expected destination name")

        let frequency = ""
        if match_token(TokenType::LPAREN) {
          expect(TokenType::IDENTIFIER, "Expected 'frequency'")  # "frequency" keyword
          expect(TokenType::COLON, "Expected ':' after 'frequency'")
          let freq_tok = expect(TokenType::IDENTIFIER, "Expected frequency name")
          frequency = freq_tok.value
          expect(TokenType::RPAREN, "Expected ')' to close socket options")
        }

        return SocketDef {
          from: from_tok.value,
          to: to_tok.value,
          frequency: frequency,
          location: loc
        }
      }

      rule parse_fruiting_body_def() -> FruitingBodyDef {
        let loc = current_location()
        expect(TokenType::FRUITING_BODY, "Expected 'fruiting_body'")

        let name_tok = expect(TokenType::IDENTIFIER, "Expected fruiting body name")

        return FruitingBodyDef {
          name: name_tok.value,
          location: loc
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # IMPORT PARSING
      # ─────────────────────────────────────────────────────────────────────────

      rule parse_import_def() -> ImportDef {
        let loc = current_location()
        expect(TokenType::IMPORT, "Expected 'import'")

        let path_tok = expect(TokenType::IDENTIFIER, "Expected import path")

        return ImportDef {
          path: path_tok.value,
          location: loc
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # STATEMENT PARSING
      # ─────────────────────────────────────────────────────────────────────────

      rule parse_statement_list() -> vec<Statement> {
        let statements: vec<Statement> = vec_new()

        while !check(TokenType::RBRACE) && !check(TokenType::EOF) {
          let stmt = parse_statement()
          if stmt != Statement::None {
            vec_push(statements, stmt)
          }

          if state.panic_mode {
            synchronize()
          }
        }

        return statements
      }

      rule parse_statement() -> Statement {
        match peek().type {
          TokenType::LET => {
            return Statement::Let(parse_let_statement())
          }
          TokenType::IF => {
            return Statement::Conditional(parse_conditional_statement())
          }
          TokenType::EMIT => {
            return Statement::Emit(parse_emit_statement())
          }
          TokenType::REPORT => {
            return Statement::Report(parse_report_statement())
          }
          TokenType::SPAWN => {
            return Statement::Spawn(parse_spawn_statement())
          }
          TokenType::DIE => {
            return Statement::Die(parse_die_statement())
          }
          TokenType::IDENTIFIER => {
            # Could be assignment or expression statement
            return parse_assignment_or_expression()
          }
          _ => {
            # Try to parse as expression statement
            let expr = parse_expression()
            if expr != Expression::None {
              return Statement::Expression(ExpressionStatement {
                expression: expr,
                location: current_location()
              })
            }
            return Statement::None
          }
        }
      }

      rule parse_let_statement() -> LetStatement {
        let loc = current_location()
        expect(TokenType::LET, "Expected 'let'")

        let name_tok = expect(TokenType::IDENTIFIER, "Expected variable name")

        # Optional type annotation
        let type_annotation = TypeRef::None
        if match_token(TokenType::COLON) {
          type_annotation = parse_type_ref()
        }

        expect(TokenType::ASSIGN, "Expected '=' after variable name")
        let value = parse_expression()

        return LetStatement {
          name: name_tok.value,
          type_annotation: type_annotation,
          value: value,
          location: loc
        }
      }

      rule parse_conditional_statement() -> ConditionalStatement {
        let loc = current_location()
        expect(TokenType::IF, "Expected 'if'")

        let condition = parse_expression()
        expect(TokenType::LBRACE, "Expected '{' after condition")
        let then_body = parse_statement_list()
        expect(TokenType::RBRACE, "Expected '}' to close then branch")

        let else_body: vec<Statement> = vec_new()
        if match_token(TokenType::ELSE) {
          if check(TokenType::IF) {
            # else if
            let nested = parse_conditional_statement()
            vec_push(else_body, Statement::Conditional(nested))
          } else {
            expect(TokenType::LBRACE, "Expected '{' after 'else'")
            else_body = parse_statement_list()
            expect(TokenType::RBRACE, "Expected '}' to close else branch")
          }
        }

        return ConditionalStatement {
          condition: condition,
          then_body: then_body,
          else_body: else_body,
          location: loc
        }
      }

      rule parse_emit_statement() -> EmitStatement {
        let loc = current_location()
        expect(TokenType::EMIT, "Expected 'emit'")

        let freq_tok = expect(TokenType::IDENTIFIER, "Expected frequency name")
        expect(TokenType::LBRACE, "Expected '{' after frequency name")

        let fields: vec<FieldInit> = vec_new()
        while !check(TokenType::RBRACE) && !check(TokenType::EOF) {
          vec_push(fields, parse_field_init())
          if !check(TokenType::RBRACE) {
            match_token(TokenType::COMMA)  # Optional comma
          }
        }

        expect(TokenType::RBRACE, "Expected '}' to close emit")

        return EmitStatement {
          frequency: freq_tok.value,
          fields: fields,
          location: loc
        }
      }

      rule parse_field_init() -> FieldInit {
        let loc = current_location()
        let name_tok = expect(TokenType::IDENTIFIER, "Expected field name")
        expect(TokenType::COLON, "Expected ':' after field name")
        let value = parse_expression()

        return FieldInit {
          name: name_tok.value,
          value: value,
          location: loc
        }
      }

      rule parse_report_statement() -> ReportStatement {
        let loc = current_location()
        expect(TokenType::REPORT, "Expected 'report'")

        let metric_tok = expect(TokenType::IDENTIFIER, "Expected metric name")
        expect(TokenType::COLON, "Expected ':' after metric name")
        let value = parse_expression()

        return ReportStatement {
          metric: metric_tok.value,
          value: value,
          location: loc
        }
      }

      rule parse_spawn_statement() -> SpawnStatement {
        let loc = current_location()
        expect(TokenType::SPAWN, "Expected 'spawn'")

        let hyphal_tok = expect(TokenType::IDENTIFIER, "Expected hyphal name")
        expect(TokenType::IDENTIFIER, "Expected 'as'")  # "as" keyword
        let instance_tok = expect(TokenType::IDENTIFIER, "Expected instance name")

        return SpawnStatement {
          hyphal: hyphal_tok.value,
          instance: instance_tok.value,
          location: loc
        }
      }

      rule parse_die_statement() -> DieStatement {
        let loc = current_location()
        expect(TokenType::DIE, "Expected 'die'")
        return DieStatement { location: loc }
      }

      rule parse_assignment_or_expression() -> Statement {
        let loc = current_location()

        # Look ahead to determine if this is an assignment
        let expr = parse_expression()

        if match_token(TokenType::ASSIGN) {
          # This is an assignment
          let target = expression_to_assignment_target(expr)
          let value = parse_expression()

          return Statement::Assignment(AssignmentStatement {
            target: target,
            value: value,
            location: loc
          })
        }

        # Expression statement
        return Statement::Expression(ExpressionStatement {
          expression: expr,
          location: loc
        })
      }

      rule expression_to_assignment_target(expr: Expression) -> AssignmentTarget {
        match expr {
          Expression::Identifier(id) => {
            return AssignmentTarget::Variable(id.name)
          }
          Expression::StateAccess(sa) => {
            return AssignmentTarget::StateField(sa.field)
          }
          Expression::FieldAccess(fa) => {
            return AssignmentTarget::FieldAccess(fa.object, fa.field)
          }
          Expression::IndexAccess(ia) => {
            return AssignmentTarget::IndexAccess(ia.object, ia.index)
          }
          _ => {
            error("Invalid assignment target", TokenType::IDENTIFIER)
            return AssignmentTarget::Variable("")
          }
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # EXPRESSION PARSING (Precedence Climbing)
      # ─────────────────────────────────────────────────────────────────────────

      rule parse_expression() -> Expression {
        return parse_logical_or()
      }

      # Precedence level 1: || (lowest)
      rule parse_logical_or() -> Expression {
        let loc = current_location()
        let left = parse_logical_and()

        while match_token(TokenType::OR) {
          let right = parse_logical_and()
          left = Expression::BinaryOp(BinaryOpExpr {
            op: BinaryOperator::Or,
            left: left,
            right: right,
            location: loc
          })
        }

        return left
      }

      # Precedence level 2: &&
      rule parse_logical_and() -> Expression {
        let loc = current_location()
        let left = parse_equality()

        while match_token(TokenType::AND) {
          let right = parse_equality()
          left = Expression::BinaryOp(BinaryOpExpr {
            op: BinaryOperator::And,
            left: left,
            right: right,
            location: loc
          })
        }

        return left
      }

      # Precedence level 3: == !=
      rule parse_equality() -> Expression {
        let loc = current_location()
        let left = parse_relational()

        while true {
          if match_token(TokenType::EQ) {
            let right = parse_relational()
            left = Expression::BinaryOp(BinaryOpExpr {
              op: BinaryOperator::Eq,
              left: left,
              right: right,
              location: loc
            })
          } else if match_token(TokenType::NE) {
            let right = parse_relational()
            left = Expression::BinaryOp(BinaryOpExpr {
              op: BinaryOperator::Ne,
              left: left,
              right: right,
              location: loc
            })
          } else {
            break
          }
        }

        return left
      }

      # Precedence level 4: < > <= >=
      rule parse_relational() -> Expression {
        let loc = current_location()
        let left = parse_additive()

        while true {
          if match_token(TokenType::LT) {
            let right = parse_additive()
            left = Expression::BinaryOp(BinaryOpExpr {
              op: BinaryOperator::Lt,
              left: left,
              right: right,
              location: loc
            })
          } else if match_token(TokenType::GT) {
            let right = parse_additive()
            left = Expression::BinaryOp(BinaryOpExpr {
              op: BinaryOperator::Gt,
              left: left,
              right: right,
              location: loc
            })
          } else if match_token(TokenType::LE) {
            let right = parse_additive()
            left = Expression::BinaryOp(BinaryOpExpr {
              op: BinaryOperator::Le,
              left: left,
              right: right,
              location: loc
            })
          } else if match_token(TokenType::GE) {
            let right = parse_additive()
            left = Expression::BinaryOp(BinaryOpExpr {
              op: BinaryOperator::Ge,
              left: left,
              right: right,
              location: loc
            })
          } else {
            break
          }
        }

        return left
      }

      # Precedence level 5: + -
      rule parse_additive() -> Expression {
        let loc = current_location()
        let left = parse_multiplicative()

        while true {
          if match_token(TokenType::PLUS) {
            let right = parse_multiplicative()
            left = Expression::BinaryOp(BinaryOpExpr {
              op: BinaryOperator::Add,
              left: left,
              right: right,
              location: loc
            })
          } else if match_token(TokenType::MINUS) {
            let right = parse_multiplicative()
            left = Expression::BinaryOp(BinaryOpExpr {
              op: BinaryOperator::Sub,
              left: left,
              right: right,
              location: loc
            })
          } else {
            break
          }
        }

        return left
      }

      # Precedence level 6: * / %
      rule parse_multiplicative() -> Expression {
        let loc = current_location()
        let left = parse_unary()

        while true {
          if match_token(TokenType::STAR) {
            let right = parse_unary()
            left = Expression::BinaryOp(BinaryOpExpr {
              op: BinaryOperator::Mul,
              left: left,
              right: right,
              location: loc
            })
          } else if match_token(TokenType::SLASH) {
            let right = parse_unary()
            left = Expression::BinaryOp(BinaryOpExpr {
              op: BinaryOperator::Div,
              left: left,
              right: right,
              location: loc
            })
          } else if match_token(TokenType::PERCENT) {
            let right = parse_unary()
            left = Expression::BinaryOp(BinaryOpExpr {
              op: BinaryOperator::Mod,
              left: left,
              right: right,
              location: loc
            })
          } else {
            break
          }
        }

        return left
      }

      # Precedence level 7: ! - + (unary)
      rule parse_unary() -> Expression {
        let loc = current_location()

        if match_token(TokenType::NOT) {
          let operand = parse_unary()
          return Expression::UnaryOp(UnaryOpExpr {
            op: UnaryOperator::Not,
            operand: operand,
            location: loc
          })
        }

        if match_token(TokenType::MINUS) {
          let operand = parse_unary()
          return Expression::UnaryOp(UnaryOpExpr {
            op: UnaryOperator::Neg,
            operand: operand,
            location: loc
          })
        }

        if match_token(TokenType::PLUS) {
          let operand = parse_unary()
          return Expression::UnaryOp(UnaryOpExpr {
            op: UnaryOperator::Pos,
            operand: operand,
            location: loc
          })
        }

        return parse_postfix()
      }

      # Precedence level 8: postfix (. [] () - highest)
      rule parse_postfix() -> Expression {
        let expr = parse_primary()

        while true {
          if match_token(TokenType::DOT) {
            let loc = current_location()
            let field_tok = expect(TokenType::IDENTIFIER, "Expected field name after '.'")

            # Check if it's a method call
            if check(TokenType::LPAREN) {
              advance()
              let args = parse_argument_list()
              expect(TokenType::RPAREN, "Expected ')' after method arguments")

              expr = Expression::MethodCall(MethodCallExpr {
                object: expr,
                method: field_tok.value,
                args: args,
                location: loc
              })
            } else {
              expr = Expression::FieldAccess(FieldAccessExpr {
                object: expr,
                field: field_tok.value,
                location: loc
              })
            }
          } else if match_token(TokenType::LBRACKET) {
            let loc = current_location()
            let index = parse_expression()
            expect(TokenType::RBRACKET, "Expected ']' after index")

            expr = Expression::IndexAccess(IndexAccessExpr {
              object: expr,
              index: index,
              location: loc
            })
          } else if match_token(TokenType::LPAREN) {
            # Function call on identifier
            match expr {
              Expression::Identifier(id) => {
                let loc = id.location
                let args = parse_argument_list()
                expect(TokenType::RPAREN, "Expected ')' after arguments")

                expr = Expression::Call(CallExpr {
                  name: id.name,
                  args: args,
                  location: loc
                })
              }
              _ => {
                error("Expected function name", TokenType::IDENTIFIER)
              }
            }
          } else {
            break
          }
        }

        return expr
      }

      rule parse_argument_list() -> vec<Expression> {
        let args: vec<Expression> = vec_new()

        if !check(TokenType::RPAREN) {
          vec_push(args, parse_expression())

          while match_token(TokenType::COMMA) {
            vec_push(args, parse_expression())
          }
        }

        return args
      }

      # Primary expressions (literals, identifiers, grouped)
      rule parse_primary() -> Expression {
        let loc = current_location()
        let tok = peek()

        match tok.type {
          TokenType::NUMBER => {
            advance()
            let value = parse_number(tok.value)
            return Expression::Literal(LiteralExpr {
              value: value,
              location: loc
            })
          }
          TokenType::STRING_LIT => {
            advance()
            return Expression::Literal(LiteralExpr {
              value: Literal::String(tok.value),
              location: loc
            })
          }
          TokenType::TRUE => {
            advance()
            return Expression::Literal(LiteralExpr {
              value: Literal::Bool(true),
              location: loc
            })
          }
          TokenType::FALSE => {
            advance()
            return Expression::Literal(LiteralExpr {
              value: Literal::Bool(false),
              location: loc
            })
          }
          TokenType::IDENTIFIER => {
            advance()

            # Check for state access: state.field
            if tok.value == "state" && check(TokenType::DOT) {
              advance()  # consume '.'
              let field_tok = expect(TokenType::IDENTIFIER, "Expected field name after 'state.'")
              return Expression::StateAccess(StateAccessExpr {
                field: field_tok.value,
                location: loc
              })
            }

            # Check for signal binding access
            if tok.value == state.current_binding && check(TokenType::DOT) {
              advance()  # consume '.'
              let field_tok = expect(TokenType::IDENTIFIER, "Expected field name")
              return Expression::SignalAccess(SignalAccessExpr {
                binding: tok.value,
                field: field_tok.value,
                location: loc
              })
            }

            # Check for struct literal: TypeName { ... }
            if check(TokenType::LBRACE) {
              advance()
              let fields: vec<FieldInit> = vec_new()
              while !check(TokenType::RBRACE) && !check(TokenType::EOF) {
                vec_push(fields, parse_field_init())
                if !check(TokenType::RBRACE) {
                  match_token(TokenType::COMMA)
                }
              }
              expect(TokenType::RBRACE, "Expected '}' to close struct literal")

              return Expression::StructLiteral(StructLiteralExpr {
                type_name: tok.value,
                fields: fields,
                location: loc
              })
            }

            return Expression::Identifier(IdentifierExpr {
              name: tok.value,
              location: loc
            })
          }
          TokenType::LPAREN => {
            advance()
            let inner = parse_expression()
            expect(TokenType::RPAREN, "Expected ')' after expression")
            return Expression::Grouped(GroupedExpr {
              inner: inner,
              location: loc
            })
          }
          TokenType::LBRACKET => {
            # List literal
            advance()
            let elements: vec<Expression> = vec_new()
            while !check(TokenType::RBRACKET) && !check(TokenType::EOF) {
              vec_push(elements, parse_expression())
              if !check(TokenType::RBRACKET) {
                expect(TokenType::COMMA, "Expected ',' between list elements")
              }
            }
            expect(TokenType::RBRACKET, "Expected ']' to close list")

            return Expression::ListLiteral(ListLiteralExpr {
              elements: elements,
              location: loc
            })
          }
          _ => {
            error("Expected expression", TokenType::IDENTIFIER)
            return Expression::None
          }
        }
      }

      rule parse_number(s: string) -> Literal {
        if string_contains(s, ".") {
          return Literal::Float(parse_f64(s))
        }
        return Literal::Number(parse_i64(s))
      }
    }

    hyphal ir_generator {
      state {
        # Input
        program: Program

        # IR generation context
        context: IRGenContext

        # Output tracking
        functions_emitted: u32
        structs_emitted: u32
        errors: vec<string>

        # Current lowering state
        current_basic_blocks: vec<BasicBlock>
        current_instructions: vec<Instruction>
        current_terminator: Terminator
      }

      on signal(ast_complete, ast) {
        # Store AST program
        state.program = ast.program

        # Initialize IR generation context
        state.context = IRGenContext {
          current_function: "",
          current_hyphal: "",
          current_trigger_frequency: "",
          temp_counter: 0,
          label_counter: 0,
          signal_counter: 0,
          payload_counter: 0,
          current_agent_id: 0,
          frequency_map: map_new(),
          struct_layouts: map_new(),
          local_vars: map_new()
        }

        # Reset counters
        state.functions_emitted = 0
        state.structs_emitted = 0
        vec_clear(state.errors)

        # Phase 1: Build frequency ID map
        build_frequency_map()

        # Phase 2: Calculate struct layouts
        calculate_all_layouts()

        # Phase 3: Lower all hyphae to functions
        lower_all_hyphae()

        # Emit completion
        emit ir_complete {
          function_count: state.functions_emitted,
          struct_count: state.structs_emitted
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # PHASE 1: Build Frequency Map
      # ─────────────────────────────────────────────────────────────────────────

      rule build_frequency_map() {
        let freq_id: u32 = 1

        # Iterate through all program items
        for item: ProgramItem in state.program.items {
          match item {
            ProgramItem::Frequency(freq_def) => {
              map_insert(state.context.frequency_map, freq_def.name, freq_id)
              freq_id = freq_id + 1
            }
            ProgramItem::Network(net_def) => {
              for freq: FrequencyDef in net_def.frequencies {
                map_insert(state.context.frequency_map, freq.name, freq_id)
                freq_id = freq_id + 1
              }
            }
            _ => {}
          }
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # PHASE 2: Calculate Struct Layouts
      # ─────────────────────────────────────────────────────────────────────────

      rule calculate_all_layouts() {
        # Calculate layouts for all frequencies (signal structs)
        for item: ProgramItem in state.program.items {
          match item {
            ProgramItem::Frequency(freq_def) => {
              let layout: StructLayout = calculate_struct_layout(freq_def.fields)
              let struct_name = format("Signal_{}", freq_def.name)
              map_insert(state.context.struct_layouts, struct_name, layout)

              # Emit struct definition
              emit_struct_def(struct_name, layout)
            }
            ProgramItem::Network(net_def) => {
              # Calculate layouts for network frequencies
              for freq: FrequencyDef in net_def.frequencies {
                let layout: StructLayout = calculate_struct_layout(freq.fields)
                let struct_name = format("Signal_{}", freq.name)
                map_insert(state.context.struct_layouts, struct_name, layout)
                emit_struct_def(struct_name, layout)
              }

              # Calculate layouts for agent state structs
              for hyphal: HyphalDef in net_def.hyphae {
                let layout: StructLayout = calculate_struct_layout_from_state(hyphal.state)
                let struct_name = format("AgentState_{}", hyphal.name)
                map_insert(state.context.struct_layouts, struct_name, layout)
                emit_struct_def(struct_name, layout)
              }
            }
            _ => {}
          }
        }
      }

      rule calculate_struct_layout(fields: vec<FieldDef>) -> StructLayout {
        let field_layouts: vec<FieldLayout> = vec_new()
        let offset: u32 = 0
        let max_alignment: u32 = 1

        # First field is freq_id (u32)
        vec_push(field_layouts, FieldLayout {
          name: "freq_id",
          offset: 0,
          size: 4,
          field_type: LIRType::I32
        })
        offset = 4
        max_alignment = 4

        # Process other fields
        for field: FieldDef in fields {
          let field_size = size_of(field.field_type)
          let field_align = align_of(field.field_type)
          max_alignment = max(max_alignment, field_align)

          # Align offset
          offset = align_up(offset, field_align)

          vec_push(field_layouts, FieldLayout {
            name: field.name,
            offset: offset,
            size: field_size,
            field_type: type_ref_to_lir(field.field_type)
          })

          offset = offset + field_size
        }

        # Align total size to max alignment
        let total_size = align_up(offset, max_alignment)

        return StructLayout {
          fields: field_layouts,
          total_size: total_size,
          alignment: max_alignment
        }
      }

      rule calculate_struct_layout_from_state(state_block: StateBlock) -> StructLayout {
        let field_layouts: vec<FieldLayout> = vec_new()
        let offset: u32 = 0
        let max_alignment: u32 = 1

        for field: StateField in state_block.fields {
          let field_size = size_of(field.field_type)
          let field_align = align_of(field.field_type)
          max_alignment = max(max_alignment, field_align)

          offset = align_up(offset, field_align)

          vec_push(field_layouts, FieldLayout {
            name: field.name,
            offset: offset,
            size: field_size,
            field_type: type_ref_to_lir(field.field_type)
          })

          offset = offset + field_size
        }

        let total_size = align_up(offset, max_alignment)

        return StructLayout {
          fields: field_layouts,
          total_size: total_size,
          alignment: max_alignment
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # Helper: Size and Alignment
      # ─────────────────────────────────────────────────────────────────────────

      rule size_of(type_ref: TypeRef) -> u32 {
        match type_ref {
          TypeRef::Primitive(prim) => {
            match prim {
              PrimitiveType::U8 | PrimitiveType::I8 | PrimitiveType::Boolean => 1
              PrimitiveType::U16 | PrimitiveType::I16 => 2
              PrimitiveType::U32 | PrimitiveType::I32 | PrimitiveType::F32 => 4
              PrimitiveType::U64 | PrimitiveType::I64 | PrimitiveType::F64 => 8
              PrimitiveType::String | PrimitiveType::Binary => 16  # ptr + len + cap
              _ => 8
            }
          }
          TypeRef::Vec(_) | TypeRef::Queue(_) | TypeRef::Map(_, _) => 16
          TypeRef::Custom(_) => 8  # Assume pointer
          _ => 8
        }
      }

      rule align_of(type_ref: TypeRef) -> u32 {
        match type_ref {
          TypeRef::Primitive(prim) => {
            match prim {
              PrimitiveType::U8 | PrimitiveType::I8 | PrimitiveType::Boolean => 1
              PrimitiveType::U16 | PrimitiveType::I16 => 2
              PrimitiveType::U32 | PrimitiveType::I32 | PrimitiveType::F32 => 4
              PrimitiveType::U64 | PrimitiveType::I64 | PrimitiveType::F64 |
              PrimitiveType::String | PrimitiveType::Binary => 8
              _ => 8
            }
          }
          TypeRef::Vec(_) | TypeRef::Queue(_) | TypeRef::Map(_, _) => 8
          TypeRef::Custom(_) => 8
          _ => 8
        }
      }

      rule align_up(offset: u32, alignment: u32) -> u32 {
        return (offset + alignment - 1) & !(alignment - 1)
      }

      rule max(a: u32, b: u32) -> u32 {
        if a > b {
          return a
        }
        return b
      }

      rule type_ref_to_lir(type_ref: TypeRef) -> LIRType {
        match type_ref {
          TypeRef::Primitive(prim) => {
            match prim {
              PrimitiveType::U8 | PrimitiveType::I8 => LIRType::I8
              PrimitiveType::U16 | PrimitiveType::I16 => LIRType::I16
              PrimitiveType::U32 | PrimitiveType::I32 | PrimitiveType::Boolean => LIRType::I32
              PrimitiveType::U64 | PrimitiveType::I64 => LIRType::I64
              PrimitiveType::F32 => LIRType::F32
              PrimitiveType::F64 => LIRType::F64
              PrimitiveType::String | PrimitiveType::Binary => LIRType::Ptr
              _ => LIRType::Ptr
            }
          }
          TypeRef::Vec(_) | TypeRef::Queue(_) | TypeRef::Map(_, _) | TypeRef::Custom(_) => LIRType::Ptr
          _ => LIRType::Ptr
        }
      }

      rule emit_struct_def(name: string, layout: StructLayout) {
        let struct_fields: vec<StructField> = vec_new()

        for field_layout: FieldLayout in layout.fields {
          vec_push(struct_fields, StructField {
            name: field_layout.name,
            offset: field_layout.offset,
            size: field_layout.size,
            field_type: field_layout.field_type
          })
        }

        emit lir_struct {
          name: name,
          fields: struct_fields,
          total_size: layout.total_size,
          alignment: layout.alignment
        }

        state.structs_emitted = state.structs_emitted + 1
      }

      # ─────────────────────────────────────────────────────────────────────────
      # PHASE 3: Lower Hyphae to Functions
      # ─────────────────────────────────────────────────────────────────────────

      rule lower_all_hyphae() {
        for item: ProgramItem in state.program.items {
          match item {
            ProgramItem::Network(net_def) => {
              for hyphal: HyphalDef in net_def.hyphae {
                lower_hyphal(hyphal)
              }
            }
            _ => {}
          }
        }
      }

      rule lower_hyphal(hyphal: HyphalDef) {
        # Generate function for each rule
        let rule_idx: u32 = 0
        for rule: Rule in hyphal.rules {
          lower_rule(hyphal.name, rule, rule_idx)
          rule_idx = rule_idx + 1
        }

        # Generate dispatch function
        generate_dispatch_function(hyphal)
      }

      rule lower_rule(hyphal_name: string, rule: Rule, rule_idx: u32) {
        # Reset function context
        state.context.temp_counter = 0
        state.context.label_counter = 0
        vec_clear(state.current_basic_blocks)
        vec_clear(state.current_instructions)
        map_clear(state.context.local_vars)

        # Set current hyphal and trigger context
        state.context.current_hyphal = hyphal_name

        # Extract trigger name and set frequency context
        # FIXME: Simplified - parser doesn't support match with enum destructuring yet
        let trigger_name = "signal_unknown"
        state.context.current_trigger_frequency = ""

        # Function name: {hyphal}_{trigger}_rule_{idx}
        let func_name = format("{}_{}_rule_{}", hyphal_name, trigger_name, rule_idx)
        state.context.current_function = func_name

        # Parameters: (state_ptr: *AgentState, signal_ptr: *Signal)
        let params: vec<Parameter> = vec_new()
        vec_push(params, Parameter { name: "state_ptr", param_type: LIRType::Ptr })
        vec_push(params, Parameter { name: "signal_ptr", param_type: LIRType::Ptr })

        # Create entry basic block
        let entry_label = fresh_label()
        start_basic_block(entry_label)

        # Lower rule body
        for stmt: Statement in rule.body {
          lower_statement(stmt)
        }

        # Add return terminator if no other terminator added
        if vec_len(state.current_instructions) > 0 {
          add_terminator(Terminator::Return(ReturnTerm { value: "" }))
          finalize_current_block()
        }

        # Emit function
        emit lir_function {
          name: func_name,
          params: params,
          return_type: LIRType::Void,
          basic_blocks: state.current_basic_blocks
        }

        state.functions_emitted = state.functions_emitted + 1
      }

      # ─────────────────────────────────────────────────────────────────────────
      # Statement Lowering
      # ─────────────────────────────────────────────────────────────────────────

      rule lower_statement(stmt: Statement) {
        match stmt {
          Statement::Let(let_stmt) => {
            lower_let_statement(let_stmt)
          }
          Statement::Assignment(assign_stmt) => {
            lower_assignment_statement(assign_stmt)
          }
          Statement::Conditional(cond_stmt) => {
            lower_conditional_statement(cond_stmt)
          }
          Statement::WhileLoop(while_stmt) => {
            lower_while_loop_statement(while_stmt)
          }
          Statement::Emit(emit_stmt) => {
            lower_emit_statement(emit_stmt)
          }
          Statement::Report(report_stmt) => {
            lower_report_statement(report_stmt)
          }
          _ => {}
        }
      }

      rule lower_let_statement(stmt: LetStatement) {
        # Lower the value expression
        let value_temp = lower_expression(stmt.value)

        # Store in local variable map
        map_insert(state.context.local_vars, stmt.name, value_temp)
      }

      rule lower_assignment_statement(stmt: AssignmentStatement) {
        match stmt.target {
          AssignmentTarget::StateField(field_name) => {
            # Lower: state.field = value
            # 1. Get field offset
            let struct_name = format("AgentState_{}", state.context.current_hyphal)
            let layout: StructLayout = map_get(state.context.struct_layouts, struct_name)
            let field_offset = get_field_offset(layout, field_name)

            # 2. Lower value expression
            let value_temp = lower_expression(stmt.value)

            # 3. Emit store_field instruction
            add_instruction(Instruction::StoreField(StoreFieldInst {
              object: "state_ptr",
              offset: field_offset,
              src: value_temp
            }))
          }
          _ => {}
        }
      }

      rule lower_conditional_statement(stmt: ConditionalStatement) {
        # Create labels
        let then_label = fresh_label()
        let else_label = fresh_label()
        let merge_label = fresh_label()

        # Lower condition
        let cond_temp = lower_expression(stmt.condition)

        # Add branch terminator
        add_terminator(Terminator::Branch(BranchTerm {
          condition: cond_temp,
          true_label: then_label,
          false_label: else_label
        }))
        finalize_current_block()

        # Then block
        start_basic_block(then_label)
        for then_stmt: Statement in stmt.then_body {
          lower_statement(then_stmt)
        }
        add_terminator(Terminator::Jump(JumpTerm { target: merge_label }))
        finalize_current_block()

        # Else block
        start_basic_block(else_label)
        for else_stmt: Statement in stmt.else_body {
          lower_statement(else_stmt)
        }
        add_terminator(Terminator::Jump(JumpTerm { target: merge_label }))
        finalize_current_block()

        # Merge block
        start_basic_block(merge_label)
      }

      rule lower_while_loop_statement(stmt: WhileLoopStatement) {
        # Create labels for loop structure
        let loop_header = fresh_label()
        let loop_body = fresh_label()
        let loop_exit = fresh_label()

        # Jump to loop header (end current block)
        add_terminator(Terminator::Jump(JumpTerm { target: loop_header }))
        finalize_current_block()

        # Loop header: evaluate condition
        start_basic_block(loop_header)
        let cond_temp = lower_expression(stmt.condition)
        add_terminator(Terminator::Branch(BranchTerm {
          condition: cond_temp,
          true_label: loop_body,
          false_label: loop_exit
        }))
        finalize_current_block()

        # Loop body: execute statements, then jump back to header
        start_basic_block(loop_body)
        for body_stmt: Statement in stmt.body {
          lower_statement(body_stmt)
        }
        add_terminator(Terminator::Jump(JumpTerm { target: loop_header }))
        finalize_current_block()

        # Loop exit: continue execution after loop
        start_basic_block(loop_exit)
      }

      rule lower_emit_statement(stmt: EmitStatement) {
        # M2 Phase 2: Updated to use signal-specific IR instructions

        # 1. Get frequency ID and layout information
        let freq_id = map_get(state.context.frequency_map, stmt.frequency)
        let struct_name = format("Signal_{}", stmt.frequency)
        let layout: StructLayout = map_get(state.context.struct_layouts, struct_name)
        let source_agent_id = get_current_agent_id()

        # 2. Allocate signal struct (32-byte header)
        let sig_var = fresh_signal_var()
        add_instruction(Instruction::SignalAlloc(SignalAllocInst {
          dst: sig_var,
          frequency_id: freq_id,
          source_agent_id: source_agent_id
        }))

        # 3. Allocate payload struct
        let payload_var = fresh_payload_var()
        add_instruction(Instruction::Alloc(AllocInst {
          dst: payload_var,
          size: layout.total_size
        }))

        # 4. Set each field in payload struct
        for field_init: FieldInit in stmt.fields {
          let field_offset = get_field_offset(layout, field_init.name)
          let value_temp = lower_expression(field_init.value)

          add_instruction(Instruction::SignalSetField(SignalSetFieldInst {
            payload: payload_var,
            field_offset: field_offset,
            value: value_temp
          }))
        }

        # 5. Attach payload to signal
        add_instruction(Instruction::SignalSetPayload(SignalSetPayloadInst {
          signal: sig_var,
          payload: payload_var,
          payload_size: layout.total_size
        }))

        # 6. Emit the signal
        add_instruction(Instruction::SignalEmit(SignalEmitInst {
          signal: sig_var,
          frequency_id: freq_id
        }))
      }

      rule lower_report_statement(stmt: ReportStatement) {
        let value_temp = lower_expression(stmt.value)
        # TODO: Call runtime_report function
      }

      # ─────────────────────────────────────────────────────────────────────────
      # Expression Lowering
      # ─────────────────────────────────────────────────────────────────────────

      rule lower_expression(expr: Expression) -> string {
        match expr {
          Expression::Literal(lit_expr) => {
            return lower_literal(lit_expr)
          }
          Expression::Identifier(id_expr) => {
            return lower_identifier(id_expr)
          }
          Expression::StateAccess(state_access) => {
            return lower_state_access(state_access)
          }
          Expression::SignalAccess(sig_access) => {
            return lower_signal_access(sig_access)
          }
          Expression::BinaryOp(bin_op) => {
            return lower_binary_op(bin_op)
          }
          Expression::Call(call_expr) => {
            return lower_call(call_expr)
          }
          Expression::FieldAccess(field_access) => {
            return lower_field_access(field_access)
          }
          Expression::Grouped(grouped) => {
            return lower_expression(grouped.inner)
          }
          Expression::UnaryOp(unary_op) => {
            return lower_unary_op(unary_op)
          }
          _ => {
            return ""
          }
        }
      }

      rule lower_unary_op(op_expr: UnaryOpExpr) -> string {
        let operand_temp = lower_expression(op_expr.operand)
        let result_temp = fresh_temp()

        match op_expr.op {
          UnaryOperator::Not => {
            add_instruction(Instruction::Not(UnaryInst {
              dst: result_temp,
              operand: operand_temp
            }))
          }
          UnaryOperator::Neg => {
            add_instruction(Instruction::Neg(UnaryInst {
              dst: result_temp,
              operand: operand_temp
            }))
          }
          UnaryOperator::Pos => {
            # Unary + is a no-op, just return operand
            return operand_temp
          }
        }

        return result_temp
      }

      rule lower_literal(lit: LiteralExpr) -> string {
        let temp = fresh_temp()

        match lit.value {
          Literal::Number(n) => {
            add_instruction(Instruction::Const(ConstInst {
              dst: temp,
              value: ConstValue::Int(n),
              const_type: LIRType::I64
            }))
          }
          Literal::Float(f) => {
            add_instruction(Instruction::Const(ConstInst {
              dst: temp,
              value: ConstValue::Float(f),
              const_type: LIRType::F64
            }))
          }
          Literal::String(s) => {
            add_instruction(Instruction::Const(ConstInst {
              dst: temp,
              value: ConstValue::String(s),
              const_type: LIRType::Ptr
            }))
          }
          Literal::Bool(b) => {
            add_instruction(Instruction::Const(ConstInst {
              dst: temp,
              value: ConstValue::Bool(b),
              const_type: LIRType::I32
            }))
          }
        }

        return temp
      }

      rule lower_identifier(id: IdentifierExpr) -> string {
        # Look up in local variables
        if map_contains_key(state.context.local_vars, id.name) {
          return map_get(state.context.local_vars, id.name)
        }

        # Unknown identifier - return empty for now
        # TODO: Error handling
        return ""
      }

      rule lower_state_access(access: StateAccessExpr) -> string {
        # state.field → load from state struct
        let struct_name = format("AgentState_{}", state.context.current_hyphal)
        let layout: StructLayout = map_get(state.context.struct_layouts, struct_name)
        let field_offset = get_field_offset(layout, access.field)

        # Get field address
        let field_addr = fresh_temp()
        add_instruction(Instruction::GetFieldAddr(GetFieldAddrInst {
          dst: field_addr,
          object: "state_ptr",
          offset: field_offset
        }))

        # Load value
        let value_temp = fresh_temp()
        add_instruction(Instruction::Load(LoadInst {
          dst: value_temp,
          addr: field_addr
        }))

        return value_temp
      }

      rule lower_signal_access(access: SignalAccessExpr) -> string {
        # g.name → load from signal struct
        # Use current trigger frequency, not binding name
        let struct_name = format("Signal_{}", state.context.current_trigger_frequency)
        let layout: StructLayout = map_get(state.context.struct_layouts, struct_name)
        let field_offset = get_field_offset(layout, access.field)

        # Get field address
        let field_addr = fresh_temp()
        add_instruction(Instruction::GetFieldAddr(GetFieldAddrInst {
          dst: field_addr,
          object: "signal_ptr",
          offset: field_offset
        }))

        # Load value
        let value_temp = fresh_temp()
        add_instruction(Instruction::Load(LoadInst {
          dst: value_temp,
          addr: field_addr
        }))

        return value_temp
      }

      rule lower_binary_op(op_expr: BinaryOpExpr) -> string {
        let lhs_temp = lower_expression(op_expr.left)
        let rhs_temp = lower_expression(op_expr.right)
        let result_temp = fresh_temp()

        match op_expr.op {
          BinaryOperator::Add => {
            add_instruction(Instruction::Add(BinaryInst {
              dst: result_temp,
              lhs: lhs_temp,
              rhs: rhs_temp
            }))
          }
          BinaryOperator::Sub => {
            add_instruction(Instruction::Sub(BinaryInst {
              dst: result_temp,
              lhs: lhs_temp,
              rhs: rhs_temp
            }))
          }
          BinaryOperator::Mul => {
            add_instruction(Instruction::Mul(BinaryInst {
              dst: result_temp,
              lhs: lhs_temp,
              rhs: rhs_temp
            }))
          }
          BinaryOperator::Div => {
            add_instruction(Instruction::Div(BinaryInst {
              dst: result_temp,
              lhs: lhs_temp,
              rhs: rhs_temp
            }))
          }
          BinaryOperator::Mod => {
            add_instruction(Instruction::Mod(BinaryInst {
              dst: result_temp,
              lhs: lhs_temp,
              rhs: rhs_temp
            }))
          }
          BinaryOperator::Eq => {
            add_instruction(Instruction::CmpEq(CompareInst {
              dst: result_temp,
              lhs: lhs_temp,
              rhs: rhs_temp
            }))
          }
          BinaryOperator::Ne => {
            add_instruction(Instruction::CmpNe(CompareInst {
              dst: result_temp,
              lhs: lhs_temp,
              rhs: rhs_temp
            }))
          }
          BinaryOperator::Lt => {
            add_instruction(Instruction::CmpLt(CompareInst {
              dst: result_temp,
              lhs: lhs_temp,
              rhs: rhs_temp
            }))
          }
          BinaryOperator::Le => {
            add_instruction(Instruction::CmpLe(CompareInst {
              dst: result_temp,
              lhs: lhs_temp,
              rhs: rhs_temp
            }))
          }
          BinaryOperator::Gt => {
            add_instruction(Instruction::CmpGt(CompareInst {
              dst: result_temp,
              lhs: lhs_temp,
              rhs: rhs_temp
            }))
          }
          BinaryOperator::Ge => {
            add_instruction(Instruction::CmpGe(CompareInst {
              dst: result_temp,
              lhs: lhs_temp,
              rhs: rhs_temp
            }))
          }
          BinaryOperator::And => {
            add_instruction(Instruction::And(BinaryInst {
              dst: result_temp,
              lhs: lhs_temp,
              rhs: rhs_temp
            }))
          }
          BinaryOperator::Or => {
            add_instruction(Instruction::Or(BinaryInst {
              dst: result_temp,
              lhs: lhs_temp,
              rhs: rhs_temp
            }))
          }
        }

        return result_temp
      }

      rule lower_call(call: CallExpr) -> string {
        # Lower all arguments
        let arg_temps: vec<string> = vec_new()
        for arg: Expression in call.args {
          let arg_temp = lower_expression(arg)
          vec_push(arg_temps, arg_temp)
        }

        # Emit call instruction
        let result_temp = fresh_temp()
        add_instruction(Instruction::Call(CallInst {
          dst: result_temp,
          func: call.name,
          args: arg_temps
        }))

        return result_temp
      }

      rule lower_field_access(access: FieldAccessExpr) -> string {
        let object_temp = lower_expression(access.object)

        # For now, assume object_temp is a struct pointer
        # TODO: Look up struct layout and get field offset
        let field_addr = fresh_temp()
        add_instruction(Instruction::GetFieldAddr(GetFieldAddrInst {
          dst: field_addr,
          object: object_temp,
          offset: 0  # TODO: Calculate actual offset
        }))

        let value_temp = fresh_temp()
        add_instruction(Instruction::Load(LoadInst {
          dst: value_temp,
          addr: field_addr
        }))

        return value_temp
      }

      # ─────────────────────────────────────────────────────────────────────────
      # Dispatch Function Generation
      # ─────────────────────────────────────────────────────────────────────────

      rule generate_dispatch_function(hyphal: HyphalDef) {
        # Generate dispatch function: {hyphal}_dispatch(state_ptr, signal_ptr)
        # This function switches on freq_id and calls appropriate rule handlers

        # Reset function context
        state.context.temp_counter = 0
        state.context.label_counter = 0
        vec_clear(state.current_basic_blocks)
        vec_clear(state.current_instructions)

        let func_name = format("{}_dispatch", hyphal.name)
        state.context.current_function = func_name
        state.context.current_hyphal = hyphal.name

        # Parameters: (state_ptr: *AgentState, signal_ptr: *Signal)
        let params: vec<Parameter> = vec_new()
        vec_push(params, Parameter { name: "state_ptr", param_type: LIRType::Ptr })
        vec_push(params, Parameter { name: "signal_ptr", param_type: LIRType::Ptr })

        # Entry block: Load freq_id from signal
        let entry_label = fresh_label()
        start_basic_block(entry_label)

        # Load freq_id (offset 0)
        let freq_id_temp = fresh_temp()
        add_instruction(Instruction::LoadField(LoadFieldInst {
          dst: freq_id_temp,
          object: "signal_ptr",
          offset: 0
        }))

        # Group rules by frequency
        let freq_rules = group_rules_by_frequency(hyphal.rules)

        # Generate branches for each frequency
        generate_frequency_dispatch(freq_rules, freq_id_temp, hyphal.name)

        # Emit function
        emit lir_function {
          name: func_name,
          params: params,
          return_type: LIRType::Void,
          basic_blocks: state.current_basic_blocks
        }

        state.functions_emitted = state.functions_emitted + 1
      }

      rule group_rules_by_frequency(rules: vec<Rule>) -> map<string, vec<Rule>> {
        let freq_map: map<string, vec<Rule>> = map_new()

        for rule in rules {
          match rule.trigger {
            RuleTrigger::Signal(sig_match) => {
              let freq_name = sig_match.frequency
              if !map_contains_key(freq_map, freq_name) {
                map_insert(freq_map, freq_name, vec_new())
              }
              let rule_list = map_get(freq_map, freq_name)
              vec_push(rule_list, rule)
              map_insert(freq_map, freq_name, rule_list)
            }
            _ => {
              # Rest and Cycle triggers handled separately
            }
          }
        }

        return freq_map
      }

      rule generate_frequency_dispatch(freq_rules: map<string, vec<Rule>>, freq_id_temp: string, hyphal_name: string) {
        # Generate switch-like structure with branches
        let no_match_label = fresh_label()

        # For each frequency, create a check and branch
        for freq_name in map_keys(freq_rules) {
          let freq_id = map_get(state.context.frequency_map, freq_name)
          let freq_check_label = fresh_label()
          let freq_handler_label = fresh_label()
          let next_check_label = fresh_label()

          # Check if freq_id matches
          let cmp_temp = fresh_temp()
          let freq_id_const = fresh_temp()
          add_instruction(Instruction::Const(ConstInst {
            dst: freq_id_const,
            value: ConstValue::Int(freq_id),
            const_type: LIRType::I32
          }))
          add_instruction(Instruction::CmpEq(CompareInst {
            dst: cmp_temp,
            lhs: freq_id_temp,
            rhs: freq_id_const
          }))

          # Branch to handler if match, otherwise check next
          add_terminator(Terminator::Branch(BranchTerm {
            condition: cmp_temp,
            true_label: freq_handler_label,
            false_label: next_check_label
          }))
          finalize_current_block()

          # Handler block: Try rules in order
          start_basic_block(freq_handler_label)
          let rules = map_get(freq_rules, freq_name)
          generate_rule_dispatch_chain(rules, hyphal_name, freq_name, no_match_label)

          # Next check block
          start_basic_block(next_check_label)
        }

        # No match - drop signal
        add_terminator(Terminator::Jump(JumpTerm { target: no_match_label }))
        finalize_current_block()

        # No match block
        start_basic_block(no_match_label)
        add_terminator(Terminator::Return(ReturnTerm { value: "" }))
        finalize_current_block()
      }

      rule generate_rule_dispatch_chain(rules: vec<Rule>, hyphal_name: string, freq_name: string, no_match_label: string) {
        let done_label = fresh_label()
        let rule_idx: u32 = 0

        for rule in rules {
          if has_guard(rule) {
            # Rule with guard - check guard first
            let guard_true_label = fresh_label()
            let guard_false_label = fresh_label()

            # Lower guard expression
            state.context.current_trigger_frequency = freq_name
            let guard_temp = lower_expression(rule.guard)

            # Branch on guard
            add_terminator(Terminator::Branch(BranchTerm {
              condition: guard_temp,
              true_label: guard_true_label,
              false_label: guard_false_label
            }))
            finalize_current_block()

            # Guard true - call rule function
            start_basic_block(guard_true_label)
            call_rule_function(hyphal_name, freq_name, rule_idx)
            add_terminator(Terminator::Jump(JumpTerm { target: done_label }))
            finalize_current_block()

            # Guard false - try next rule
            start_basic_block(guard_false_label)
          } else {
            # Rule without guard - always call
            call_rule_function(hyphal_name, freq_name, rule_idx)
            add_terminator(Terminator::Jump(JumpTerm { target: done_label }))
            finalize_current_block()
          }

          rule_idx = rule_idx + 1
        }

        # No rule matched - jump to no_match
        add_terminator(Terminator::Jump(JumpTerm { target: no_match_label }))
        finalize_current_block()

        # Done label
        start_basic_block(done_label)
        add_terminator(Terminator::Return(ReturnTerm { value: "" }))
        finalize_current_block()
      }

      rule has_guard(rule: Rule) -> boolean {
        match rule.guard {
          Expression::None => false
          _ => true
        }
      }

      rule call_rule_function(hyphal_name: string, freq_name: string, rule_idx: u32) {
        let func_name = format("{}_signal_{}_rule_{}", hyphal_name, freq_name, rule_idx)
        add_instruction(Instruction::Call(CallInst {
          dst: "",
          func: func_name,
          args: vec_from(["state_ptr", "signal_ptr"])
        }))
      }

      # ─────────────────────────────────────────────────────────────────────────
      # Helpers
      # ─────────────────────────────────────────────────────────────────────────

      rule fresh_temp() -> string {
        let temp_name = format("%tmp{}", state.context.temp_counter)
        state.context.temp_counter = state.context.temp_counter + 1
        return temp_name
      }

      rule fresh_label() -> string {
        let label_name = format("bb{}", state.context.label_counter)
        state.context.label_counter = state.context.label_counter + 1
        return label_name
      }

      # M2 Phase 2: Signal operation helper functions

      rule fresh_signal_var() -> string {
        let sig_name = format("%signal{}", state.context.signal_counter)
        state.context.signal_counter = state.context.signal_counter + 1
        return sig_name
      }

      rule fresh_payload_var() -> string {
        let payload_name = format("%payload{}", state.context.payload_counter)
        state.context.payload_counter = state.context.payload_counter + 1
        return payload_name
      }

      rule get_current_agent_id() -> u32 {
        # Return the current agent ID from context
        # In compiled code, this will be a compile-time constant
        return state.context.current_agent_id
      }

      rule get_frequency_id(frequency_name: string) -> u32 {
        # Look up frequency ID from frequency map
        let freq_id = map_get(state.context.frequency_map, frequency_name)
        if freq_id == null {
          # Frequency not found - should have been caught by type checker
          return 0
        }
        return freq_id
      }

      rule start_basic_block(label: string) {
        vec_clear(state.current_instructions)
      }

      rule add_instruction(inst: Instruction) {
        vec_push(state.current_instructions, inst)
      }

      rule add_terminator(term: Terminator) {
        # Store terminator for current block
        state.current_terminator = term
      }

      rule finalize_current_block() {
        # Add current block to function with stored terminator
        let block = BasicBlock {
          label: format("bb{}", vec_len(state.current_basic_blocks)),
          instructions: state.current_instructions,
          terminator: state.current_terminator
        }
        vec_push(state.current_basic_blocks, block)

        # Reset for next block
        vec_clear(state.current_instructions)
      }

      rule get_field_offset(layout: StructLayout, field_name: string) -> u32 {
        for field_layout: FieldLayout in layout.fields {
          if field_layout.name == field_name {
            return field_layout.offset
          }
        }
        return 0
      }

      rule vec_from(items: vec<string>) -> vec<string> {
        return items
      }
    }

    hyphal x86_codegen {
      frequency tidal_cycle

      state {
        # Buffered input
        ir_instructions: vec<IRInstruction>
        current_function: string
        current_params: vec<Parameter>
        current_return_type: Type

        # Register allocation state
        live_intervals: vec<LiveInterval>
        active_intervals: vec<LiveInterval>
        allocation: map<string, string>      # vreg -> physical reg
        spill_slots: map<string, i32>        # vreg -> stack offset
        next_spill_offset: i32

        # Output tracking
        asm_count: u32
        function_count: u32

        # Physical register pool (System V AMD64 allocatable)
        available_regs: vec<string>
        callee_saved_regs: vec<string>
        caller_saved_regs: vec<string>

        # Argument registers
        arg_regs: vec<string>
      }

      # ─────────────────────────────────────────────────────────────────────────
      # INITIALIZATION
      # ─────────────────────────────────────────────────────────────────────────

      on rest {
        # Initialize register pools (run once on first cycle)
        if vec_len(state.available_regs) == 0 {
          # Allocatable registers (10 total)
          state.available_regs = vec_from(
            "r10", "r11",     # Scratch (prefer these first)
            "rbx", "r15",     # Callee-saved
            "rax", "rcx", "rdx", "rsi", "rdi",  # Caller-saved
            "r8", "r9"        # More caller-saved
          )

          # Callee-saved (must preserve)
          state.callee_saved_regs = vec_from("rbx", "r12", "r13", "r14", "r15")

          # Caller-saved (can clobber)
          state.caller_saved_regs = vec_from(
            "rax", "rcx", "rdx", "rsi", "rdi", "r8", "r9", "r10", "r11"
          )

          # Argument passing order (System V AMD64)
          state.arg_regs = vec_from("rdi", "rsi", "rdx", "rcx", "r8", "r9")
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # SIGNAL HANDLERS - SENSE PHASE
      # ─────────────────────────────────────────────────────────────────────────

      on signal(ir_function_start, func) {
        # New function starting
        state.current_function = func.name
        state.current_params = func.params
        state.current_return_type = func.return_type

        # Reset per-function state
        vec_clear(state.ir_instructions)
        vec_clear(state.live_intervals)
        vec_clear(state.active_intervals)
        map_clear(state.allocation)
        map_clear(state.spill_slots)
        state.next_spill_offset = -8  # First spill slot at [rbp-8]
      }

      on signal(ir_node, node) {
        # Buffer IR instruction
        vec_push(state.ir_instructions, node.instruction)
      }

      on signal(ir_function_end, func) {
        # Function complete - generate code
        generate_function(func.name)
        state.function_count = state.function_count + 1
      }

      on signal(ir_complete, irc) {
        # M3 Phase 1b: Generate _start entry point that extracts argc/argv
        generate_start_function()

        # M2 Phase 5: Generate main() entry point
        generate_main_function()

        # All IR received - emit completion signal
        emit codegen_complete {
          instruction_count: state.asm_count,
          function_count: state.function_count
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # CODE GENERATION - ACT PHASE
      # ─────────────────────────────────────────────────────────────────────────

      rule generate_function(func_name: string) {
        # Phase 1: Build live intervals
        build_live_intervals()

        # Phase 2: Register allocation (linear scan)
        allocate_registers()

        # Phase 3: Emit function prologue
        emit_prologue(func_name)

        # Phase 4: Translate each IR instruction to x86-64
        let position = 0u32
        for ir_inst: IRInstruction in state.ir_instructions {
          translate_instruction(ir_inst, position)
          position = position + 1
        }

        # Phase 5: Emit function epilogue (handled by RET instruction)
      }

      # ─────────────────────────────────────────────────────────────────────────
      # LIVE INTERVAL CONSTRUCTION
      # ─────────────────────────────────────────────────────────────────────────

      rule build_live_intervals() {
        let interval_map: map<string, LiveInterval> = map_new()
        let position = 0u32

        for ir_inst: IRInstruction in state.ir_instructions {
          # Record definition (dst)
          if ir_inst.dst != "" {
            if !map_has(interval_map, ir_inst.dst) {
              # First definition - create interval
              let interval = LiveInterval {
                vreg: ir_inst.dst,
                start: position,
                end: position,
                assigned: "",
                spill_slot: -1
              }
              map_set(interval_map, ir_inst.dst, interval)
            } else {
              # Update end position
              let interval: LiveInterval = map_get(interval_map, ir_inst.dst)
              interval.end = position
              map_set(interval_map, ir_inst.dst, interval)
            }
          }

          # Record uses (src1, src2)
          for src in vec_from(ir_inst.src1, ir_inst.src2) {
            if src != "" && !is_immediate(src) && !is_label(src) {
              if map_has(interval_map, src) {
                let interval: LiveInterval = map_get(interval_map, src)
                interval.end = position
                map_set(interval_map, src, interval)
              }
            }
          }

          position = position + 1
        }

        # Convert map to sorted vector (by start position)
        # TODO: Implement sorting - for now using unsorted values
        state.live_intervals = map_values(interval_map)
      }

      # ─────────────────────────────────────────────────────────────────────────
      # REGISTER ALLOCATION (Linear Scan)
      # ─────────────────────────────────────────────────────────────────────────

      rule allocate_registers() {
        vec_clear(state.active_intervals)

        for interval: LiveInterval in state.live_intervals {
          # Expire old intervals
          expire_old_intervals(interval.start)

          # Find a free register
          let free_reg = find_free_register()

          if free_reg != "" {
            # Assign register
            interval.assigned = free_reg
            map_set(state.allocation, interval.vreg, free_reg)
            vec_push(state.active_intervals, interval)
          } else {
            # Spill - no free registers
            spill_at_interval(interval)
          }
        }
      }

      rule expire_old_intervals(current_pos: u32) {
        let new_active: vec<LiveInterval> = vec_new()

        for interval: LiveInterval in state.active_intervals {
          if interval.end >= current_pos {
            vec_push(new_active, interval)
          }
          # Expired intervals release their registers automatically
          # (they're no longer in active, so their reg becomes free)
        }

        state.active_intervals = new_active
      }

      rule find_free_register() -> string {
        let used_regs: vec<string> = vec_new()

        for interval: LiveInterval in state.active_intervals {
          if interval.assigned != "" {
            vec_push(used_regs, interval.assigned)
          }
        }

        for reg in state.available_regs {
          if !vec_contains(used_regs, reg) {
            return reg
          }
        }

        return ""  # No free register
      }

      rule spill_at_interval(interval: LiveInterval) {
        # Check if we should spill this interval or an active one
        if vec_len(state.active_intervals) == 0 {
          # Must spill current interval
          do_spill(interval)
          return
        }

        # Find the active interval that ends latest
        let spill_candidate: LiveInterval = state.active_intervals[0]
        for active: LiveInterval in state.active_intervals {
          if active.end > spill_candidate.end {
            spill_candidate = active
          }
        }

        if spill_candidate.end > interval.end {
          # Spill the longer-living active interval
          # Give its register to current interval
          interval.assigned = spill_candidate.assigned
          map_set(state.allocation, interval.vreg, interval.assigned)

          # Spill the old one
          do_spill(spill_candidate)

          # Remove old from active, add new
          vec_remove(state.active_intervals, spill_candidate)
          vec_push(state.active_intervals, interval)
        } else {
          # Spill current interval
          do_spill(interval)
        }
      }

      rule do_spill(interval: LiveInterval) {
        interval.spill_slot = state.next_spill_offset
        state.next_spill_offset = state.next_spill_offset - 8
        map_set(state.spill_slots, interval.vreg, interval.spill_slot)
      }

      # ─────────────────────────────────────────────────────────────────────────
      # FUNCTION PROLOGUE / EPILOGUE
      # ─────────────────────────────────────────────────────────────────────────

      rule emit_prologue(func_name: string) {
        # Function label
        emit asm_instruction {
          label: func_name,
          mnemonic: "",
          operands: vec_new()
        }

        # Push frame pointer
        emit asm_instruction {
          label: "",
          mnemonic: "pushq",
          operands: vec_from("%rbp")
        }

        # Set up frame pointer
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("%rsp", "%rbp")
        }

        # Allocate stack space (aligned to 16 bytes)
        let frame_size = calculate_frame_size()
        if frame_size > 0 {
          emit asm_instruction {
            label: "",
            mnemonic: "subq",
            operands: vec_from(format("${}", frame_size), "%rsp")
          }
        }

        # Save callee-saved registers we're using
        let used_callee_saved = get_used_callee_saved()
        for reg in used_callee_saved {
          let offset = get_callee_save_offset(reg)
          emit asm_instruction {
            label: "",
            mnemonic: "movq",
            operands: vec_from(format("%{}", reg), format("{}(%rbp)", offset))
          }
        }

        # Move arguments from registers to local storage if needed
        let param_idx = 0u32
        for param in state.current_params {
          if param_idx < 6 {
            let arg_reg = state.arg_regs[param_idx]
            let dst = get_operand(param.name)
            if dst != format("%{}", arg_reg) {
              emit asm_instruction {
                label: "",
                mnemonic: "movq",
                operands: vec_from(format("%{}", arg_reg), dst)
              }
            }
          }
          param_idx = param_idx + 1
        }

        state.asm_count = state.asm_count + 4 + vec_len(used_callee_saved)
      }

      rule emit_epilogue() {
        # Restore callee-saved registers
        let used_callee_saved = get_used_callee_saved()
        for reg in vec_reverse(used_callee_saved) {
          let offset = get_callee_save_offset(reg)
          emit asm_instruction {
            label: "",
            mnemonic: "movq",
            operands: vec_from(format("{}(%rbp)", offset), format("%{}", reg))
          }
        }

        # Restore stack pointer
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("%rbp", "%rsp")
        }

        # Restore frame pointer
        emit asm_instruction {
          label: "",
          mnemonic: "popq",
          operands: vec_from("%rbp")
        }

        # Return
        emit asm_instruction {
          label: "",
          mnemonic: "ret",
          operands: vec_new()
        }

        state.asm_count = state.asm_count + 3 + vec_len(used_callee_saved)
      }

      rule calculate_frame_size() -> i32 {
        # Calculate space needed:
        # - Spill slots
        # - Callee-saved registers
        # - Local variables
        # - Align to 16 bytes

        let spill_space = -(state.next_spill_offset + 8)  # Total spill bytes
        let callee_save_space = vec_len(get_used_callee_saved()) * 8
        let total = spill_space + callee_save_space

        # Align to 16 bytes
        return ((total + 15) / 16) * 16
      }

      rule get_used_callee_saved() -> vec<string> {
        let used: vec<string> = vec_new()
        for vreg, preg in state.allocation {
          if vec_contains(state.callee_saved_regs, preg) {
            if !vec_contains(used, preg) {
              vec_push(used, preg)
            }
          }
        }
        return used
      }

      rule get_callee_save_offset(reg: string) -> i32 {
        # Callee-saved registers stored after spill slots
        let used = get_used_callee_saved()
        let idx = vec_index_of(used, reg)
        return state.next_spill_offset - (idx * 8) - 8
      }

      # ─────────────────────────────────────────────────────────────────────────
      # INSTRUCTION TRANSLATION
      # ─────────────────────────────────────────────────────────────────────────

      rule translate_instruction(ir: IRInstruction, pos: u32) {
        # Emit label if present
        if ir.label != "" {
          emit asm_instruction {
            label: ir.label,
            mnemonic: "",
            operands: vec_new()
          }
        }

        # Translate based on opcode
        match ir.op {
          IROpcode::LABEL => {
            # Already handled above
          }

          IROpcode::MOVE => {
            translate_move(ir)
          }

          IROpcode::CONST => {
            translate_const(ir)
          }

          IROpcode::LOAD => {
            translate_load(ir)
          }

          IROpcode::STORE => {
            translate_store(ir)
          }

          IROpcode::LOAD_FIELD => {
            translate_load_field(ir)
          }

          IROpcode::STORE_FIELD => {
            translate_store_field(ir)
          }

          IROpcode::ADD => {
            translate_binop(ir, "addq")
          }

          IROpcode::SUB => {
            translate_binop(ir, "subq")
          }

          IROpcode::MUL => {
            translate_mul(ir)
          }

          IROpcode::DIV => {
            translate_div(ir, false)  # Quotient
          }

          IROpcode::MOD => {
            translate_div(ir, true)   # Remainder
          }

          IROpcode::NEG => {
            translate_neg(ir)
          }

          IROpcode::AND => {
            translate_binop(ir, "andq")
          }

          IROpcode::OR => {
            translate_binop(ir, "orq")
          }

          IROpcode::XOR => {
            translate_binop(ir, "xorq")
          }

          IROpcode::NOT => {
            translate_not(ir)
          }

          IROpcode::SHL => {
            translate_shift(ir, "shlq")
          }

          IROpcode::SHR => {
            translate_shift(ir, "shrq")
          }

          IROpcode::CMP_EQ => {
            translate_cmp(ir, "sete")
          }

          IROpcode::CMP_NE => {
            translate_cmp(ir, "setne")
          }

          IROpcode::CMP_LT => {
            translate_cmp(ir, "setl")
          }

          IROpcode::CMP_LE => {
            translate_cmp(ir, "setle")
          }

          IROpcode::CMP_GT => {
            translate_cmp(ir, "setg")
          }

          IROpcode::CMP_GE => {
            translate_cmp(ir, "setge")
          }

          IROpcode::JUMP => {
            translate_jump(ir)
          }

          IROpcode::BRANCH => {
            translate_branch(ir)
          }

          IROpcode::RET => {
            translate_ret(ir)
          }

          IROpcode::CALL => {
            translate_call(ir)
          }

          IROpcode::ALLOC => {
            translate_alloc(ir)
          }

          IROpcode::FREE => {
            translate_free(ir)
          }

          IROpcode::GET_FIELD_ADDR => {
            translate_get_field_addr(ir)
          }

          IROpcode::BITCAST => {
            # Bitcast is a no-op (same bits, different type)
            translate_move(ir)
          }

          IROpcode::PHI => {
            # PHI nodes handled during register allocation
            # Should have been resolved already
          }

          # M2 Phase 2: Signal operation handlers
          IROpcode::SIGNAL_ALLOC => {
            translate_signal_alloc(ir)
          }

          IROpcode::SIGNAL_SET_PAYLOAD => {
            translate_signal_set_payload(ir)
          }

          IROpcode::SIGNAL_SET_FIELD => {
            translate_signal_set_field(ir)
          }

          IROpcode::SIGNAL_EMIT => {
            translate_signal_emit(ir)
          }
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # INDIVIDUAL INSTRUCTION TRANSLATIONS
      # ─────────────────────────────────────────────────────────────────────────

      rule translate_move(ir: IRInstruction) {
        let dst = get_operand(ir.dst)
        let src = get_operand(ir.src1)

        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from(src, dst)
        }
        state.asm_count = state.asm_count + 1
      }

      rule translate_const(ir: IRInstruction) {
        let dst = get_operand(ir.dst)
        let imm = ir.src1  # Immediate value

        # Check if 64-bit immediate (needs movabs)
        if is_large_immediate(imm) {
          emit asm_instruction {
            label: "",
            mnemonic: "movabsq",
            operands: vec_from(format("${}", imm), dst)
          }
        } else {
          emit asm_instruction {
            label: "",
            mnemonic: "movq",
            operands: vec_from(format("${}", imm), dst)
          }
        }
        state.asm_count = state.asm_count + 1
      }

      rule translate_load(ir: IRInstruction) {
        let dst = get_operand(ir.dst)
        let addr = get_operand(ir.src1)

        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from(format("({})", addr), dst)
        }
        state.asm_count = state.asm_count + 1
      }

      rule translate_store(ir: IRInstruction) {
        let addr = get_operand(ir.dst)  # dst is actually the address
        let src = get_operand(ir.src1)

        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from(src, format("({})", addr))
        }
        state.asm_count = state.asm_count + 1
      }

      rule translate_load_field(ir: IRInstruction) {
        let dst = get_operand(ir.dst)
        let base = get_operand(ir.src1)
        let offset = ir.src2  # Numeric offset

        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from(format("{}({})", offset, base), dst)
        }
        state.asm_count = state.asm_count + 1
      }

      rule translate_store_field(ir: IRInstruction) {
        let base = get_operand(ir.dst)
        let offset = ir.src1  # Numeric offset
        let src = get_operand(ir.src2)

        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from(src, format("{}({})", offset, base))
        }
        state.asm_count = state.asm_count + 1
      }

      rule translate_binop(ir: IRInstruction, mnemonic: string) {
        let dst = get_operand(ir.dst)
        let lhs = get_operand(ir.src1)
        let rhs = get_operand(ir.src2)

        # x86-64 is two-address: dst = dst op src
        # So we need: mov dst, lhs; op dst, rhs
        if dst != lhs {
          emit asm_instruction {
            label: "",
            mnemonic: "movq",
            operands: vec_from(lhs, dst)
          }
          state.asm_count = state.asm_count + 1
        }

        emit asm_instruction {
          label: "",
          mnemonic: mnemonic,
          operands: vec_from(rhs, dst)
        }
        state.asm_count = state.asm_count + 1
      }

      rule translate_mul(ir: IRInstruction) {
        let dst = get_operand(ir.dst)
        let lhs = get_operand(ir.src1)
        let rhs = get_operand(ir.src2)

        # imul can use 3-operand form: imul src, dst
        # Or we use: mov rax, lhs; imul rhs; mov dst, rax
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from(lhs, "%rax")
        }

        emit asm_instruction {
          label: "",
          mnemonic: "imulq",
          operands: vec_from(rhs)
        }

        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("%rax", dst)
        }
        state.asm_count = state.asm_count + 3
      }

      rule translate_div(ir: IRInstruction, get_remainder: boolean) {
        let dst = get_operand(ir.dst)
        let lhs = get_operand(ir.src1)
        let rhs = get_operand(ir.src2)

        # idiv uses rax:rdx / src -> quotient in rax, remainder in rdx
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from(lhs, "%rax")
        }

        # Sign-extend rax to rdx:rax
        emit asm_instruction {
          label: "",
          mnemonic: "cqo",
          operands: vec_new()
        }

        emit asm_instruction {
          label: "",
          mnemonic: "idivq",
          operands: vec_from(rhs)
        }

        if get_remainder {
          emit asm_instruction {
            label: "",
            mnemonic: "movq",
            operands: vec_from("%rdx", dst)
          }
        } else {
          emit asm_instruction {
            label: "",
            mnemonic: "movq",
            operands: vec_from("%rax", dst)
          }
        }
        state.asm_count = state.asm_count + 4
      }

      rule translate_neg(ir: IRInstruction) {
        let dst = get_operand(ir.dst)
        let src = get_operand(ir.src1)

        if dst != src {
          emit asm_instruction {
            label: "",
            mnemonic: "movq",
            operands: vec_from(src, dst)
          }
          state.asm_count = state.asm_count + 1
        }

        emit asm_instruction {
          label: "",
          mnemonic: "negq",
          operands: vec_from(dst)
        }
        state.asm_count = state.asm_count + 1
      }

      rule translate_not(ir: IRInstruction) {
        let dst = get_operand(ir.dst)
        let src = get_operand(ir.src1)

        if dst != src {
          emit asm_instruction {
            label: "",
            mnemonic: "movq",
            operands: vec_from(src, dst)
          }
          state.asm_count = state.asm_count + 1
        }

        emit asm_instruction {
          label: "",
          mnemonic: "notq",
          operands: vec_from(dst)
        }
        state.asm_count = state.asm_count + 1
      }

      rule translate_shift(ir: IRInstruction, mnemonic: string) {
        let dst = get_operand(ir.dst)
        let src = get_operand(ir.src1)
        let amt = ir.src2  # Shift amount

        if dst != src {
          emit asm_instruction {
            label: "",
            mnemonic: "movq",
            operands: vec_from(src, dst)
          }
          state.asm_count = state.asm_count + 1
        }

        # Shift amount must be in cl or immediate
        if is_immediate(amt) {
          emit asm_instruction {
            label: "",
            mnemonic: mnemonic,
            operands: vec_from(format("${}", amt), dst)
          }
        } else {
          let amt_op = get_operand(amt)
          emit asm_instruction {
            label: "",
            mnemonic: "movq",
            operands: vec_from(amt_op, "%rcx")
          }
          emit asm_instruction {
            label: "",
            mnemonic: mnemonic,
            operands: vec_from("%cl", dst)
          }
          state.asm_count = state.asm_count + 1
        }
        state.asm_count = state.asm_count + 1
      }

      rule translate_cmp(ir: IRInstruction, set_instr: string) {
        let dst = get_operand(ir.dst)
        let lhs = get_operand(ir.src1)
        let rhs = get_operand(ir.src2)

        # Compare
        emit asm_instruction {
          label: "",
          mnemonic: "cmpq",
          operands: vec_from(rhs, lhs)
        }

        # Set byte based on condition
        emit asm_instruction {
          label: "",
          mnemonic: set_instr,
          operands: vec_from("%al")
        }

        # Zero-extend to 64-bit
        emit asm_instruction {
          label: "",
          mnemonic: "movzbq",
          operands: vec_from("%al", dst)
        }
        state.asm_count = state.asm_count + 3
      }

      rule translate_jump(ir: IRInstruction) {
        let target = ir.src1  # Label name

        emit asm_instruction {
          label: "",
          mnemonic: "jmp",
          operands: vec_from(target)
        }
        state.asm_count = state.asm_count + 1
      }

      rule translate_branch(ir: IRInstruction) {
        let cond = get_operand(ir.src1)
        let true_label = ir.src2
        let false_label = ir.dst  # Overloaded: dst holds false label

        # Test condition
        emit asm_instruction {
          label: "",
          mnemonic: "testq",
          operands: vec_from(cond, cond)
        }

        # Jump if not zero (condition true)
        emit asm_instruction {
          label: "",
          mnemonic: "jnz",
          operands: vec_from(true_label)
        }

        # Fall through or jump to false
        emit asm_instruction {
          label: "",
          mnemonic: "jmp",
          operands: vec_from(false_label)
        }
        state.asm_count = state.asm_count + 3
      }

      rule translate_ret(ir: IRInstruction) {
        # Move return value to rax if present
        if ir.src1 != "" {
          let ret_val = get_operand(ir.src1)
          if ret_val != "%rax" {
            emit asm_instruction {
              label: "",
              mnemonic: "movq",
              operands: vec_from(ret_val, "%rax")
            }
            state.asm_count = state.asm_count + 1
          }
        }

        # Emit epilogue
        emit_epilogue()
      }

      rule translate_call(ir: IRInstruction) {
        let dst = ir.dst
        let func_name = ir.src1
        let args = parse_args(ir.src2)  # src2 contains comma-separated args

        # Set up arguments in registers
        let arg_idx = 0u32
        for arg: Expression in args {
          if arg_idx < 6 {
            let arg_op = get_operand(arg)
            let reg = state.arg_regs[arg_idx]
            if arg_op != format("%{}", reg) {
              emit asm_instruction {
                label: "",
                mnemonic: "movq",
                operands: vec_from(arg_op, format("%{}", reg))
              }
              state.asm_count = state.asm_count + 1
            }
          } else {
            # Stack argument
            let arg_op = get_operand(arg)
            emit asm_instruction {
              label: "",
              mnemonic: "pushq",
              operands: vec_from(arg_op)
            }
            state.asm_count = state.asm_count + 1
          }
          arg_idx = arg_idx + 1
        }

        # Call function
        emit asm_instruction {
          label: "",
          mnemonic: "call",
          operands: vec_from(func_name)
        }
        state.asm_count = state.asm_count + 1

        # Clean up stack args if any
        if arg_idx > 6 {
          let stack_bytes = (arg_idx - 6) * 8
          emit asm_instruction {
            label: "",
            mnemonic: "addq",
            operands: vec_from(format("${}", stack_bytes), "%rsp")
          }
          state.asm_count = state.asm_count + 1
        }

        # Move result to destination
        if dst != "" {
          let dst_op = get_operand(dst)
          if dst_op != "%rax" {
            emit asm_instruction {
              label: "",
              mnemonic: "movq",
              operands: vec_from("%rax", dst_op)
            }
            state.asm_count = state.asm_count + 1
          }
        }
      }

      rule translate_alloc(ir: IRInstruction) {
        let dst = ir.dst
        let size = ir.src1

        # Call runtime_alloc(size)
        let size_op = get_operand(size)
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from(size_op, "%rdi")
        }

        emit asm_instruction {
          label: "",
          mnemonic: "call",
          operands: vec_from("runtime_alloc")
        }

        let dst_op = get_operand(dst)
        if dst_op != "%rax" {
          emit asm_instruction {
            label: "",
            mnemonic: "movq",
            operands: vec_from("%rax", dst_op)
          }
          state.asm_count = state.asm_count + 1
        }
        state.asm_count = state.asm_count + 2
      }

      rule translate_free(ir: IRInstruction) {
        let ptr = get_operand(ir.src1)

        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from(ptr, "%rdi")
        }

        emit asm_instruction {
          label: "",
          mnemonic: "call",
          operands: vec_from("runtime_free")
        }
        state.asm_count = state.asm_count + 2
      }

      rule translate_get_field_addr(ir: IRInstruction) {
        let dst = get_operand(ir.dst)
        let base = get_operand(ir.src1)
        let offset = ir.src2

        emit asm_instruction {
          label: "",
          mnemonic: "leaq",
          operands: vec_from(format("{}({})", offset, base), dst)
        }
        state.asm_count = state.asm_count + 1
      }

      # ─────────────────────────────────────────────────────────────────────────
      # M2 PHASE 2: SIGNAL OPERATION TRANSLATIONS
      # ─────────────────────────────────────────────────────────────────────────

      rule translate_signal_alloc(ir: IRInstruction) {
        # SIGNAL_ALLOC: Allocate 32-byte signal header
        # dst = signal variable
        # src1 = frequency_id
        # src2 = source_agent_id

        let dst = ir.dst
        let freq_id = ir.src1
        let agent_id = ir.src2

        # Allocate 32 bytes for signal struct (M2 Signal Runtime Spec)
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("$32", "%rdi")
        }

        emit asm_instruction {
          label: "",
          mnemonic: "call",
          operands: vec_from("heap_allocate")
        }

        # Save signal pointer to destination
        let dst_op = get_operand(dst)
        if dst_op != "%rax" {
          emit asm_instruction {
            label: "",
            mnemonic: "movq",
            operands: vec_from("%rax", dst_op)
          }
          state.asm_count = state.asm_count + 1
        }

        # Store frequency_id at offset 0 (u16)
        emit asm_instruction {
          label: "",
          mnemonic: "movw",
          operands: vec_from(format("${}", freq_id), format("0({})", dst_op))
        }

        # Store source_agent_id at offset 2 (u16)
        emit asm_instruction {
          label: "",
          mnemonic: "movw",
          operands: vec_from(format("${}", agent_id), format("2({})", dst_op))
        }

        # Initialize ref_count to 1 at offset 6 (u16)
        emit asm_instruction {
          label: "",
          mnemonic: "movw",
          operands: vec_from("$1", format("6({})", dst_op))
        }

        # Get timestamp (RDTSC)
        emit asm_instruction {
          label: "",
          mnemonic: "rdtsc",
          operands: vec_new()
        }

        # Combine EDX:EAX into RAX
        emit asm_instruction {
          label: "",
          mnemonic: "shlq",
          operands: vec_from("$32", "%rdx")
        }

        emit asm_instruction {
          label: "",
          mnemonic: "orq",
          operands: vec_from("%rdx", "%rax")
        }

        # Store timestamp at offset 24 (u64)
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("%rax", format("24({})", dst_op))
        }

        state.asm_count = state.asm_count + 9
      }

      rule translate_signal_set_payload(ir: IRInstruction) {
        # SIGNAL_SET_PAYLOAD: Attach payload to signal
        # src1 = signal variable
        # src2 = payload variable
        # type_size = payload size (stored in type_size field)

        let signal = get_operand(ir.src1)
        let payload = get_operand(ir.src2)
        let payload_size = ir.type_size

        # Store payload_ptr at signal offset 8 (u64)
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from(payload, format("8({})", signal))
        }

        # Store payload_size at signal offset 16 (u32)
        emit asm_instruction {
          label: "",
          mnemonic: "movl",
          operands: vec_from(format("${}", payload_size), format("16({})", signal))
        }

        # Store payload_capacity at signal offset 20 (u32)
        emit asm_instruction {
          label: "",
          mnemonic: "movl",
          operands: vec_from(format("${}", payload_size), format("20({})", signal))
        }

        state.asm_count = state.asm_count + 3
      }

      rule translate_signal_set_field(ir: IRInstruction) {
        # SIGNAL_SET_FIELD: Store field value in payload struct
        # src1 = payload variable
        # src2 = value variable
        # type_size = field offset

        let payload = get_operand(ir.src1)
        let value = get_operand(ir.src2)
        let offset = ir.type_size

        # Store value at payload + offset
        # Use 8-byte mov (assuming pointer/u64 for now)
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from(value, format("{}({})", offset, payload))
        }

        state.asm_count = state.asm_count + 1
      }

      rule translate_signal_emit(ir: IRInstruction) {
        # SIGNAL_EMIT: Route and broadcast signal
        # src1 = signal variable
        # src2 = frequency_id

        let signal = get_operand(ir.src1)
        let freq_id = ir.src2

        # Load routing table pointer into RDI (1st arg)
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("routing_table(%rip)", "%rdi")
        }

        # Load signal pointer into RSI (2nd arg)
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from(signal, "%rsi")
        }

        # Load agent registry pointer into RDX (3rd arg)
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("agent_registry(%rip)", "%rdx")
        }

        # Call routing_broadcast(routing_table, signal, agents)
        emit asm_instruction {
          label: "",
          mnemonic: "call",
          operands: vec_from("routing_broadcast")
        }

        state.asm_count = state.asm_count + 4
      }

      # ─────────────────────────────────────────────────────────────────────────
      # M2 PHASE 5: MAIN FUNCTION GENERATION
      # ─────────────────────────────────────────────────────────────────────────

      rule generate_start_function() {
        # Generate _start entry point that extracts argc/argv from stack and calls main
        # Based on M3_COMMAND_LINE_ARGS_SONNET_PROMPT.md
        #
        # Linux x86-64 stack layout at program start:
        #   [rsp + 0]  = argc
        #   [rsp + 8]  = argv[0]
        #   [rsp + 16] = argv[1]
        #   ...

        # Declare global variables for argc and argv in .data section
        emit asm_data {
          label: "argc",
          data_type: "quad",
          value: "0"
        }

        emit asm_data {
          label: "argv",
          data_type: "quad",
          value: "0"
        }

        # _start entry point label
        emit asm_instruction {
          label: "_start",
          mnemonic: "",
          operands: vec_new()
        }

        # Extract argc from stack (top of stack)
        emit asm_instruction {
          label: "",
          mnemonic: "popq",
          operands: vec_from("%rdi")
        }

        # rsp now points to argv[0], save it in %rsi
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("%rsp", "%rsi")
        }

        # Store argc in global variable
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("%rdi", "argc(%rip)")
        }

        # Store argv in global variable
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("%rsi", "argv(%rip)")
        }

        # Call main function
        emit asm_instruction {
          label: "",
          mnemonic: "call",
          operands: vec_from("main")
        }

        # Exit with return code from main (in %rax)
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("%rax", "%rdi")
        }

        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("$60", "%rax")
        }

        emit asm_instruction {
          label: "",
          mnemonic: "syscall",
          operands: vec_new()
        }

        state.asm_count = state.asm_count + 9
        state.function_count = state.function_count + 1
      }

      rule generate_main_function() {
        # Generate main() entry point that initializes runtime and starts scheduler
        # Based on M2_PHASE5_TIDAL_CYCLE_SCHEDULER_SPEC.md

        # Function label
        emit asm_instruction {
          label: "main",
          mnemonic: "",
          operands: vec_new()
        }

        # Prologue - set up stack frame
        emit asm_instruction {
          label: "",
          mnemonic: "pushq",
          operands: vec_from("%rbp")
        }

        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("%rsp", "%rbp")
        }

        # Initialize heap allocator
        emit asm_instruction {
          label: "",
          mnemonic: "call",
          operands: vec_from("heap_init")
        }

        # Create agent registry
        # TODO: Get num_agents from topology compilation (Phase 4)
        # For now, assume global symbol provided by Phase 4
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("num_agents(%rip)", "%rdi")
        }

        emit asm_instruction {
          label: "",
          mnemonic: "call",
          operands: vec_from("registry_create")
        }

        # Save registry pointer to global
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("%rax", "global_registry(%rip)")
        }

        # Initialize all agents (function generated by Phase 4)
        emit asm_instruction {
          label: "",
          mnemonic: "call",
          operands: vec_from("init_agents")
        }

        # Initialize routing tables (function generated by Phase 4)
        emit asm_instruction {
          label: "",
          mnemonic: "call",
          operands: vec_from("init_routing_tables")
        }

        # Create scheduler
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("global_registry(%rip)", "%rdi")
        }

        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("global_routing_table(%rip)", "%rsi")
        }

        emit asm_instruction {
          label: "",
          mnemonic: "call",
          operands: vec_from("scheduler_create")
        }

        # Save scheduler pointer to global
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("%rax", "global_scheduler(%rip)")
        }

        # Run scheduler (main event loop)
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("global_scheduler(%rip)", "%rdi")
        }

        emit asm_instruction {
          label: "",
          mnemonic: "call",
          operands: vec_from("scheduler_run")
        }

        # Clean up - destroy scheduler
        emit asm_instruction {
          label: "",
          mnemonic: "movq",
          operands: vec_from("global_scheduler(%rip)", "%rdi")
        }

        emit asm_instruction {
          label: "",
          mnemonic: "call",
          operands: vec_from("scheduler_destroy")
        }

        # Return 0
        emit asm_instruction {
          label: "",
          mnemonic: "xorq",
          operands: vec_from("%rax", "%rax")
        }

        # Epilogue
        emit asm_instruction {
          label: "",
          mnemonic: "popq",
          operands: vec_from("%rbp")
        }

        emit asm_instruction {
          label: "",
          mnemonic: "ret",
          operands: vec_new()
        }

        state.asm_count = state.asm_count + 20
        state.function_count = state.function_count + 1
      }

      # ─────────────────────────────────────────────────────────────────────────
      # HELPER FUNCTIONS
      # ─────────────────────────────────────────────────────────────────────────

      rule get_operand(vreg: string) -> string {
        # Check if it's a parameter (special handling)
        if starts_with(vreg, "%param") {
          let idx = parse_param_index(vreg)
          if idx < 6 {
            return format("%{}", state.arg_regs[idx])
          } else {
            # Stack parameter
            let offset = 16 + (idx - 6) * 8
            return format("{}(%rbp)", offset)
          }
        }

        # Check if allocated to a register
        if map_has(state.allocation, vreg) {
          return format("%{}", map_get(state.allocation, vreg))
        }

        # Check if spilled to stack
        if map_has(state.spill_slots, vreg) {
          let offset = map_get(state.spill_slots, vreg)
          return format("{}(%rbp)", offset)
        }

        # Unknown - return as-is (might be a label or immediate)
        return vreg
      }

      rule is_immediate(s: string) -> boolean {
        return starts_with(s, "$") || is_numeric(s)
      }

      rule is_label(s: string) -> boolean {
        return starts_with(s, ".") || starts_with(s, "_")
      }

      rule is_large_immediate(s: string) -> boolean {
        let val = parse_i64(s)
        return val > 2147483647 || val < -2147483648
      }

      rule parse_args(args_str: string) -> vec<string> {
        if args_str == "" {
          return vec_new()
        }
        return string_split(args_str, ",")
      }

      rule parse_param_index(param: string) -> u32 {
        # %param0 -> 0, %param1 -> 1, etc.
        let suffix = string_slice(param, 6, string_len(param))
        return parse_u32(suffix)
      }
    }

    hyphal assembler {
      frequency tidal_cycle

      state {
        # Input buffers
        asm_lines: vec<AsmLine>
        data_lines: vec<DataLine>
        current_section: string

        # Symbol table
        symbols: map<string, Symbol>

        # Section data
        text_section: Section
        rodata_section: Section
        data_section: Section
        bss_section: Section

        # Counters
        line_num: u32
        error_count: u32

        # Register encoding tables (initialized on first use)
        reg_codes: map<string, u8>
        reg_extended: map<string, boolean>
        reg_sizes: map<string, u8>
      }

      # ─────────────────────────────────────────────────────────────────────────
      # INITIALIZATION
      # ─────────────────────────────────────────────────────────────────────────

      on rest {
        if map_len(state.reg_codes) == 0 {
          init_register_tables()
          init_sections()
        }
      }

      rule init_register_tables() {
        # 64-bit registers (code, is_extended)
        state.reg_codes["rax"] = 0; state.reg_extended["rax"] = false; state.reg_sizes["rax"] = 64
        state.reg_codes["rcx"] = 1; state.reg_extended["rcx"] = false; state.reg_sizes["rcx"] = 64
        state.reg_codes["rdx"] = 2; state.reg_extended["rdx"] = false; state.reg_sizes["rdx"] = 64
        state.reg_codes["rbx"] = 3; state.reg_extended["rbx"] = false; state.reg_sizes["rbx"] = 64
        state.reg_codes["rsp"] = 4; state.reg_extended["rsp"] = false; state.reg_sizes["rsp"] = 64
        state.reg_codes["rbp"] = 5; state.reg_extended["rbp"] = false; state.reg_sizes["rbp"] = 64
        state.reg_codes["rsi"] = 6; state.reg_extended["rsi"] = false; state.reg_sizes["rsi"] = 64
        state.reg_codes["rdi"] = 7; state.reg_extended["rdi"] = false; state.reg_sizes["rdi"] = 64

        # Extended 64-bit registers (r8-r15)
        state.reg_codes["r8"]  = 0; state.reg_extended["r8"]  = true; state.reg_sizes["r8"]  = 64
        state.reg_codes["r9"]  = 1; state.reg_extended["r9"]  = true; state.reg_sizes["r9"]  = 64
        state.reg_codes["r10"] = 2; state.reg_extended["r10"] = true; state.reg_sizes["r10"] = 64
        state.reg_codes["r11"] = 3; state.reg_extended["r11"] = true; state.reg_sizes["r11"] = 64
        state.reg_codes["r12"] = 4; state.reg_extended["r12"] = true; state.reg_sizes["r12"] = 64
        state.reg_codes["r13"] = 5; state.reg_extended["r13"] = true; state.reg_sizes["r13"] = 64
        state.reg_codes["r14"] = 6; state.reg_extended["r14"] = true; state.reg_sizes["r14"] = 64
        state.reg_codes["r15"] = 7; state.reg_extended["r15"] = true; state.reg_sizes["r15"] = 64

        # 32-bit registers
        state.reg_codes["eax"] = 0; state.reg_extended["eax"] = false; state.reg_sizes["eax"] = 32
        state.reg_codes["ecx"] = 1; state.reg_extended["ecx"] = false; state.reg_sizes["ecx"] = 32
        state.reg_codes["edx"] = 2; state.reg_extended["edx"] = false; state.reg_sizes["edx"] = 32
        state.reg_codes["ebx"] = 3; state.reg_extended["ebx"] = false; state.reg_sizes["ebx"] = 32
        state.reg_codes["esp"] = 4; state.reg_extended["esp"] = false; state.reg_sizes["esp"] = 32
        state.reg_codes["ebp"] = 5; state.reg_extended["ebp"] = false; state.reg_sizes["ebp"] = 32
        state.reg_codes["esi"] = 6; state.reg_extended["esi"] = false; state.reg_sizes["esi"] = 32
        state.reg_codes["edi"] = 7; state.reg_extended["edi"] = false; state.reg_sizes["edi"] = 32

        # Extended 32-bit registers
        state.reg_codes["r8d"]  = 0; state.reg_extended["r8d"]  = true; state.reg_sizes["r8d"]  = 32
        state.reg_codes["r9d"]  = 1; state.reg_extended["r9d"]  = true; state.reg_sizes["r9d"]  = 32
        state.reg_codes["r10d"] = 2; state.reg_extended["r10d"] = true; state.reg_sizes["r10d"] = 32
        state.reg_codes["r11d"] = 3; state.reg_extended["r11d"] = true; state.reg_sizes["r11d"] = 32
        state.reg_codes["r12d"] = 4; state.reg_extended["r12d"] = true; state.reg_sizes["r12d"] = 32
        state.reg_codes["r13d"] = 5; state.reg_extended["r13d"] = true; state.reg_sizes["r13d"] = 32
        state.reg_codes["r14d"] = 6; state.reg_extended["r14d"] = true; state.reg_sizes["r14d"] = 32
        state.reg_codes["r15d"] = 7; state.reg_extended["r15d"] = true; state.reg_sizes["r15d"] = 32

        # 8-bit registers (low byte)
        state.reg_codes["al"] = 0; state.reg_extended["al"] = false; state.reg_sizes["al"] = 8
        state.reg_codes["cl"] = 1; state.reg_extended["cl"] = false; state.reg_sizes["cl"] = 8
        state.reg_codes["dl"] = 2; state.reg_extended["dl"] = false; state.reg_sizes["dl"] = 8
        state.reg_codes["bl"] = 3; state.reg_extended["bl"] = false; state.reg_sizes["bl"] = 8
        state.reg_codes["spl"] = 4; state.reg_extended["spl"] = false; state.reg_sizes["spl"] = 8
        state.reg_codes["bpl"] = 5; state.reg_extended["bpl"] = false; state.reg_sizes["bpl"] = 8
        state.reg_codes["sil"] = 6; state.reg_extended["sil"] = false; state.reg_sizes["sil"] = 8
        state.reg_codes["dil"] = 7; state.reg_extended["dil"] = false; state.reg_sizes["dil"] = 8
      }

      rule init_sections() {
        state.text_section = Section {
          name: ".text",
          data: vec_new(),
          relocations: vec_new()
        }
        state.rodata_section = Section {
          name: ".rodata",
          data: vec_new(),
          relocations: vec_new()
        }
        state.data_section = Section {
          name: ".data",
          data: vec_new(),
          relocations: vec_new()
        }
        state.bss_section = Section {
          name: ".bss",
          data: vec_new(),
          relocations: vec_new()
        }
        state.current_section = ".text"
      }

      # ─────────────────────────────────────────────────────────────────────────
      # SIGNAL HANDLERS - SENSE PHASE
      # ─────────────────────────────────────────────────────────────────────────

      on signal(asm_section, sect) {
        state.current_section = sect.name
      }

      on signal(asm_instruction, instr) {
        state.line_num = state.line_num + 1

        # Parse operands
        let parsed_operands: vec<Operand> = vec_new()
        for op_str in instr.operands {
          let op = parse_operand(op_str)
          vec_push(parsed_operands, op)
        }

        # Record label if present
        if instr.label != "" {
          let offset = get_current_section_offset()
          let sym = Symbol {
            name: instr.label,
            section: state.current_section,
            offset: offset,
            is_global: starts_with(instr.label, "_") || !starts_with(instr.label, "."),
            is_defined: true
          }
          map_set(state.symbols, instr.label, sym)
        }

        # Buffer the instruction
        let line = AsmLine {
          label: instr.label,
          mnemonic: string_lower(instr.mnemonic),
          operands: parsed_operands,
          line_num: state.line_num
        }
        vec_push(state.asm_lines, line)
      }

      on signal(asm_data, data) {
        state.line_num = state.line_num + 1

        # Record label if present
        if data.label != "" {
          let offset = get_current_section_offset()
          let sym = Symbol {
            name: data.label,
            section: state.current_section,
            offset: offset,
            is_global: starts_with(data.label, "_") || !starts_with(data.label, "."),
            is_defined: true
          }
          map_set(state.symbols, data.label, sym)
        }

        # Buffer the data
        let line = DataLine {
          label: data.label,
          data_type: data.data_type,
          value: data.value,
          line_num: state.line_num
        }
        vec_push(state.data_lines, line)
      }

      on signal(codegen_complete, done) {
        # All input received - perform two-pass assembly
        assemble_all()
      }

      # ─────────────────────────────────────────────────────────────────────────
      # TWO-PASS ASSEMBLY
      # ─────────────────────────────────────────────────────────────────────────

      rule assemble_all() {
        # Pass 1: Calculate instruction sizes, finalize symbol offsets
        pass1_calculate_sizes()

        # Pass 2: Encode all instructions, resolve labels
        pass2_encode_instructions()

        # Encode data sections
        encode_data_sections()

        # Emit results to Linker
        emit_results()
      }

      rule pass1_calculate_sizes() {
        let offset = 0u32

        for line in state.asm_lines {
          # Update label offset if present
          if line.label != "" && map_has(state.symbols, line.label) {
            let sym: Symbol = map_get(state.symbols, line.label)
            sym.offset = offset
            map_set(state.symbols, line.label, sym)
          }

          # Calculate instruction size (conservative estimate)
          let size = estimate_instruction_size(line.mnemonic, line.operands)
          offset = offset + size
        }
      }

      rule pass2_encode_instructions() {
        for line in state.asm_lines {
          let encoded = encode_instruction(line.mnemonic, line.operands, line.line_num)

          # Add bytes to section
          let section = get_current_section_mut()
          for byte in encoded.bytes {
            vec_push(section.data, byte)
          }

          # Add relocations
          for reloc: InstrRelocation in encoded.relocations {
            let section_reloc = SectionRelocation {
              offset: vec_len(section.data) - vec_len(encoded.bytes) + reloc.offset,
              symbol: reloc.symbol,
              reloc_type: reloc.reloc_type,
              addend: reloc.addend
            }
            vec_push(section.relocations, section_reloc)
          }
        }
      }

      rule encode_data_sections() {
        for data in state.data_lines {
          match data.data_type {
            "asciz" | "ascii" => {
              let bytes = string_to_bytes(data.value)
              let section = get_section_by_name_mut(state.current_section)
              for byte in bytes {
                vec_push(section.data, byte)
              }
              if data.data_type == "asciz" {
                vec_push(section.data, 0u8)  # Null terminator
              }
            }
            "quad" => {
              let val = parse_i64(data.value)
              let bytes = i64_to_le_bytes(val)
              let section = get_section_by_name_mut(state.current_section)
              for byte in bytes {
                vec_push(section.data, byte)
              }
            }
            "byte" => {
              let val = parse_u8(data.value)
              let section = get_section_by_name_mut(state.current_section)
              vec_push(section.data, val)
            }
            "align" => {
              let alignment = parse_u32(data.value)
              let section = get_section_by_name_mut(state.current_section)
              let current = vec_len(section.data)
              let padding = (alignment - (current % alignment)) % alignment
              for i in 0..padding {
                vec_push(section.data, 0u8)
              }
            }
            _ => {
              # Unknown data type
            }
          }
        }
      }

      rule emit_results() {
        # Emit text section
        if vec_len(state.text_section.data) > 0 {
          emit machine_code {
            section: ".text",
            offset: 0,
            bytes: state.text_section.data
          }

          for reloc: SectionRelocation in state.text_section.relocations {
            emit relocation {
              section: ".text",
              offset: reloc.offset,
              symbol: reloc.symbol,
              reloc_type: reloc.reloc_type,
              addend: reloc.addend
            }
          }

          emit section_info {
            name: ".text",
            size: vec_len(state.text_section.data),
            flags: 0x6  # 0x2 | 0x4
          }
        }

        # Emit rodata section
        if vec_len(state.rodata_section.data) > 0 {
          emit machine_code {
            section: ".rodata",
            offset: 0,
            bytes: state.rodata_section.data
          }

          emit section_info {
            name: ".rodata",
            size: vec_len(state.rodata_section.data),
            flags: 0x2  # 0x2
          }
        }

        # Emit symbols
        for name: string, sym: Symbol in state.symbols {
          emit symbol_def {
            name: sym.name,
            section: sym.section,
            offset: sym.offset,
            is_global: sym.is_global
          }
        }

        # Emit completion
        let total_relocs = vec_len(state.text_section.relocations) +
                           vec_len(state.rodata_section.relocations) +
                           vec_len(state.data_section.relocations)

        emit asm_complete {
          total_bytes: vec_len(state.text_section.data) +
                       vec_len(state.rodata_section.data) +
                       vec_len(state.data_section.data),
          symbol_count: map_len(state.symbols),
          relocation_count: total_relocs
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # OPERAND PARSING
      # ─────────────────────────────────────────────────────────────────────────

      rule parse_operand(op_str: string) -> Operand {
        let s = string_trim(op_str)

        # Check for register (with or without % prefix)
        let reg_name = if starts_with(s, "%") { string_slice(s, 1, string_len(s)) } else { s }
        if map_has(state.reg_codes, reg_name) {
          return Operand::Reg(RegisterInfo {
            name: reg_name,
            code: map_get(state.reg_codes, reg_name),
            is_extended: map_get(state.reg_extended, reg_name),
            size: map_get(state.reg_sizes, reg_name)
          })
        }

        # Check for immediate (with $ prefix or plain number)
        if starts_with(s, "$") {
          let val_str = string_slice(s, 1, string_len(s))
          let val = parse_number_value(val_str)
          return Operand::Imm(val)
        }
        if is_numeric_string(s) {
          return Operand::Imm(parse_number_value(s))
        }

        # Check for memory operand: [base + index*scale + disp] or offset(base, index, scale)
        if starts_with(s, "(") || contains(s, "(") {
          return Operand::Mem(parse_memory_operand(s))
        }

        # Otherwise, it's a label reference
        return Operand::Label(s)
      }

      rule parse_memory_operand(s: string) -> MemoryOperand {
        # Parse AT&T syntax: disp(base, index, scale) or (base)
        # Also handle: offset(%reg) or (%reg)

        let base = ""
        let index = ""
        let scale = 1u8
        let displacement = 0i32
        let is_rip = false

        # Find displacement (before parenthesis)
        let paren_pos = string_index_of(s, "(")
        if paren_pos > 0 {
          let disp_str = string_slice(s, 0, paren_pos)
          if disp_str != "" && is_numeric_string(disp_str) {
            displacement = parse_i32(disp_str)
          }
        }

        # Extract content inside parentheses
        let start = paren_pos + 1
        let end = string_index_of(s, ")")
        let inner = string_slice(s, start, end)

        # Parse base, index, scale
        let parts = string_split(inner, ",")
        if vec_len(parts) >= 1 && parts[0] != "" {
          base = string_trim(parts[0])
          if starts_with(base, "%") {
            base = string_slice(base, 1, string_len(base))
          }
          if base == "rip" {
            is_rip = true
          }
        }
        if vec_len(parts) >= 2 && parts[1] != "" {
          index = string_trim(parts[1])
          if starts_with(index, "%") {
            index = string_slice(index, 1, string_len(index))
          }
        }
        if vec_len(parts) >= 3 && parts[2] != "" {
          scale = parse_u8(string_trim(parts[2]))
        }

        return MemoryOperand {
          base: base,
          index: index,
          scale: scale,
          displacement: displacement,
          is_rip_relative: is_rip
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # INSTRUCTION ENCODING
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_instruction(mnemonic: string, operands: vec<Operand>, line: u32) -> EncodedInstruction {
        let bytes: vec<u8> = vec_new()
        let relocs: vec<InstrRelocation> = vec_new()

        match mnemonic {
          # ─── DATA MOVEMENT ───
          "mov" | "movq" | "movl" | "movw" | "movb" => {
            encode_mov(operands, bytes, relocs)
          }
          "movabs" | "movabsq" => {
            encode_movabs(operands, bytes, relocs)
          }
          "lea" | "leaq" => {
            encode_lea(operands, bytes, relocs)
          }
          "push" | "pushq" => {
            encode_push(operands, bytes)
          }
          "pop" | "popq" => {
            encode_pop(operands, bytes)
          }

          # ─── ARITHMETIC ───
          "add" | "addq" | "addl" => {
            encode_alu(operands, bytes, relocs, 0x01, 0x03, 0x81, 0x83, 0)
          }
          "sub" | "subq" | "subl" => {
            encode_alu(operands, bytes, relocs, 0x29, 0x2B, 0x81, 0x83, 5)
          }
          "imul" | "imulq" => {
            encode_imul(operands, bytes)
          }
          "idiv" | "idivq" => {
            encode_idiv(operands, bytes)
          }
          "neg" | "negq" => {
            encode_unary(operands, bytes, 0xF7, 3)
          }
          "inc" | "incq" => {
            encode_unary(operands, bytes, 0xFF, 0)
          }
          "dec" | "decq" => {
            encode_unary(operands, bytes, 0xFF, 1)
          }

          # ─── BITWISE LOGIC ───
          "and" | "andq" | "andl" => {
            encode_alu(operands, bytes, relocs, 0x21, 0x23, 0x81, 0x83, 4)
          }
          "or" | "orq" | "orl" => {
            encode_alu(operands, bytes, relocs, 0x09, 0x0B, 0x81, 0x83, 1)
          }
          "xor" | "xorq" | "xorl" => {
            encode_alu(operands, bytes, relocs, 0x31, 0x33, 0x81, 0x83, 6)
          }
          "not" | "notq" => {
            encode_unary(operands, bytes, 0xF7, 2)
          }
          "shl" | "shlq" | "sal" | "salq" => {
            encode_shift(operands, bytes, 4)
          }
          "shr" | "shrq" => {
            encode_shift(operands, bytes, 5)
          }
          "sar" | "sarq" => {
            encode_shift(operands, bytes, 7)
          }

          # ─── COMPARISON ───
          "cmp" | "cmpq" | "cmpl" => {
            encode_alu(operands, bytes, relocs, 0x39, 0x3B, 0x81, 0x83, 7)
          }
          "test" | "testq" | "testl" => {
            encode_test(operands, bytes)
          }

          # ─── CONTROL FLOW ───
          "jmp" => {
            encode_jmp(operands, bytes, relocs)
          }
          "je" | "jz" => {
            encode_jcc(operands, bytes, relocs, 0x84, 0x74)
          }
          "jne" | "jnz" => {
            encode_jcc(operands, bytes, relocs, 0x85, 0x75)
          }
          "jl" | "jnge" => {
            encode_jcc(operands, bytes, relocs, 0x8C, 0x7C)
          }
          "jle" | "jng" => {
            encode_jcc(operands, bytes, relocs, 0x8E, 0x7E)
          }
          "jg" | "jnle" => {
            encode_jcc(operands, bytes, relocs, 0x8F, 0x7F)
          }
          "jge" | "jnl" => {
            encode_jcc(operands, bytes, relocs, 0x8D, 0x7D)
          }
          "ja" | "jnbe" => {
            encode_jcc(operands, bytes, relocs, 0x87, 0x77)
          }
          "jae" | "jnb" | "jnc" => {
            encode_jcc(operands, bytes, relocs, 0x83, 0x73)
          }
          "jb" | "jnae" | "jc" => {
            encode_jcc(operands, bytes, relocs, 0x82, 0x72)
          }
          "jbe" | "jna" => {
            encode_jcc(operands, bytes, relocs, 0x86, 0x76)
          }
          "call" => {
            encode_call(operands, bytes, relocs)
          }
          "ret" | "retq" => {
            vec_push(bytes, 0xC3)
          }

          # ─── SET BYTE ───
          "sete" | "setz" => {
            encode_setcc(operands, bytes, 0x94)
          }
          "setne" | "setnz" => {
            encode_setcc(operands, bytes, 0x95)
          }
          "setl" | "setnge" => {
            encode_setcc(operands, bytes, 0x9C)
          }
          "setle" | "setng" => {
            encode_setcc(operands, bytes, 0x9E)
          }
          "setg" | "setnle" => {
            encode_setcc(operands, bytes, 0x9F)
          }
          "setge" | "setnl" => {
            encode_setcc(operands, bytes, 0x9D)
          }

          # ─── ZERO/SIGN EXTEND ───
          "movzbq" | "movzbl" => {
            encode_movzx(operands, bytes)
          }
          "movsbq" | "movsbl" => {
            encode_movsx(operands, bytes)
          }
          "movsxd" | "movslq" => {
            encode_movsxd(operands, bytes)
          }
          "cqo" | "cqto" => {
            vec_push(bytes, 0x48)  # REX.W
            vec_push(bytes, 0x99)  # CQO
          }
          "cdq" | "cltd" => {
            vec_push(bytes, 0x99)  # CDQ
          }

          # ─── EXCHANGE ───
          "xchg" | "xchgq" => {
            encode_xchg(operands, bytes)
          }

          # ─── UNSIGNED MULTIPLY/DIVIDE ───
          "mul" | "mulq" => {
            encode_unary(operands, bytes, 0xF7, 4)  # MUL r/m64
          }
          "div" | "divq" => {
            encode_unary(operands, bytes, 0xF7, 6)  # DIV r/m64
          }

          # ─── ADDITIONAL CONDITIONAL JUMPS ───
          "js" => {
            encode_jcc(operands, bytes, relocs, 0x88, 0x78)
          }
          "jns" => {
            encode_jcc(operands, bytes, relocs, 0x89, 0x79)
          }
          "jo" => {
            encode_jcc(operands, bytes, relocs, 0x80, 0x70)
          }
          "jno" => {
            encode_jcc(operands, bytes, relocs, 0x81, 0x71)
          }
          "jp" | "jpe" => {
            encode_jcc(operands, bytes, relocs, 0x8A, 0x7A)
          }
          "jnp" | "jpo" => {
            encode_jcc(operands, bytes, relocs, 0x8B, 0x7B)
          }

          # ─── ADDITIONAL SET BYTE ───
          "seta" | "setnbe" => {
            encode_setcc(operands, bytes, 0x97)
          }
          "setae" | "setnb" | "setnc" => {
            encode_setcc(operands, bytes, 0x93)
          }
          "setb" | "setnae" | "setc" => {
            encode_setcc(operands, bytes, 0x92)
          }
          "setbe" | "setna" => {
            encode_setcc(operands, bytes, 0x96)
          }
          "sets" => {
            encode_setcc(operands, bytes, 0x98)
          }
          "setns" => {
            encode_setcc(operands, bytes, 0x99)
          }
          "seto" => {
            encode_setcc(operands, bytes, 0x90)
          }
          "setno" => {
            encode_setcc(operands, bytes, 0x91)
          }
          "setp" | "setpe" => {
            encode_setcc(operands, bytes, 0x9A)
          }
          "setnp" | "setpo" => {
            encode_setcc(operands, bytes, 0x9B)
          }

          # ─── CONDITIONAL MOVE ───
          "cmove" | "cmovz" => {
            encode_cmovcc(operands, bytes, 0x44)
          }
          "cmovne" | "cmovnz" => {
            encode_cmovcc(operands, bytes, 0x45)
          }
          "cmovl" | "cmovnge" => {
            encode_cmovcc(operands, bytes, 0x4C)
          }
          "cmovle" | "cmovng" => {
            encode_cmovcc(operands, bytes, 0x4E)
          }
          "cmovg" | "cmovnle" => {
            encode_cmovcc(operands, bytes, 0x4F)
          }
          "cmovge" | "cmovnl" => {
            encode_cmovcc(operands, bytes, 0x4D)
          }
          "cmova" | "cmovnbe" => {
            encode_cmovcc(operands, bytes, 0x47)
          }
          "cmovae" | "cmovnb" | "cmovnc" => {
            encode_cmovcc(operands, bytes, 0x43)
          }
          "cmovb" | "cmovnae" | "cmovc" => {
            encode_cmovcc(operands, bytes, 0x42)
          }
          "cmovbe" | "cmovna" => {
            encode_cmovcc(operands, bytes, 0x46)
          }
          "cmovs" => {
            encode_cmovcc(operands, bytes, 0x48)
          }
          "cmovns" => {
            encode_cmovcc(operands, bytes, 0x49)
          }

          # ─── SYSTEM ───
          "syscall" => {
            vec_push(bytes, 0x0F)
            vec_push(bytes, 0x05)
          }
          "nop" => {
            vec_push(bytes, 0x90)
          }
          "hlt" => {
            vec_push(bytes, 0xF4)
          }
          "ud2" => {
            vec_push(bytes, 0x0F)
            vec_push(bytes, 0x0B)
          }

          _ => {
            emit asm_error {
              message: format("Unknown instruction: {}", mnemonic),
              line: line,
              instruction: mnemonic
            }
            state.error_count = state.error_count + 1
          }
        }

        return EncodedInstruction {
          bytes: bytes,
          relocations: relocs
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # MOV ENCODING
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_mov(operands: vec<Operand>, bytes: vec<u8>, relocs: vec<InstrRelocation>) {
        if vec_len(operands) != 2 {
          return
        }

        let src = operands[0]
        let dst = operands[1]

        match (src, dst) {
          # mov reg, reg
          (Operand::Reg(src_reg), Operand::Reg(dst_reg)) => {
            let rex = build_rex_rr(dst_reg, src_reg, true)
            if rex != 0 {
              vec_push(bytes, rex)
            }
            vec_push(bytes, 0x89)  # MOV r/m64, r64
            vec_push(bytes, build_modrm(3, src_reg.code, dst_reg.code))
          }

          # mov imm, reg
          (Operand::Imm(val), Operand::Reg(dst_reg)) => {
            if val >= -2147483648 && val <= 2147483647 {
              # 32-bit immediate (sign-extended)
              let rex = build_rex_r(dst_reg, true)
              if rex != 0 {
                vec_push(bytes, rex)
              }
              vec_push(bytes, 0xC7)  # MOV r/m64, imm32
              vec_push(bytes, build_modrm(3, 0, dst_reg.code))
              append_imm32(bytes, val as i32)
            } else {
              # 64-bit immediate (movabs)
              let rex = 0x48 | (if dst_reg.is_extended { 0x01 } else { 0 })
              vec_push(bytes, rex)
              vec_push(bytes, 0xB8 + dst_reg.code)  # MOV r64, imm64
              append_imm64(bytes, val)
            }
          }

          # mov mem, reg (load)
          (Operand::Mem(mem), Operand::Reg(dst_reg)) => {
            encode_mem_reg(bytes, relocs, mem, dst_reg, 0x8B, true)
          }

          # mov reg, mem (store)
          (Operand::Reg(src_reg), Operand::Mem(mem)) => {
            encode_reg_mem(bytes, relocs, src_reg, mem, 0x89, true)
          }

          # mov label, reg
          (Operand::Label(label), Operand::Reg(dst_reg)) => {
            # lea with RIP-relative addressing
            let rex = build_rex_r(dst_reg, true)
            if rex != 0 {
              vec_push(bytes, rex)
            }
            vec_push(bytes, 0x8D)  # LEA
            vec_push(bytes, build_modrm(0, dst_reg.code, 5))  # RIP-relative
            # Add relocation
            vec_push(relocs, InstrRelocation {
              offset: vec_len(bytes) as u8,
              symbol: label,
              reloc_type: RelocationType::R_X86_64_PC32,
              addend: -4
            })
            append_imm32(bytes, 0)  # Placeholder
          }

          _ => {
            # Unsupported operand combination
          }
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # MOVABS ENCODING (64-bit immediate)
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_movabs(operands: vec<Operand>, bytes: vec<u8>, relocs: vec<InstrRelocation>) {
        if vec_len(operands) != 2 {
          return
        }

        match (operands[0], operands[1]) {
          (Operand::Imm(val), Operand::Reg(dst_reg)) => {
            let rex = 0x48 | (if dst_reg.is_extended { 0x01 } else { 0 })
            vec_push(bytes, rex)
            vec_push(bytes, 0xB8 + dst_reg.code)  # MOV r64, imm64
            append_imm64(bytes, val)
          }
          _ => {}
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # LEA ENCODING
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_lea(operands: vec<Operand>, bytes: vec<u8>, relocs: vec<InstrRelocation>) {
        if vec_len(operands) != 2 {
          return
        }

        match (operands[0], operands[1]) {
          (Operand::Mem(mem), Operand::Reg(dst_reg)) => {
            encode_mem_reg(bytes, relocs, mem, dst_reg, 0x8D, true)
          }
          (Operand::Label(label), Operand::Reg(dst_reg)) => {
            # RIP-relative LEA
            let rex = build_rex_r(dst_reg, true)
            if rex != 0 {
              vec_push(bytes, rex)
            }
            vec_push(bytes, 0x8D)  # LEA
            vec_push(bytes, build_modrm(0, dst_reg.code, 5))  # RIP-relative
            vec_push(relocs, InstrRelocation {
              offset: vec_len(bytes) as u8,
              symbol: label,
              reloc_type: RelocationType::R_X86_64_PC32,
              addend: -4
            })
            append_imm32(bytes, 0)
          }
          _ => {}
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # PUSH/POP ENCODING
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_push(operands: vec<Operand>, bytes: vec<u8>) {
        if vec_len(operands) != 1 {
          return
        }

        match operands[0] {
          Operand::Reg(reg) => {
            if reg.is_extended {
              vec_push(bytes, 0x41)  # REX.B
            }
            vec_push(bytes, 0x50 + reg.code)
          }
          Operand::Imm(val) => {
            if val >= -128 && val <= 127 {
              vec_push(bytes, 0x6A)  # PUSH imm8
              vec_push(bytes, val as u8)
            } else {
              vec_push(bytes, 0x68)  # PUSH imm32
              append_imm32(bytes, val as i32)
            }
          }
          _ => {}
        }
      }

      rule encode_pop(operands: vec<Operand>, bytes: vec<u8>) {
        if vec_len(operands) != 1 {
          return
        }

        match operands[0] {
          Operand::Reg(reg) => {
            if reg.is_extended {
              vec_push(bytes, 0x41)  # REX.B
            }
            vec_push(bytes, 0x58 + reg.code)
          }
          _ => {}
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # ALU OPERATIONS (add, sub, and, or, xor, cmp)
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_alu(operands: vec<Operand>, bytes: vec<u8>, relocs: vec<InstrRelocation>,
                      opcode_rm_r: u8, opcode_r_rm: u8, opcode_rm_imm32: u8, opcode_rm_imm8: u8,
                      reg_opcode: u8) {
        if vec_len(operands) != 2 {
          return
        }

        let src = operands[0]
        let dst = operands[1]

        match (src, dst) {
          # alu reg, reg
          (Operand::Reg(src_reg), Operand::Reg(dst_reg)) => {
            let rex = build_rex_rr(dst_reg, src_reg, true)
            if rex != 0 {
              vec_push(bytes, rex)
            }
            vec_push(bytes, opcode_rm_r)
            vec_push(bytes, build_modrm(3, src_reg.code, dst_reg.code))
          }

          # alu imm, reg
          (Operand::Imm(val), Operand::Reg(dst_reg)) => {
            let rex = build_rex_r(dst_reg, true)
            if rex != 0 {
              vec_push(bytes, rex)
            }

            if val >= -128 && val <= 127 {
              vec_push(bytes, opcode_rm_imm8)  # 83 /r
              vec_push(bytes, build_modrm(3, reg_opcode, dst_reg.code))
              vec_push(bytes, val as u8)
            } else {
              vec_push(bytes, opcode_rm_imm32)  # 81 /r
              vec_push(bytes, build_modrm(3, reg_opcode, dst_reg.code))
              append_imm32(bytes, val as i32)
            }
          }

          # alu mem, reg
          (Operand::Mem(mem), Operand::Reg(dst_reg)) => {
            encode_mem_reg(bytes, relocs, mem, dst_reg, opcode_r_rm, true)
          }

          # alu reg, mem
          (Operand::Reg(src_reg), Operand::Mem(mem)) => {
            encode_reg_mem(bytes, relocs, src_reg, mem, opcode_rm_r, true)
          }

          _ => {}
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # IMUL/IDIV ENCODING
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_imul(operands: vec<Operand>, bytes: vec<u8>) {
        if vec_len(operands) == 1 {
          # imul r/m64 (rdx:rax = rax * r/m64)
          match operands[0] {
            Operand::Reg(reg) => {
              let rex = build_rex_r(reg, true)
              if rex != 0 {
                vec_push(bytes, rex)
              }
              vec_push(bytes, 0xF7)
              vec_push(bytes, build_modrm(3, 5, reg.code))
            }
            _ => {}
          }
        } else if vec_len(operands) == 2 {
          # imul r64, r/m64
          match (operands[0], operands[1]) {
            (Operand::Reg(src_reg), Operand::Reg(dst_reg)) => {
              let rex = build_rex_rr(src_reg, dst_reg, true)
              if rex != 0 {
                vec_push(bytes, rex)
              }
              vec_push(bytes, 0x0F)
              vec_push(bytes, 0xAF)
              vec_push(bytes, build_modrm(3, dst_reg.code, src_reg.code))
            }
            _ => {}
          }
        }
      }

      rule encode_idiv(operands: vec<Operand>, bytes: vec<u8>) {
        if vec_len(operands) != 1 {
          return
        }

        match operands[0] {
          Operand::Reg(reg) => {
            let rex = build_rex_r(reg, true)
            if rex != 0 {
              vec_push(bytes, rex)
            }
            vec_push(bytes, 0xF7)
            vec_push(bytes, build_modrm(3, 7, reg.code))
          }
          _ => {}
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # UNARY OPERATIONS (neg, not, inc, dec)
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_unary(operands: vec<Operand>, bytes: vec<u8>, opcode: u8, reg_opcode: u8) {
        if vec_len(operands) != 1 {
          return
        }

        match operands[0] {
          Operand::Reg(reg) => {
            let rex = build_rex_r(reg, true)
            if rex != 0 {
              vec_push(bytes, rex)
            }
            vec_push(bytes, opcode)
            vec_push(bytes, build_modrm(3, reg_opcode, reg.code))
          }
          _ => {}
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # SHIFT OPERATIONS
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_shift(operands: vec<Operand>, bytes: vec<u8>, reg_opcode: u8) {
        if vec_len(operands) != 2 {
          return
        }

        match (operands[0], operands[1]) {
          # shift imm8, reg
          (Operand::Imm(count), Operand::Reg(reg)) => {
            let rex = build_rex_r(reg, true)
            if rex != 0 {
              vec_push(bytes, rex)
            }
            if count == 1 {
              vec_push(bytes, 0xD1)  # Shift by 1
            } else {
              vec_push(bytes, 0xC1)  # Shift by imm8
            }
            vec_push(bytes, build_modrm(3, reg_opcode, reg.code))
            if count != 1 {
              vec_push(bytes, count as u8)
            }
          }
          # shift cl, reg
          (Operand::Reg(cl_reg), Operand::Reg(reg)) => {
            if cl_reg.name == "cl" {
              let rex = build_rex_r(reg, true)
              if rex != 0 {
                vec_push(bytes, rex)
              }
              vec_push(bytes, 0xD3)  # Shift by CL
              vec_push(bytes, build_modrm(3, reg_opcode, reg.code))
            }
          }
          _ => {}
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # TEST ENCODING
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_test(operands: vec<Operand>, bytes: vec<u8>) {
        if vec_len(operands) != 2 {
          return
        }

        match (operands[0], operands[1]) {
          (Operand::Reg(src_reg), Operand::Reg(dst_reg)) => {
            let rex = build_rex_rr(dst_reg, src_reg, true)
            if rex != 0 {
              vec_push(bytes, rex)
            }
            vec_push(bytes, 0x85)  # TEST r/m64, r64
            vec_push(bytes, build_modrm(3, src_reg.code, dst_reg.code))
          }
          _ => {}
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # JUMP ENCODING
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_jmp(operands: vec<Operand>, bytes: vec<u8>, relocs: vec<InstrRelocation>) {
        if vec_len(operands) != 1 {
          return
        }

        match operands[0] {
          Operand::Label(label) => {
            # Always use rel32 for simplicity
            vec_push(bytes, 0xE9)  # JMP rel32
            vec_push(relocs, InstrRelocation {
              offset: vec_len(bytes) as u8,
              symbol: label,
              reloc_type: RelocationType::R_X86_64_PC32,
              addend: -4
            })
            append_imm32(bytes, 0)  # Placeholder
          }
          Operand::Reg(reg) => {
            # JMP r/m64 (indirect jump)
            if reg.is_extended {
              vec_push(bytes, 0x41)  # REX.B
            }
            vec_push(bytes, 0xFF)
            vec_push(bytes, build_modrm(3, 4, reg.code))
          }
          _ => {}
        }
      }

      rule encode_jcc(operands: vec<Operand>, bytes: vec<u8>, relocs: vec<InstrRelocation>,
                      opcode_rel32: u8, opcode_rel8: u8) {
        if vec_len(operands) != 1 {
          return
        }

        match operands[0] {
          Operand::Label(label) => {
            # Use rel32 form (0F 8x)
            vec_push(bytes, 0x0F)
            vec_push(bytes, opcode_rel32)
            vec_push(relocs, InstrRelocation {
              offset: vec_len(bytes) as u8,
              symbol: label,
              reloc_type: RelocationType::R_X86_64_PC32,
              addend: -4
            })
            append_imm32(bytes, 0)  # Placeholder
          }
          _ => {}
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # CALL ENCODING
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_call(operands: vec<Operand>, bytes: vec<u8>, relocs: vec<InstrRelocation>) {
        if vec_len(operands) != 1 {
          return
        }

        match operands[0] {
          Operand::Label(label) => {
            vec_push(bytes, 0xE8)  # CALL rel32
            vec_push(relocs, InstrRelocation {
              offset: vec_len(bytes) as u8,
              symbol: label,
              reloc_type: RelocationType::R_X86_64_PC32,
              addend: -4
            })
            append_imm32(bytes, 0)  # Placeholder
          }
          Operand::Reg(reg) => {
            # CALL r/m64 (indirect call)
            if reg.is_extended {
              vec_push(bytes, 0x41)  # REX.B
            }
            vec_push(bytes, 0xFF)
            vec_push(bytes, build_modrm(3, 2, reg.code))
          }
          _ => {}
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # SETCC ENCODING
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_setcc(operands: vec<Operand>, bytes: vec<u8>, opcode: u8) {
        if vec_len(operands) != 1 {
          return
        }

        match operands[0] {
          Operand::Reg(reg) => {
            if reg.is_extended {
              vec_push(bytes, 0x41)  # REX.B
            }
            vec_push(bytes, 0x0F)
            vec_push(bytes, opcode)
            vec_push(bytes, build_modrm(3, 0, reg.code))
          }
          _ => {}
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # MOVZX/MOVSX ENCODING
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_movzx(operands: vec<Operand>, bytes: vec<u8>) {
        if vec_len(operands) != 2 {
          return
        }

        match (operands[0], operands[1]) {
          (Operand::Reg(src_reg), Operand::Reg(dst_reg)) => {
            let rex = build_rex_rr(src_reg, dst_reg, true)
            if rex != 0 {
              vec_push(bytes, rex)
            }
            vec_push(bytes, 0x0F)
            vec_push(bytes, 0xB6)  # MOVZX r64, r/m8
            vec_push(bytes, build_modrm(3, dst_reg.code, src_reg.code))
          }
          _ => {}
        }
      }

      rule encode_movsx(operands: vec<Operand>, bytes: vec<u8>) {
        if vec_len(operands) != 2 {
          return
        }

        match (operands[0], operands[1]) {
          (Operand::Reg(src_reg), Operand::Reg(dst_reg)) => {
            let rex = build_rex_rr(src_reg, dst_reg, true)
            if rex != 0 {
              vec_push(bytes, rex)
            }
            vec_push(bytes, 0x0F)
            vec_push(bytes, 0xBE)  # MOVSX r64, r/m8
            vec_push(bytes, build_modrm(3, dst_reg.code, src_reg.code))
          }
          _ => {}
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # MOVSXD ENCODING (Sign-extend dword to qword)
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_movsxd(operands: vec<Operand>, bytes: vec<u8>) {
        if vec_len(operands) != 2 {
          return
        }

        match (operands[0], operands[1]) {
          (Operand::Reg(src_reg), Operand::Reg(dst_reg)) => {
            let rex = build_rex_rr(src_reg, dst_reg, true)
            if rex != 0 {
              vec_push(bytes, rex)
            }
            vec_push(bytes, 0x63)  # MOVSXD r64, r/m32
            vec_push(bytes, build_modrm(3, dst_reg.code, src_reg.code))
          }
          _ => {}
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # XCHG ENCODING
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_xchg(operands: vec<Operand>, bytes: vec<u8>) {
        if vec_len(operands) != 2 {
          return
        }

        match (operands[0], operands[1]) {
          (Operand::Reg(src_reg), Operand::Reg(dst_reg)) => {
            # Special case: xchg rax, reg uses short form
            if dst_reg.name == "rax" && !src_reg.is_extended {
              vec_push(bytes, 0x48)  # REX.W
              vec_push(bytes, 0x90 + src_reg.code)  # XCHG rax, r64
            } else if src_reg.name == "rax" && !dst_reg.is_extended {
              vec_push(bytes, 0x48)  # REX.W
              vec_push(bytes, 0x90 + dst_reg.code)  # XCHG rax, r64
            } else {
              # General form: XCHG r/m64, r64
              let rex = build_rex_rr(dst_reg, src_reg, true)
              if rex != 0 {
                vec_push(bytes, rex)
              }
              vec_push(bytes, 0x87)  # XCHG r/m64, r64
              vec_push(bytes, build_modrm(3, src_reg.code, dst_reg.code))
            }
          }
          _ => {}
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # CMOVCC ENCODING (Conditional Move)
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_cmovcc(operands: vec<Operand>, bytes: vec<u8>, opcode: u8) {
        if vec_len(operands) != 2 {
          return
        }

        match (operands[0], operands[1]) {
          (Operand::Reg(src_reg), Operand::Reg(dst_reg)) => {
            let rex = build_rex_rr(src_reg, dst_reg, true)
            if rex != 0 {
              vec_push(bytes, rex)
            }
            vec_push(bytes, 0x0F)
            vec_push(bytes, opcode)  # CMOVcc r64, r/m64
            vec_push(bytes, build_modrm(3, dst_reg.code, src_reg.code))
          }
          _ => {}
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # MEMORY ADDRESSING HELPERS
      # ─────────────────────────────────────────────────────────────────────────

      rule encode_mem_reg(bytes: vec<u8>, relocs: vec<InstrRelocation>,
                          mem: MemoryOperand, reg: RegisterInfo, opcode: u8, is_64bit: boolean) {
        # Build REX prefix
        let rex = build_rex_mem_reg(mem, reg, is_64bit)
        if rex != 0 {
          vec_push(bytes, rex)
        }

        vec_push(bytes, opcode)

        # Encode addressing mode
        encode_memory_modrm_sib(bytes, relocs, mem, reg.code)
      }

      rule encode_reg_mem(bytes: vec<u8>, relocs: vec<InstrRelocation>,
                          reg: RegisterInfo, mem: MemoryOperand, opcode: u8, is_64bit: boolean) {
        # Build REX prefix
        let rex = build_rex_mem_reg(mem, reg, is_64bit)
        if rex != 0 {
          vec_push(bytes, rex)
        }

        vec_push(bytes, opcode)

        # Encode addressing mode
        encode_memory_modrm_sib(bytes, relocs, mem, reg.code)
      }

      rule encode_memory_modrm_sib(bytes: vec<u8>, relocs: vec<InstrRelocation>,
                                    mem: MemoryOperand, reg_code: u8) {
        if mem.is_rip_relative || mem.base == "" {
          # RIP-relative or absolute addressing
          vec_push(bytes, build_modrm(0, reg_code, 5))  # mod=00, r/m=101 (RIP-relative)
          append_imm32(bytes, mem.displacement)
          return
        }

        let base_code = map_get(state.reg_codes, mem.base)
        let base_extended = map_get(state.reg_extended, mem.base)
        let needs_sib = mem.index != "" || mem.base == "rsp" || mem.base == "r12"

        # Determine mod field based on displacement
        let mod_field = 0u8
        if mem.displacement == 0 && mem.base != "rbp" && mem.base != "r13" {
          mod_field = 0  # No displacement
        } else if mem.displacement >= -128 && mem.displacement <= 127 {
          mod_field = 1  # 8-bit displacement
        } else {
          mod_field = 2  # 32-bit displacement
        }

        if needs_sib {
          # Need SIB byte
          let rm_field = 4u8  # SIB follows
          vec_push(bytes, build_modrm(mod_field, reg_code, rm_field))

          # Build SIB byte
          let scale = match mem.scale {
            1 => 0u8
            2 => 1u8
            4 => 2u8
            8 => 3u8
            _ => 0u8
          }

          let index_code = if mem.index != "" {
            map_get(state.reg_codes, mem.index)
          } else {
            4  # No index (100)
          }

          vec_push(bytes, (scale << 6) | (index_code << 3) | base_code)
        } else {
          vec_push(bytes, build_modrm(mod_field, reg_code, base_code))
        }

        # Add displacement
        if mod_field == 1 {
          vec_push(bytes, mem.displacement as u8)
        } else if mod_field == 2 {
          append_imm32(bytes, mem.displacement)
        } else if mem.base == "rbp" || mem.base == "r13" {
          # Special case: rbp/r13 with no displacement needs disp8=0
          vec_push(bytes, 0)
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # REX PREFIX HELPERS
      # ─────────────────────────────────────────────────────────────────────────

      rule build_rex_rr(rm_reg: RegisterInfo, r_reg: RegisterInfo, is_64bit: boolean) -> u8 {
        let w = if is_64bit { 1u8 } else { 0u8 }
        let r = if r_reg.is_extended { 1u8 } else { 0u8 }
        let b = if rm_reg.is_extended { 1u8 } else { 0u8 }

        if w == 0 && r == 0 && b == 0 {
          return 0  # No REX needed
        }
        return 0x40 | (w << 3) | (r << 2) | b
      }

      rule build_rex_r(reg: RegisterInfo, is_64bit: boolean) -> u8 {
        let w = if is_64bit { 1u8 } else { 0u8 }
        let b = if reg.is_extended { 1u8 } else { 0u8 }

        if w == 0 && b == 0 {
          return 0
        }
        return 0x40 | (w << 3) | b
      }

      rule build_rex_mem_reg(mem: MemoryOperand, reg: RegisterInfo, is_64bit: boolean) -> u8 {
        let w = if is_64bit { 1u8 } else { 0u8 }
        let r = if reg.is_extended { 1u8 } else { 0u8 }
        let x = if mem.index != "" && map_get(state.reg_extended, mem.index) { 1u8 } else { 0u8 }
        let b = if mem.base != "" && map_get(state.reg_extended, mem.base) { 1u8 } else { 0u8 }

        if w == 0 && r == 0 && x == 0 && b == 0 {
          return 0
        }
        return 0x40 | (w << 3) | (r << 2) | (x << 1) | b
      }

      # ─────────────────────────────────────────────────────────────────────────
      # MODR/M AND IMMEDIATE HELPERS
      # ─────────────────────────────────────────────────────────────────────────

      rule build_modrm(mod_field: u8, reg: u8, rm: u8) -> u8 {
        return (mod_field << 6) | ((reg & 0x7) << 3) | (rm & 0x7)
      }

      rule append_imm8(bytes: vec<u8>, val: i8) {
        vec_push(bytes, val as u8)
      }

      rule append_imm32(bytes: vec<u8>, val: i32) {
        vec_push(bytes, (val & 0xFF) as u8)
        vec_push(bytes, ((val >> 8) & 0xFF) as u8)
        vec_push(bytes, ((val >> 16) & 0xFF) as u8)
        vec_push(bytes, ((val >> 24) & 0xFF) as u8)
      }

      rule append_imm64(bytes: vec<u8>, val: i64) {
        vec_push(bytes, (val & 0xFF) as u8)
        vec_push(bytes, ((val >> 8) & 0xFF) as u8)
        vec_push(bytes, ((val >> 16) & 0xFF) as u8)
        vec_push(bytes, ((val >> 24) & 0xFF) as u8)
        vec_push(bytes, ((val >> 32) & 0xFF) as u8)
        vec_push(bytes, ((val >> 40) & 0xFF) as u8)
        vec_push(bytes, ((val >> 48) & 0xFF) as u8)
        vec_push(bytes, ((val >> 56) & 0xFF) as u8)
      }

      # ─────────────────────────────────────────────────────────────────────────
      # UTILITY HELPERS
      # ─────────────────────────────────────────────────────────────────────────

      rule estimate_instruction_size(mnemonic: string, operands: vec<Operand>) -> u32 {
        # Conservative estimate for instruction sizes
        match mnemonic {
          "ret" | "nop" | "hlt" => 1
          "syscall" | "ud2" => 2
          "cqo" | "cdq" => 2
          "push" | "pop" => 2
          _ => 7  # Maximum typical instruction size (REX + opcode + modrm + sib + disp32)
        }
      }

      rule get_current_section_offset() -> u32 {
        match state.current_section {
          ".text" => vec_len(state.text_section.data)
          ".rodata" => vec_len(state.rodata_section.data)
          ".data" => vec_len(state.data_section.data)
          ".bss" => vec_len(state.bss_section.data)
          _ => 0
        }
      }

      rule get_current_section_mut() -> Section {
        match state.current_section {
          ".text" => state.text_section
          ".rodata" => state.rodata_section
          ".data" => state.data_section
          ".bss" => state.bss_section
          _ => state.text_section
        }
      }

      rule get_section_by_name_mut(name: string) -> Section {
        match name {
          ".text" => state.text_section
          ".rodata" => state.rodata_section
          ".data" => state.data_section
          ".bss" => state.bss_section
          _ => state.text_section
        }
      }

      rule parse_number_value(s: string) -> i64 {
        if starts_with(s, "0x") || starts_with(s, "0X") {
          return parse_hex(string_slice(s, 2, string_len(s)))
        }
        return parse_i64(s)
      }

      rule is_numeric_string(s: string) -> boolean {
        if string_len(s) == 0 {
          return false
        }
        let first = char_at(s, 0)
        return first == '-' || first == '+' || (first >= '0' && first <= '9')
      }

      rule string_to_bytes(s: string) -> vec<u8> {
        let result: vec<u8> = vec_new()
        let i = 0
        let len = string_len(s)

        # Skip surrounding quotes if present
        if len >= 2 && (char_at(s, 0) == '"' || char_at(s, 0) == '\'') {
          i = 1
          len = len - 1
        }

        while i < len {
          let c = char_at(s, i)
          if c == '\\' && i + 1 < len {
            let next = char_at(s, i + 1)
            match next {
              'n' => { vec_push(result, 10u8); i = i + 2 }
              'r' => { vec_push(result, 13u8); i = i + 2 }
              't' => { vec_push(result, 9u8); i = i + 2 }
              '0' => { vec_push(result, 0u8); i = i + 2 }
              '\\' => { vec_push(result, 92u8); i = i + 2 }
              '"' => { vec_push(result, 34u8); i = i + 2 }
              '\'' => { vec_push(result, 39u8); i = i + 2 }
              _ => { vec_push(result, c as u8); i = i + 1 }
            }
          } else {
            vec_push(result, c as u8)
            i = i + 1
          }
        }
        return result
      }

      rule i64_to_le_bytes(val: i64) -> vec<u8> {
        let result: vec<u8> = vec_new()
        append_imm64(result, val)
        return result
      }
    }

    hyphal linker {
      frequency tidal_cycle

      state {
        # Section data
        text_data: vec<u8>
        rodata_data: vec<u8>
        data_data: vec<u8>
        bss_size: u32

        # Symbols and relocations
        symbols: vec<SymbolEntry>
        relocations: vec<RelocationEntry>

        # Layout information
        text_vaddr: u64
        rodata_vaddr: u64
        data_vaddr: u64
        bss_vaddr: u64

        text_file_offset: u64
        rodata_file_offset: u64
        data_file_offset: u64

        # String tables
        shstrtab: vec<u8>       # Section name string table
        strtab: vec<u8>         # Symbol string table

        # Output
        output_buffer: vec<u8>
        output_file: string
        entry_point: u64

        # Counters
        error_count: u32
      }

      # ─────────────────────────────────────────────────────────────────────────
      # INITIALIZATION
      # ─────────────────────────────────────────────────────────────────────────

      on rest {
        if vec_len(state.text_data) == 0 {
          init_state()
        }
      }

      rule init_state() {
        state.text_data = vec_new()
        state.rodata_data = vec_new()
        state.data_data = vec_new()
        state.bss_size = 0

        state.symbols = vec_new()
        state.relocations = vec_new()

        state.shstrtab = vec_new()
        state.strtab = vec_new()
        state.output_buffer = vec_new()
        state.output_file = "a.out"
      }

      # ─────────────────────────────────────────────────────────────────────────
      # SIGNAL HANDLERS - SENSE PHASE
      # ─────────────────────────────────────────────────────────────────────────

      on signal(machine_code, mc) {
        # Collect machine code by section
        match mc.section {
          ".text" => {
            for byte in mc.bytes {
              vec_push(state.text_data, byte)
            }
          }
          ".rodata" => {
            for byte in mc.bytes {
              vec_push(state.rodata_data, byte)
            }
          }
          ".data" => {
            for byte in mc.bytes {
              vec_push(state.data_data, byte)
            }
          }
          ".bss" => {
            state.bss_size = state.bss_size + vec_len(mc.bytes)
          }
          _ => {}
        }
      }

      on signal(relocation, rel) {
        let entry = RelocationEntry {
          section: rel.section,
          offset: rel.offset,
          symbol: rel.symbol,
          reloc_type: rel.reloc_type,
          addend: rel.addend
        }
        vec_push(state.relocations, entry)
      }

      on signal(symbol_def, sym) {
        let entry = SymbolEntry {
          name: sym.name,
          section: sym.section,
          offset: sym.offset,
          is_global: sym.is_global,
          vaddr: 0  # Calculated during layout
        }
        vec_push(state.symbols, entry)
      }

      on signal(section_info, info) {
        # Section info received (used for validation)
        if info.name == ".bss" {
          state.bss_size = info.size
        }
      }

      on signal(asm_complete, done) {
        # All input received - perform linking
        link_executable()
      }

      # ─────────────────────────────────────────────────────────────────────────
      # MAIN LINKING PROCESS
      # ─────────────────────────────────────────────────────────────────────────

      rule link_executable() {
        # Step 1: Calculate section layout
        calculate_layout()

        # Step 2: Finalize symbol addresses
        finalize_symbol_addresses()

        # Step 3: Apply relocations
        apply_relocations()

        # Step 4: Build string tables
        build_string_tables()

        # Step 5: Generate ELF binary
        generate_elf_binary()

        # Step 6: Write to file
        write_output_file()

        if state.error_count == 0 {
          emit link_complete {
            output_file: state.output_file,
            file_size: vec_len(state.output_buffer),
            entry_point: state.entry_point
          }
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # STEP 1: CALCULATE LAYOUT
      # ─────────────────────────────────────────────────────────────────────────

      rule calculate_layout() {
        # ELF Header at offset 0 (64 bytes)
        # Program Headers at offset 64 (2 headers * 56 bytes = 112 bytes)
        # Total headers: 64 + 112 = 176 bytes (0xB0)

        let headers_size = 64 + (2 * 56)  # ELF_HEADER_SIZE + (2 * PROGRAM_HEADER_SIZE)

        # .text section starts at page boundary after headers
        state.text_file_offset = align_up(headers_size as u64, 4096)
        state.text_vaddr = 0x400000 + state.text_file_offset

        # Entry point is start of .text
        state.entry_point = state.text_vaddr

        # .rodata follows .text, aligned to 16 bytes
        let text_end = state.text_file_offset + (vec_len(state.text_data) as u64)
        state.rodata_file_offset = align_up(text_end, 16)
        state.rodata_vaddr = 0x400000 + state.rodata_file_offset

        # .data follows .rodata, aligned to 8 bytes
        let rodata_end = state.rodata_file_offset + (vec_len(state.rodata_data) as u64)
        state.data_file_offset = align_up(rodata_end, 8)
        state.data_vaddr = 0x400000 + state.data_file_offset

        # .bss follows .data (not in file, only in memory)
        let data_end = state.data_file_offset + (vec_len(state.data_data) as u64)
        state.bss_vaddr = 0x400000 + align_up(data_end, 8)
      }

      # ─────────────────────────────────────────────────────────────────────────
      # STEP 2: FINALIZE SYMBOL ADDRESSES
      # ─────────────────────────────────────────────────────────────────────────

      rule finalize_symbol_addresses() {
        for i in 0..vec_len(state.symbols) {
          let sym: SymbolEntry = state.symbols[i]

          # Calculate virtual address based on section
          let base_vaddr = match sym.section {
            ".text" => state.text_vaddr
            ".rodata" => state.rodata_vaddr
            ".data" => state.data_vaddr
            ".bss" => state.bss_vaddr
            _ => state.text_vaddr  # Default to .text
          }

          sym.vaddr = base_vaddr + (sym.offset as u64)
          state.symbols[i] = sym
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # STEP 3: APPLY RELOCATIONS
      # ─────────────────────────────────────────────────────────────────────────

      rule apply_relocations() {
        for reloc: RelocationEntry in state.relocations {
          # Find symbol address
          let symbol_vaddr = find_symbol_address(reloc.symbol)
          if symbol_vaddr == 0 {
            emit link_error {
              message: format("Undefined symbol: {}", reloc.symbol),
              symbol: reloc.symbol
            }
            state.error_count = state.error_count + 1
            continue
          }

          # Calculate relocation address
          let reloc_section_vaddr = match reloc.section {
            ".text" => state.text_vaddr
            ".rodata" => state.rodata_vaddr
            ".data" => state.data_vaddr
            _ => state.text_vaddr
          }

          let reloc_vaddr = reloc_section_vaddr + (reloc.offset as u64)

          # Apply relocation based on type
          match reloc.reloc_type {
            RelocationType::R_X86_64_PC32 => {
              # PC-relative 32-bit: S + A - P
              # P = address of next instruction (reloc_vaddr + 4)
              let next_instr = reloc_vaddr + 4
              let value = (symbol_vaddr as i64) + reloc.addend - (next_instr as i64)

              # Patch in .text section
              if reloc.section == ".text" {
                patch_i32(state.text_data, reloc.offset, value as i32)
              }
            }
            RelocationType::R_X86_64_64 => {
              # 64-bit absolute: S + A
              let value = (symbol_vaddr as i64) + reloc.addend

              if reloc.section == ".text" {
                patch_i64(state.text_data, reloc.offset, value)
              } else if reloc.section == ".data" {
                patch_i64(state.data_data, reloc.offset, value)
              }
            }
            RelocationType::R_X86_64_32 => {
              # 32-bit absolute: S + A
              let value = (symbol_vaddr as i64) + reloc.addend

              if reloc.section == ".text" {
                patch_i32(state.text_data, reloc.offset, value as i32)
              }
            }
            RelocationType::R_X86_64_32S => {
              # 32-bit signed: S + A
              let value = (symbol_vaddr as i64) + reloc.addend

              if reloc.section == ".text" {
                patch_i32(state.text_data, reloc.offset, value as i32)
              }
            }
            _ => {
              # Unsupported relocation type
            }
          }
        }
      }

      rule find_symbol_address(name: string) -> u64 {
        for sym: SymbolEntry in state.symbols {
          if sym.name == name {
            return sym.vaddr
          }
        }
        # Symbol not found
        return 0
      }

      rule patch_i32(data: vec<u8>, offset: u32, value: i32) {
        data[offset] = (value & 0xFF) as u8
        data[offset + 1] = ((value >> 8) & 0xFF) as u8
        data[offset + 2] = ((value >> 16) & 0xFF) as u8
        data[offset + 3] = ((value >> 24) & 0xFF) as u8
      }

      rule patch_i64(data: vec<u8>, offset: u32, value: i64) {
        data[offset] = (value & 0xFF) as u8
        data[offset + 1] = ((value >> 8) & 0xFF) as u8
        data[offset + 2] = ((value >> 16) & 0xFF) as u8
        data[offset + 3] = ((value >> 24) & 0xFF) as u8
        data[offset + 4] = ((value >> 32) & 0xFF) as u8
        data[offset + 5] = ((value >> 40) & 0xFF) as u8
        data[offset + 6] = ((value >> 48) & 0xFF) as u8
        data[offset + 7] = ((value >> 56) & 0xFF) as u8
      }

      # ─────────────────────────────────────────────────────────────────────────
      # STEP 4: BUILD STRING TABLES
      # ─────────────────────────────────────────────────────────────────────────

      rule build_string_tables() {
        # Build section name string table (.shstrtab)
        # Format: \0.text\0.rodata\0.data\0.bss\0.symtab\0.strtab\0.shstrtab\0

        state.shstrtab = vec_new()
        vec_push(state.shstrtab, 0u8)  # Index 0: empty string

        # Add section names
        add_string_to_table(state.shstrtab, ".text")      # Offset 1
        add_string_to_table(state.shstrtab, ".rodata")    # Offset 7
        add_string_to_table(state.shstrtab, ".data")      # Offset 15
        add_string_to_table(state.shstrtab, ".bss")       # Offset 21
        add_string_to_table(state.shstrtab, ".symtab")    # Offset 26
        add_string_to_table(state.shstrtab, ".strtab")    # Offset 34
        add_string_to_table(state.shstrtab, ".shstrtab")  # Offset 42

        # Build symbol string table (.strtab)
        state.strtab = vec_new()
        vec_push(state.strtab, 0u8)  # Index 0: empty string

        for sym: SymbolEntry in state.symbols {
          add_string_to_table(state.strtab, sym.name)
        }
      }

      rule add_string_to_table(table: vec<u8>, s: string) {
        for i in 0..string_len(s) {
          vec_push(table, char_at(s, i) as u8)
        }
        vec_push(table, 0u8)  # Null terminator
      }

      # ─────────────────────────────────────────────────────────────────────────
      # STEP 5: GENERATE ELF BINARY
      # ─────────────────────────────────────────────────────────────────────────

      rule generate_elf_binary() {
        state.output_buffer = vec_new()

        # Generate ELF header
        generate_elf_header()

        # Generate program headers
        generate_program_headers()

        # Pad to .text file offset
        pad_to_offset(state.text_file_offset as u32)

        # Write .text section
        for byte in state.text_data {
          vec_push(state.output_buffer, byte)
        }

        # Pad to .rodata file offset
        pad_to_offset(state.rodata_file_offset as u32)

        # Write .rodata section
        for byte in state.rodata_data {
          vec_push(state.output_buffer, byte)
        }

        # Pad to .data file offset (if we have data)
        if vec_len(state.data_data) > 0 {
          pad_to_offset(state.data_file_offset as u32)

          # Write .data section
          for byte in state.data_data {
            vec_push(state.output_buffer, byte)
          }
        }

        # Note: .bss is not written to file (only takes memory at runtime)

        # For a minimal executable, we can skip section headers
        # They're only needed for debugging/linking, not execution
      }

      rule generate_elf_header() {
        # ELF Header: 64 bytes

        # e_ident[0..4]: Magic number
        vec_push(state.output_buffer, 0x7F)
        vec_push(state.output_buffer, 0x45)  # 'E'
        vec_push(state.output_buffer, 0x4C)  # 'L'
        vec_push(state.output_buffer, 0x46)  # 'F'

        # e_ident[4]: Class (64-bit)
        vec_push(state.output_buffer, 0x02)

        # e_ident[5]: Data (little-endian)
        vec_push(state.output_buffer, 0x01)

        # e_ident[6]: Version
        vec_push(state.output_buffer, 0x01)

        # e_ident[7]: OS/ABI (SYSV)
        vec_push(state.output_buffer, 0x00)

        # e_ident[8..16]: Padding
        for i in 0..8 {
          vec_push(state.output_buffer, 0x00)
        }

        # e_type: ET_EXEC (executable)
        write_u16_le(state.output_buffer, 0x0002)

        # e_machine: x86-64
        write_u16_le(state.output_buffer, 0x003E)

        # e_version: 1
        write_u32_le(state.output_buffer, 0x00000001)

        # e_entry: Entry point address
        write_u64_le(state.output_buffer, state.entry_point)

        # e_phoff: Program header offset (64 = right after ELF header)
        write_u64_le(state.output_buffer, 64)

        # e_shoff: Section header offset (0 = no section headers for minimal)
        write_u64_le(state.output_buffer, 0)

        # e_flags: 0
        write_u32_le(state.output_buffer, 0)

        # e_ehsize: ELF header size (64)
        write_u16_le(state.output_buffer, 64)

        # e_phentsize: Program header entry size (56)
        write_u16_le(state.output_buffer, 56)

        # e_phnum: Number of program headers (2: code + data)
        let phnum = if vec_len(state.data_data) > 0 || state.bss_size > 0 { 2 } else { 1 }
        write_u16_le(state.output_buffer, phnum as u16)

        # e_shentsize: Section header entry size (64)
        write_u16_le(state.output_buffer, 64)

        # e_shnum: Number of section headers (0 for minimal)
        write_u16_le(state.output_buffer, 0)

        # e_shstrndx: Section name string table index (0)
        write_u16_le(state.output_buffer, 0)
      }

      rule generate_program_headers() {
        # Program Header 1: Code segment (PT_LOAD, R+X)
        # Covers ELF header + program headers + .text + .rodata

        let code_segment_end = state.rodata_file_offset + (vec_len(state.rodata_data) as u64)
        let code_filesz = code_segment_end
        let code_memsz = code_filesz

        # p_type: PT_LOAD
        write_u32_le(state.output_buffer, 1)

        # p_flags: PF_R | PF_X (readable + executable)
        write_u32_le(state.output_buffer, 5)

        # p_offset: File offset (0 - include headers)
        write_u64_le(state.output_buffer, 0)

        # p_vaddr: Virtual address
        write_u64_le(state.output_buffer, 0x400000)

        # p_paddr: Physical address (same as vaddr)
        write_u64_le(state.output_buffer, 0x400000)

        # p_filesz: Size in file
        write_u64_le(state.output_buffer, code_filesz)

        # p_memsz: Size in memory
        write_u64_le(state.output_buffer, code_memsz)

        # p_align: Page alignment
        write_u64_le(state.output_buffer, 4096)

        # Program Header 2: Data segment (PT_LOAD, R+W) - if we have data
        if vec_len(state.data_data) > 0 || state.bss_size > 0 {
          let data_filesz = vec_len(state.data_data) as u64
          let data_memsz = data_filesz + (state.bss_size as u64)

          # p_type: PT_LOAD
          write_u32_le(state.output_buffer, 1)

          # p_flags: PF_R | PF_W (readable + writable)
          write_u32_le(state.output_buffer, 6)

          # p_offset: File offset
          write_u64_le(state.output_buffer, state.data_file_offset)

          # p_vaddr: Virtual address
          write_u64_le(state.output_buffer, state.data_vaddr)

          # p_paddr: Physical address
          write_u64_le(state.output_buffer, state.data_vaddr)

          # p_filesz: Size in file
          write_u64_le(state.output_buffer, data_filesz)

          # p_memsz: Size in memory (includes .bss)
          write_u64_le(state.output_buffer, data_memsz)

          # p_align: Page alignment
          write_u64_le(state.output_buffer, 4096)
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # STEP 6: WRITE OUTPUT FILE
      # ─────────────────────────────────────────────────────────────────────────

      rule write_output_file() {
        # Write the output buffer to file
        # In a real implementation, this would use a file I/O system
        # For now, we emit the binary data as a signal

        # The runtime would handle:
        # write_file(state.output_file, state.output_buffer)
        # chmod(state.output_file, 0o755)
      }

      # ─────────────────────────────────────────────────────────────────────────
      # HELPER FUNCTIONS
      # ─────────────────────────────────────────────────────────────────────────

      rule align_up(value: u64, alignment: u64) -> u64 {
        if alignment == 0 {
          return value
        }
        return ((value + alignment - 1) / alignment) * alignment
      }

      rule pad_to_offset(target_offset: u32) {
        while vec_len(state.output_buffer) < target_offset {
          vec_push(state.output_buffer, 0u8)
        }
      }

      rule write_u16_le(buffer: vec<u8>, value: u16) {
        vec_push(buffer, (value & 0xFF) as u8)
        vec_push(buffer, ((value >> 8) & 0xFF) as u8)
      }

      rule write_u32_le(buffer: vec<u8>, value: u32) {
        vec_push(buffer, (value & 0xFF) as u8)
        vec_push(buffer, ((value >> 8) & 0xFF) as u8)
        vec_push(buffer, ((value >> 16) & 0xFF) as u8)
        vec_push(buffer, ((value >> 24) & 0xFF) as u8)
      }

      rule write_u64_le(buffer: vec<u8>, value: u64) {
        vec_push(buffer, (value & 0xFF) as u8)
        vec_push(buffer, ((value >> 8) & 0xFF) as u8)
        vec_push(buffer, ((value >> 16) & 0xFF) as u8)
        vec_push(buffer, ((value >> 24) & 0xFF) as u8)
        vec_push(buffer, ((value >> 32) & 0xFF) as u8)
        vec_push(buffer, ((value >> 40) & 0xFF) as u8)
        vec_push(buffer, ((value >> 48) & 0xFF) as u8)
        vec_push(buffer, ((value >> 56) & 0xFF) as u8)
      }

      rule get_section_name_offset(name: string) -> u32 {
        # Return offset of section name in .shstrtab
        match name {
          ".text" => 1
          ".rodata" => 7
          ".data" => 15
          ".bss" => 21
          ".symtab" => 26
          ".strtab" => 34
          ".shstrtab" => 42
          _ => 0
        }
      }

      # ─────────────────────────────────────────────────────────────────────────
      # OPTIONAL: FULL ELF WITH SECTION HEADERS
      # ─────────────────────────────────────────────────────────────────────────

      rule generate_full_elf_binary() {
        # This generates a complete ELF with section headers
        # Useful for debugging with objdump, readelf, etc.

        state.output_buffer = vec_new()

        # Calculate section header table offset
        let data_end = state.data_file_offset + (vec_len(state.data_data) as u64)
        let symtab_offset = align_up(data_end, 8)
        let symtab_size = vec_len(state.symbols) * 24
        let strtab_offset = symtab_offset + (symtab_size as u64)
        let strtab_size = vec_len(state.strtab)
        let shstrtab_offset = strtab_offset + (strtab_size as u64)
        let shstrtab_size = vec_len(state.shstrtab)
        let shdr_offset = align_up(shstrtab_offset + (shstrtab_size as u64), 8)

        # Number of sections: null + .text + .rodata + .data + .bss + .symtab + .strtab + .shstrtab = 8
        let section_count = 8u16

        # Generate ELF header with section headers
        generate_elf_header_full(shdr_offset, section_count)

        # Generate program headers
        generate_program_headers()

        # Write sections
        pad_to_offset(state.text_file_offset as u32)
        for byte in state.text_data {
          vec_push(state.output_buffer, byte)
        }

        pad_to_offset(state.rodata_file_offset as u32)
        for byte in state.rodata_data {
          vec_push(state.output_buffer, byte)
        }

        if vec_len(state.data_data) > 0 {
          pad_to_offset(state.data_file_offset as u32)
          for byte in state.data_data {
            vec_push(state.output_buffer, byte)
          }
        }

        # Write symbol table
        pad_to_offset(symtab_offset as u32)
        generate_symbol_table()

        # Write string table
        pad_to_offset(strtab_offset as u32)
        for byte in state.strtab {
          vec_push(state.output_buffer, byte)
        }

        # Write section name string table
        pad_to_offset(shstrtab_offset as u32)
        for byte in state.shstrtab {
          vec_push(state.output_buffer, byte)
        }

        # Write section headers
        pad_to_offset(shdr_offset as u32)
        generate_section_headers(symtab_offset, strtab_offset, shstrtab_offset)
      }

      rule generate_elf_header_full(shdr_offset: u64, section_count: u16) {
        # Same as generate_elf_header but with section headers

        # e_ident[0..4]: Magic number
        vec_push(state.output_buffer, 0x7F)
        vec_push(state.output_buffer, 0x45)
        vec_push(state.output_buffer, 0x4C)
        vec_push(state.output_buffer, 0x46)

        # e_ident[4..16]
        vec_push(state.output_buffer, 0x02)  # 64-bit
        vec_push(state.output_buffer, 0x01)  # Little-endian
        vec_push(state.output_buffer, 0x01)  # Version
        vec_push(state.output_buffer, 0x00)  # OS/ABI
        for i in 0..8 {
          vec_push(state.output_buffer, 0x00)
        }

        write_u16_le(state.output_buffer, 0x0002)  # ET_EXEC
        write_u16_le(state.output_buffer, 0x003E)  # x86-64
        write_u32_le(state.output_buffer, 0x00000001)  # Version
        write_u64_le(state.output_buffer, state.entry_point)  # Entry
        write_u64_le(state.output_buffer, 64)  # Program header offset
        write_u64_le(state.output_buffer, shdr_offset)  # Section header offset
        write_u32_le(state.output_buffer, 0)  # Flags
        write_u16_le(state.output_buffer, 64)  # ELF header size
        write_u16_le(state.output_buffer, 56)  # Program header size
        write_u16_le(state.output_buffer, 2)   # Number of program headers
        write_u16_le(state.output_buffer, 64)  # Section header size
        write_u16_le(state.output_buffer, section_count)  # Number of section headers
        write_u16_le(state.output_buffer, 7)   # Section name string table index (.shstrtab)
      }

      rule generate_symbol_table() {
        # First entry: null symbol
        for i in 0..24 {
          vec_push(state.output_buffer, 0u8)
        }

        # Symbol entries
        let strtab_offset = 1u32  # Start after null byte
        for sym: SymbolEntry in state.symbols {
          # st_name: Offset in string table
          write_u32_le(state.output_buffer, strtab_offset)
          strtab_offset = strtab_offset + (string_len(sym.name) as u32) + 1

          # st_info: Binding and type
          let binding = if sym.is_global { 1 } else { 0 }
          let stype = 2  # Assume functions for now
          vec_push(state.output_buffer, (binding << 4) | stype)

          # st_other: 0 (default visibility)
          vec_push(state.output_buffer, 0u8)

          # st_shndx: Section index
          let shndx = match sym.section {
            ".text" => 1u16
            ".rodata" => 2u16
            ".data" => 3u16
            ".bss" => 4u16
            _ => 0u16
          }
          write_u16_le(state.output_buffer, shndx)

          # st_value: Symbol address
          write_u64_le(state.output_buffer, sym.vaddr)

          # st_size: 0 (unknown)
          write_u64_le(state.output_buffer, 0)
        }
      }

      rule generate_section_headers(symtab_offset: u64, strtab_offset: u64, shstrtab_offset: u64) {
        # Section 0: NULL
        generate_null_section_header()

        # Section 1: .text
        generate_section_header(
          get_section_name_offset(".text"),
          1,
          0x2 | 0x4,
          state.text_vaddr,
          state.text_file_offset,
          vec_len(state.text_data) as u64,
          0, 0, 16, 0
        )

        # Section 2: .rodata
        generate_section_header(
          get_section_name_offset(".rodata"),
          1,
          0x2,
          state.rodata_vaddr,
          state.rodata_file_offset,
          vec_len(state.rodata_data) as u64,
          0, 0, 8, 0
        )

        # Section 3: .data
        generate_section_header(
          get_section_name_offset(".data"),
          1,
          0x2 | 0x1,
          state.data_vaddr,
          state.data_file_offset,
          vec_len(state.data_data) as u64,
          0, 0, 8, 0
        )

        # Section 4: .bss
        generate_section_header(
          get_section_name_offset(".bss"),
          8,
          0x2 | 0x1,
          state.bss_vaddr,
          0,  # No file offset for .bss
          state.bss_size as u64,
          0, 0, 8, 0
        )

        # Section 5: .symtab
        generate_section_header(
          get_section_name_offset(".symtab"),
          2,
          0,
          0,
          symtab_offset,
          ((vec_len(state.symbols) + 1) * 24) as u64,
          6,  # Link to .strtab
          1,  # First global symbol index
          8,
          24 as u64
        )

        # Section 6: .strtab
        generate_section_header(
          get_section_name_offset(".strtab"),
          3,
          0,
          0,
          strtab_offset,
          vec_len(state.strtab) as u64,
          0, 0, 1, 0
        )

        # Section 7: .shstrtab
        generate_section_header(
          get_section_name_offset(".shstrtab"),
          3,
          0,
          0,
          shstrtab_offset,
          vec_len(state.shstrtab) as u64,
          0, 0, 1, 0
        )
      }

      rule generate_null_section_header() {
        for i in 0..64 {
          vec_push(state.output_buffer, 0u8)
        }
      }

      rule generate_section_header(
        sh_name: u32,
        sh_type: u32,
        sh_flags: u64,
        sh_addr: u64,
        sh_offset: u64,
        sh_size: u64,
        sh_link: u32,
        sh_info: u32,
        sh_addralign: u64,
        sh_entsize: u64
      ) {
        write_u32_le(state.output_buffer, sh_name)
        write_u32_le(state.output_buffer, sh_type)
        write_u64_le(state.output_buffer, sh_flags)
        write_u64_le(state.output_buffer, sh_addr)
        write_u64_le(state.output_buffer, sh_offset)
        write_u64_le(state.output_buffer, sh_size)
        write_u32_le(state.output_buffer, sh_link)
        write_u32_le(state.output_buffer, sh_info)
        write_u64_le(state.output_buffer, sh_addralign)
        write_u64_le(state.output_buffer, sh_entsize)
      }
    }
  }


  # ============================================================================
  # SECTION 8: TOPOLOGY
  # ============================================================================

  topology {
    # External interfaces
    fruiting_body input      # Receives startup signal with file paths
    fruiting_body output     # Emits final compilation status

    # Spawn all agents
    spawn main as M1
    spawn orchestrator as O1
    spawn lexer as L1

    # All compiler pipeline agents
    spawn parser as P1
    spawn ir_generator as IR1
    spawn x86_codegen as CG1
    spawn assembler as AS1
    spawn linker as LK1

    # Input to main
    socket input -> M1 (frequency: startup)

    # Main to orchestrator
    socket M1 -> O1 (frequency: compile_request)

    # Orchestrator to lexer
    socket O1 -> L1 (frequency: lex_request)

    # Lexer to orchestrator (tokens)
    socket L1 -> O1 (frequency: token)
    socket L1 -> O1 (frequency: lex_complete)

    # Orchestrator forwards to parser
    socket O1 -> P1 (frequency: token)
    socket O1 -> P1 (frequency: lex_complete)

    # Parser to orchestrator
    socket P1 -> O1 (frequency: ast_node)
    socket P1 -> O1 (frequency: ast_complete)
    socket P1 -> O1 (frequency: parse_error)
    socket P1 -> O1 (frequency: parse_complete)

    # Orchestrator forwards to IR generator
    socket O1 -> IR1 (frequency: ast_complete)

    # IR generator to orchestrator
    socket IR1 -> O1 (frequency: ir_node)
    socket IR1 -> O1 (frequency: ir_function_start)
    socket IR1 -> O1 (frequency: ir_function_end)
    socket IR1 -> O1 (frequency: lir_function)
    socket IR1 -> O1 (frequency: lir_struct)
    socket IR1 -> O1 (frequency: ir_complete)
    socket IR1 -> O1 (frequency: ir_error)

    # Orchestrator forwards to code generator
    socket O1 -> CG1 (frequency: ir_node)
    socket O1 -> CG1 (frequency: ir_function_start)
    socket O1 -> CG1 (frequency: ir_function_end)
    socket O1 -> CG1 (frequency: ir_complete)

    # Code generator to orchestrator
    socket CG1 -> O1 (frequency: asm_instruction)
    socket CG1 -> O1 (frequency: asm_data)
    socket CG1 -> O1 (frequency: asm_section)
    socket CG1 -> O1 (frequency: codegen_complete)

    # Orchestrator forwards to assembler
    socket O1 -> AS1 (frequency: asm_instruction)
    socket O1 -> AS1 (frequency: asm_data)
    socket O1 -> AS1 (frequency: asm_section)
    socket O1 -> AS1 (frequency: codegen_complete)

    # Assembler to orchestrator
    socket AS1 -> O1 (frequency: machine_code)
    socket AS1 -> O1 (frequency: relocation)
    socket AS1 -> O1 (frequency: symbol_def)
    socket AS1 -> O1 (frequency: section_info)
    socket AS1 -> O1 (frequency: asm_complete)
    socket AS1 -> O1 (frequency: asm_error)

    # Orchestrator forwards to linker
    socket O1 -> LK1 (frequency: machine_code)
    socket O1 -> LK1 (frequency: relocation)
    socket O1 -> LK1 (frequency: symbol_def)
    socket O1 -> LK1 (frequency: section_info)
    socket O1 -> LK1 (frequency: asm_complete)

    # Linker to orchestrator
    socket LK1 -> O1 (frequency: link_complete)
    socket LK1 -> O1 (frequency: link_error)

    # Orchestrator to main (completion)
    socket O1 -> M1 (frequency: compilation_complete)
    socket O1 -> M1 (frequency: compilation_error)

    # Main to output
    socket M1 -> output (frequency: compilation_complete)
  }
}

# ============================================================================
# END OF ORCHESTRATION FILE
# ============================================================================
#
# Total Structure:
#   - 7 Sections
#   - 35+ Frequency Definitions
#   - 1 Lexer Hyphal (new)
#   - 1 Orchestrator Hyphal
#   - 1 Main Entry Hyphal
#   - Complete Topology Definition
#
# Pipeline Flow:
#   startup -> main -> orchestrator -> lexer -> parser -> ir_generator ->
#   codegen -> assembler -> linker -> compilation_complete
#
# Author: Opus (Claude Opus 4.5)
# Date: 2026-01-01
